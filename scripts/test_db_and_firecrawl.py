#!/usr/bin/env python3
"""
æ•°æ®åº“è¿æ¥å’ŒFirecrawl APIæµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. å¯åŠ¨é¡¹ç›®å¹¶è¿æ¥MongoDBæ•°æ®åº“
2. è·å–ä¸¤æ¡Firecrawl APIè¿”å›çš„åŸå§‹æ•°æ®

è¿è¡Œæ–¹å¼ï¼š
    python scripts/test_db_and_firecrawl.py
"""

import asyncio
import json
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from motor.motor_asyncio import AsyncIOMotorClient
from src.config import settings
from src.infrastructure.crawlers.firecrawl_adapter import FirecrawlAdapter
from src.utils.logger import get_logger

logger = get_logger(__name__)


class DatabaseAndFirecrawlTester:
    """æ•°æ®åº“è¿æ¥å’ŒFirecrawl APIæµ‹è¯•å™¨"""

    def __init__(self):
        self.mongo_client = None
        self.db = None
        self.firecrawl_adapter = None

    async def connect_database(self) -> bool:
        """è¿æ¥MongoDBæ•°æ®åº“"""
        print("\n" + "="*70)
        print("ğŸ“Š æ­¥éª¤1: è¿æ¥MongoDBæ•°æ®åº“")
        print("="*70)

        try:
            print(f"ğŸ”Œ æ­£åœ¨è¿æ¥MongoDB...")
            print(f"   URL: {settings.MONGODB_URL.split('@')[1] if '@' in settings.MONGODB_URL else 'localhost'}")
            print(f"   æ•°æ®åº“: {settings.MONGODB_DB_NAME}")

            # åˆ›å»ºMongoDBè¿æ¥
            self.mongo_client = AsyncIOMotorClient(
                settings.MONGODB_URL,
                maxPoolSize=settings.MONGODB_MAX_POOL_SIZE,
                minPoolSize=settings.MONGODB_MIN_POOL_SIZE,
                serverSelectionTimeoutMS=5000
            )

            self.db = self.mongo_client[settings.MONGODB_DB_NAME]

            # æµ‹è¯•è¿æ¥
            await asyncio.wait_for(
                self.mongo_client.admin.command('ping'),
                timeout=5.0
            )

            # è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
            stats = await self.db.command("dbStats")
            collections = await self.db.list_collection_names()

            print(f"\nâœ… MongoDBè¿æ¥æˆåŠŸï¼")
            print(f"\nğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
            print(f"   - æ•°æ®åº“åç§°: {stats['db']}")
            print(f"   - é›†åˆæ•°é‡: {stats['collections']}")
            print(f"   - æ•°æ®å¤§å°: {stats['dataSize'] / 1024 / 1024:.2f} MB")
            print(f"   - ç´¢å¼•æ•°é‡: {stats['indexes']}")
            print(f"\nğŸ“ é›†åˆåˆ—è¡¨:")
            for coll in collections[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                count = await self.db[coll].count_documents({})
                print(f"   - {coll}: {count} æ¡è®°å½•")

            return True

        except asyncio.TimeoutError:
            print(f"\nâŒ MongoDBè¿æ¥è¶…æ—¶")
            print(f"   è¯·æ£€æŸ¥MongoDBæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
            return False
        except Exception as e:
            print(f"\nâŒ MongoDBè¿æ¥å¤±è´¥: {e}")
            return False

    async def init_firecrawl(self) -> bool:
        """åˆå§‹åŒ–Firecrawlé€‚é…å™¨"""
        print("\n" + "="*70)
        print("ğŸ”¥ æ­¥éª¤2: åˆå§‹åŒ–Firecrawlé€‚é…å™¨")
        print("="*70)

        try:
            print(f"ğŸ”‘ æ­£åœ¨åˆå§‹åŒ–Firecrawl...")
            print(f"   API Key: {settings.FIRECRAWL_API_KEY[:10]}...{settings.FIRECRAWL_API_KEY[-10:]}")
            print(f"   Base URL: {settings.FIRECRAWL_BASE_URL}")
            print(f"   Timeout: {settings.FIRECRAWL_TIMEOUT}s")

            self.firecrawl_adapter = FirecrawlAdapter(api_key=settings.FIRECRAWL_API_KEY)

            print(f"\nâœ… Firecrawlé€‚é…å™¨åˆå§‹åŒ–æˆåŠŸï¼")
            return True

        except ValueError as e:
            print(f"\nâŒ Firecrawlåˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"   è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„FIRECRAWL_API_KEYé…ç½®")
            return False
        except Exception as e:
            print(f"\nâŒ Firecrawlåˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def test_firecrawl_scrape(self) -> dict:
        """æµ‹è¯•Firecrawl scrapeæ–¹æ³•ï¼ˆçˆ¬å–å•ä¸ªé¡µé¢ï¼‰"""
        print("\n" + "="*70)
        print("ğŸŒ æ­¥éª¤3: æµ‹è¯•Firecrawl Scrape APIï¼ˆçˆ¬å–å•ä¸ªé¡µé¢ï¼‰")
        print("="*70)

        test_url = "https://example.com"

        try:
            print(f"ğŸ“ ç›®æ ‡URL: {test_url}")
            print(f"â±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
            print(f"ğŸ”„ æ­£åœ¨çˆ¬å–...")

            start_time = asyncio.get_event_loop().time()

            # è°ƒç”¨scrapeæ–¹æ³•
            result = await self.firecrawl_adapter.scrape(test_url)

            end_time = asyncio.get_event_loop().time()
            duration = end_time - start_time

            print(f"\nâœ… çˆ¬å–æˆåŠŸï¼")
            print(f"â±ï¸  è€—æ—¶: {duration:.2f}ç§’")

            # æ„é€ åŸå§‹å“åº”æ•°æ®
            raw_response = {
                "success": True,
                "method": "scrape",
                "url": test_url,
                "timestamp": datetime.now().isoformat(),
                "duration_seconds": round(duration, 2),
                "data": {
                    "url": result.url,
                    "content": result.content[:500] + "..." if len(result.content) > 500 else result.content,
                    "content_length": len(result.content),
                    "markdown": result.markdown[:500] + "..." if result.markdown and len(result.markdown) > 500 else result.markdown,
                    "markdown_length": len(result.markdown) if result.markdown else 0,
                    "html_length": len(result.html) if result.html else 0,
                    "metadata": result.metadata,
                    "has_screenshot": result.screenshot is not None
                }
            }

            print(f"\nğŸ“„ å“åº”æ•°æ®æ‘˜è¦:")
            print(f"   - URL: {result.url}")
            print(f"   - å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦")
            print(f"   - Markdowné•¿åº¦: {len(result.markdown) if result.markdown else 0} å­—ç¬¦")
            print(f"   - HTMLé•¿åº¦: {len(result.html) if result.html else 0} å­—ç¬¦")
            print(f"   - å…ƒæ•°æ®: {len(result.metadata)} é¡¹")

            return raw_response

        except Exception as e:
            print(f"\nâŒ Scrape APIè°ƒç”¨å¤±è´¥: {e}")
            return {
                "success": False,
                "method": "scrape",
                "url": test_url,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def test_firecrawl_scrape_2(self) -> dict:
        """æµ‹è¯•Firecrawl scrapeæ–¹æ³•ï¼ˆçˆ¬å–ç¬¬äºŒä¸ªé¡µé¢ï¼‰"""
        print("\n" + "="*70)
        print("ğŸŒ æ­¥éª¤4: æµ‹è¯•Firecrawl Scrape APIï¼ˆçˆ¬å–ç¬¬äºŒä¸ªé¡µé¢ï¼‰")
        print("="*70)

        test_url = "https://www.iana.org/domains/reserved"

        try:
            print(f"ğŸ“ ç›®æ ‡URL: {test_url}")
            print(f"â±ï¸  å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
            print(f"ğŸ”„ æ­£åœ¨çˆ¬å–...")

            start_time = asyncio.get_event_loop().time()

            # è°ƒç”¨scrapeæ–¹æ³•
            result = await self.firecrawl_adapter.scrape(test_url)

            end_time = asyncio.get_event_loop().time()
            duration = end_time - start_time

            print(f"\nâœ… çˆ¬å–æˆåŠŸï¼")
            print(f"â±ï¸  è€—æ—¶: {duration:.2f}ç§’")

            # æ„é€ åŸå§‹å“åº”æ•°æ®
            raw_response = {
                "success": True,
                "method": "scrape",
                "url": test_url,
                "timestamp": datetime.now().isoformat(),
                "duration_seconds": round(duration, 2),
                "data": {
                    "url": result.url,
                    "content": result.content[:500] + "..." if len(result.content) > 500 else result.content,
                    "content_length": len(result.content),
                    "markdown": result.markdown[:500] + "..." if result.markdown and len(result.markdown) > 500 else result.markdown,
                    "markdown_length": len(result.markdown) if result.markdown else 0,
                    "html_length": len(result.html) if result.html else 0,
                    "metadata": result.metadata,
                    "has_screenshot": result.screenshot is not None
                }
            }

            print(f"\nğŸ“„ å“åº”æ•°æ®æ‘˜è¦:")
            print(f"   - URL: {result.url}")
            print(f"   - å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦")
            print(f"   - Markdowné•¿åº¦: {len(result.markdown) if result.markdown else 0} å­—ç¬¦")
            print(f"   - HTMLé•¿åº¦: {len(result.html) if result.html else 0} å­—ç¬¦")
            print(f"   - å…ƒæ•°æ®: {len(result.metadata)} é¡¹")

            return raw_response

        except Exception as e:
            print(f"\nâŒ Scrape APIè°ƒç”¨å¤±è´¥: {e}")
            return {
                "success": False,
                "method": "scrape",
                "url": test_url,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    def display_raw_response(self, response: dict, title: str):
        """æ˜¾ç¤ºåŸå§‹APIå“åº”"""
        print("\n" + "="*70)
        print(f"ğŸ“¦ {title}")
        print("="*70)
        print("\n```json")
        print(json.dumps(response, ensure_ascii=False, indent=2))
        print("```\n")

    async def run(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("\n" + "="*70)
        print("ğŸš€ å¯åŠ¨æ•°æ®åº“è¿æ¥å’ŒFirecrawl APIæµ‹è¯•")
        print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*70)

        try:
            # æ­¥éª¤1: è¿æ¥æ•°æ®åº“
            db_connected = await self.connect_database()

            if not db_connected:
                print("\nâš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Œä½†ç»§ç»­æµ‹è¯•Firecrawl API")

            # æ­¥éª¤2: åˆå§‹åŒ–Firecrawl
            firecrawl_ready = await self.init_firecrawl()

            if not firecrawl_ready:
                print("\nâŒ Firecrawlåˆå§‹åŒ–å¤±è´¥ï¼Œæµ‹è¯•ç»ˆæ­¢")
                return

            # æ­¥éª¤3: æµ‹è¯•Scrape API (ç¬¬1æ¬¡)
            scrape_response_1 = await self.test_firecrawl_scrape()

            # æ­¥éª¤4: æµ‹è¯•Scrape API (ç¬¬2æ¬¡)
            scrape_response_2 = await self.test_firecrawl_scrape_2()

            # æ˜¾ç¤ºåŸå§‹å“åº”
            print("\n" + "="*70)
            print("ğŸ“Š åŸå§‹APIå“åº”æ•°æ®")
            print("="*70)

            self.display_raw_response(scrape_response_1, "åŸå§‹å“åº” #1: Scrape API (example.com)")
            self.display_raw_response(scrape_response_2, "åŸå§‹å“åº” #2: Scrape API (iana.org/domains/reserved)")

            # æµ‹è¯•æ€»ç»“
            print("\n" + "="*70)
            print("âœ… æµ‹è¯•å®Œæˆæ€»ç»“")
            print("="*70)

            print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
            print(f"   âœ… æ•°æ®åº“è¿æ¥: {'æˆåŠŸ' if db_connected else 'å¤±è´¥'}")
            print(f"   âœ… Firecrawlåˆå§‹åŒ–: {'æˆåŠŸ' if firecrawl_ready else 'å¤±è´¥'}")
            print(f"   âœ… Scrape API #1: {'æˆåŠŸ' if scrape_response_1.get('success') else 'å¤±è´¥'}")
            print(f"   âœ… Scrape API #2: {'æˆåŠŸ' if scrape_response_2.get('success') else 'å¤±è´¥'}")

            if db_connected:
                print(f"\nğŸ’¡ æ•°æ®åº“ä¿¡æ¯:")
                print(f"   - è¿æ¥URL: {settings.MONGODB_URL.split('@')[1] if '@' in settings.MONGODB_URL else 'localhost'}")
                print(f"   - æ•°æ®åº“å: {settings.MONGODB_DB_NAME}")

            print(f"\nğŸ’¡ Firecrawl APIä¿¡æ¯:")
            print(f"   - API Key: å·²é…ç½®")
            print(f"   - Scrape #1: {'âœ… æ­£å¸¸' if scrape_response_1.get('success') else 'âŒ å¤±è´¥'}")
            print(f"   - Scrape #2: {'âœ… æ­£å¸¸' if scrape_response_2.get('success') else 'âŒ å¤±è´¥'}")

            print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•æµç¨‹å·²å®Œæˆï¼")

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

        finally:
            await self.cleanup()

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\n" + "="*70)
        print("ğŸ§¹ æ¸…ç†èµ„æº")
        print("="*70)

        if self.mongo_client:
            self.mongo_client.close()
            print("âœ… MongoDBè¿æ¥å·²å…³é—­")

        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    tester = DatabaseAndFirecrawlTester()
    await tester.run()


if __name__ == "__main__":
    asyncio.run(main())
