"""
æ£€æŸ¥Firecrawl APIåŸå§‹å“åº”æ•°æ®

æŸ¥çœ‹firecrawl_raw_responsesè¡¨ä¸­å­˜å‚¨çš„åŸå§‹APIå“åº”
åˆ†æmarkdownå­—æ®µçš„å®é™…å†…å®¹
"""

import asyncio
import sys
import os
import json
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.infrastructure.database.connection import get_mongodb_database
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def check_firecrawl_raw_data():
    """æ£€æŸ¥FirecrawlåŸå§‹å“åº”æ•°æ®"""

    print(f"\n{'='*80}")
    print(f"Firecrawl API åŸå§‹å“åº”æ•°æ®æ£€æŸ¥")
    print(f"{'='*80}")

    try:
        db = await get_mongodb_database()
        raw_collection = db['firecrawl_raw_responses']

        # æŸ¥è¯¢æœ€è¿‘3æ¡è®°å½•
        cursor = raw_collection.find().sort("created_at", -1).limit(3)
        results = await cursor.to_list(length=3)

        if not results:
            print(f"âŒ æœªæ‰¾åˆ°åŸå§‹å“åº”è®°å½•")
            return

        print(f"\nğŸ“Š æ‰¾åˆ° {len(results)} æ¡åŸå§‹APIå“åº”")
        print(f"{'='*80}")

        # åˆ†ææ¯æ¡è®°å½•
        for idx, result in enumerate(results, 1):
            print(f"\n{'='*80}")
            print(f"ğŸ“„ åŸå§‹å“åº” #{idx}")
            print(f"{'='*80}")
            print(f"ID: {result.get('_id')}")
            print(f"Task ID: {result.get('task_id')}")
            print(f"URL: {result.get('result_url', 'N/A')[:80]}")
            print(f"API Endpoint: {result.get('api_endpoint', 'N/A')}")
            print(f"Created: {result.get('created_at', 'N/A')}")

            # æ‰“å°å®Œæ•´è®°å½•ç»“æ„
            print(f"\nğŸ” å®Œæ•´è®°å½•ç»“æ„:")
            print(f"   æ‰€æœ‰å­—æ®µ: {list(result.keys())}")

            # è·å–åŸå§‹æ•°æ®ï¼ˆå­—æ®µåæ˜¯ raw_responseï¼‰
            raw_data = result.get('raw_response', {})

            print(f"\nğŸ“¦ åŸå§‹å“åº”æ•°æ®ç»“æ„:")
            print(f"   ç±»å‹: {type(raw_data)}")
            if isinstance(raw_data, dict):
                print(f"   é¡¶å±‚å­—æ®µ: {list(raw_data.keys())}")

            # æ£€æŸ¥markdownå­—æ®µ
            if 'markdown' in raw_data:
                markdown = raw_data['markdown']
                print(f"\nğŸ“ Markdown å­—æ®µ:")
                print(f"   ç±»å‹: {type(markdown)}")
                print(f"   é•¿åº¦: {len(markdown) if isinstance(markdown, str) else 'N/A'} å­—ç¬¦")

                if isinstance(markdown, str):
                    # æ˜¾ç¤ºå‰500å­—ç¬¦
                    preview = markdown[:500]
                    print(f"\n   é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
                    print(f"   {'-'*76}")
                    for line in preview.split('\n')[:15]:
                        print(f"   {line[:76]}")
                    print(f"   {'-'*76}")

                    # åˆ†æå†…å®¹
                    print(f"\n   å†…å®¹åˆ†æ:")
                    print(f"   - æ˜¯å¦ä»¥å›¾ç‰‡å¼€å¤´: {'æ˜¯' if markdown.strip().startswith('![') else 'å¦'}")
                    print(f"   - æ˜¯å¦åŒ…å«å¯¼èˆªé“¾æ¥: {'æ˜¯' if '[é¦–é¡µ]' in markdown or '[ä¸»è¦èŒè´£]' in markdown else 'å¦'}")
                    print(f"   - æ ‡é¢˜æ•°é‡: {markdown.count('# ')}")
                    print(f"   - é“¾æ¥æ•°é‡: {markdown.count('[')}")
                    print(f"   - æ®µè½æ•°é‡: {markdown.count(chr(10) + chr(10))}")
                    print(f"   - åˆ—è¡¨é¡¹æ•°é‡: {markdown.count('- ') + markdown.count('* ')}")

            # æ£€æŸ¥metadataå­—æ®µ
            if 'metadata' in raw_data:
                metadata = raw_data['metadata']
                print(f"\nğŸ” Metadata å­—æ®µ:")
                print(f"   å­—æ®µ: {list(metadata.keys()) if isinstance(metadata, dict) else 'N/A'}")

                # æ˜¾ç¤ºéƒ¨åˆ†metadataå†…å®¹
                if isinstance(metadata, dict):
                    for key in ['title', 'description', 'language', 'author', 'og:type']:
                        if key in metadata:
                            value = metadata[key]
                            print(f"   - {key}: {str(value)[:60]}")

            # æ£€æŸ¥htmlå­—æ®µ
            if 'html' in raw_data:
                html = raw_data['html']
                print(f"\nğŸ“„ HTML å­—æ®µ:")
                print(f"   é•¿åº¦: {len(html) if isinstance(html, str) else 'N/A'} å­—ç¬¦")

            # æ£€æŸ¥å…¶ä»–å­—æ®µ
            for key in ['url', 'title', 'description', 'source']:
                if key in raw_data:
                    value = raw_data[key]
                    print(f"\n{key}: {str(value)[:100]}")

        # åˆ†æé…ç½®é—®é¢˜
        print(f"\n{'='*80}")
        print(f"ğŸ“Š é—®é¢˜åˆ†æ")
        print(f"{'='*80}")

        # æ£€æŸ¥ç¬¬ä¸€æ¡è®°å½•çš„markdownå†…å®¹ç‰¹å¾
        if results:
            first_result = results[0]
            raw_data = first_result.get('raw_data', {})
            markdown = raw_data.get('markdown', '')

            if isinstance(markdown, str):
                has_navigation = any(nav in markdown for nav in ['[é¦–é¡µ]', '[ä¸»è¦èŒè´£]', '[å¤–äº¤éƒ¨]', 'navigation', 'menu'])
                has_header_footer = any(hf in markdown.lower() for hf in ['footer', 'header', 'copyright', 'ç‰ˆæƒ'])
                starts_with_image = markdown.strip().startswith('![')

                print(f"\nå‘ç°çš„é—®é¢˜:")
                if has_navigation:
                    print(f"   âš ï¸  å†…å®¹åŒ…å«å¯¼èˆªèœå•é“¾æ¥")
                if has_header_footer:
                    print(f"   âš ï¸  å†…å®¹åŒ…å«é¡µçœ‰/é¡µè„š")
                if starts_with_image:
                    print(f"   âš ï¸  å†…å®¹ä»¥å›¾ç‰‡å¼€å¤´ï¼ˆå¯èƒ½æ˜¯logoæˆ–bannerï¼‰")

                if has_navigation or has_header_footer or starts_with_image:
                    print(f"\nå¯èƒ½åŸå› :")
                    print(f"   1. onlyMainContent é…ç½®æœªç”Ÿæ•ˆ")
                    print(f"   2. Firecrawl API çš„ä¸»å†…å®¹è¯†åˆ«ç®—æ³•å¯¹æŸäº›ç½‘ç«™æ•ˆæœä¸å¥½")
                    print(f"   3. éœ€è¦ä½¿ç”¨ excludeTags æ’é™¤ç‰¹å®šæ ‡ç­¾")
                    print(f"   4. éœ€è¦ä½¿ç”¨ includeTags é™åˆ¶åªæå–ç‰¹å®šæ ‡ç­¾")

                    print(f"\nå»ºè®®æ–¹æ¡ˆ:")
                    print(f"   1. æ£€æŸ¥ scrapeOptions.onlyMainContent æ˜¯å¦æ­£ç¡®ä¼ é€’ç»™ API")
                    print(f"   2. æ·»åŠ  excludeTags: ['nav', 'header', 'footer']")
                    print(f"   3. å°è¯•ä½¿ç”¨ includeTags: ['article', 'main', 'p']")
                    print(f"   4. å¯¹æ¯” Search API å’Œ Scrape API è¿”å›çš„å†…å®¹å·®å¼‚")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def main():
    """ä¸»å‡½æ•°"""
    await check_firecrawl_raw_data()


if __name__ == "__main__":
    asyncio.run(main())
