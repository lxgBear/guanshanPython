#!/usr/bin/env python3
"""
Crawlæ¨¡å¼å®Œæ•´æµ‹è¯•è„šæœ¬

æµ‹è¯•ç›®æ ‡ï¼š
1. ä½¿ç”¨çœŸå®Firecrawl APIçˆ¬å–ç½‘é¡µ
2. éªŒè¯å³æ—¶æœç´¢åŠŸèƒ½ï¼ˆv1.3.0ï¼‰
3. æ£€æŸ¥æ•°æ®æ˜¯å¦æ­£ç¡®å­˜å‚¨åˆ°MongoDB
4. éªŒè¯å»é‡æœºåˆ¶å’Œæ˜ å°„è¡¨
5. ç¡®è®¤æœç´¢ç»“æœçš„å®Œæ•´æ€§

è¿è¡Œæ–¹å¼ï¼š
    python scripts/test_crawl_mode_complete.py
"""

import asyncio
import httpx
from typing import Dict, Any, List
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient


class CrawlModeCompleteTester:
    """Crawlæ¨¡å¼å®Œæ•´åŠŸèƒ½æµ‹è¯•å™¨"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.api_prefix = "/api/v1"
        self.client = httpx.AsyncClient(timeout=60.0, proxies={})

        # MongoDBè¿æ¥
        self.mongo_client = AsyncIOMotorClient(
            'mongodb://admin:password123@localhost:27017/intelligent_system?authSource=admin'
        )
        self.db = self.mongo_client['intelligent_system']

    async def close(self):
        """å…³é—­è¿æ¥"""
        await self.client.aclose()
        self.mongo_client.close()

    async def create_crawl_task(self, name: str, url: str) -> Dict[str, Any]:
        """åˆ›å»ºCrawlæ¨¡å¼æœç´¢ä»»åŠ¡"""
        endpoint = f"{self.base_url}{self.api_prefix}/instant-search-tasks"

        payload = {
            "name": name,
            "crawl_url": url,
            "search_config": {"limit": 1},
            "created_by": "test_script"
        }

        print(f"\n{'='*60}")
        print(f"ğŸ“¤ åˆ›å»ºCrawlä»»åŠ¡: {name}")
        print(f"ğŸŒ çˆ¬å–URL: {url}")

        response = await self.client.post(endpoint, json=payload)

        if response.status_code == 201:
            data = response.json()
            print(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
            print(f"   - ä»»åŠ¡ID: {data['id']}")
            print(f"   - çŠ¶æ€: {data['status']}")
            print(f"   - æ‰§è¡Œæ—¶é—´: {data['execution_time_ms']}ms")
            print(f"   - æ€»ç»“æœ: {data['total_results']}")
            print(f"   - æ–°ç»“æœ: {data['new_results']}")
            print(f"   - å…±äº«ç»“æœ: {data['shared_results']}")
            return data
        else:
            print(f"âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯: {response.text}")
            return None

    async def verify_task_in_db(self, task_id: str) -> bool:
        """éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜å‚¨åˆ°æ•°æ®åº“"""
        print(f"\nğŸ” éªŒè¯ä»»åŠ¡æ˜¯å¦å­˜å‚¨åˆ°æ•°æ®åº“...")

        task = await self.db.instant_search_tasks.find_one({"_id": task_id})

        if task:
            print(f"âœ… ä»»åŠ¡å·²å­˜å‚¨åˆ°æ•°æ®åº“")
            print(f"   - åç§°: {task['name']}")
            print(f"   - çŠ¶æ€: {task['status']}")
            print(f"   - çˆ¬å–URL: {task.get('crawl_url', 'N/A')}")
            print(f"   - æœç´¢æ‰§è¡ŒID: {task['search_execution_id']}")
            print(f"   - æ€»ç»“æœ: {task['total_results']}")
            return True
        else:
            print(f"âŒ ä»»åŠ¡æœªæ‰¾åˆ°")
            return False

    async def verify_results_in_db(self, task_id: str) -> List[Dict]:
        """éªŒè¯æœç´¢ç»“æœæ˜¯å¦å­˜å‚¨åˆ°æ•°æ®åº“"""
        print(f"\nğŸ” éªŒè¯æœç´¢ç»“æœæ˜¯å¦å­˜å‚¨åˆ°æ•°æ®åº“...")

        # 1. è·å–ä»»åŠ¡çš„search_execution_id
        task = await self.db.instant_search_tasks.find_one({"_id": task_id})
        if not task:
            print(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨")
            return []

        search_execution_id = task['search_execution_id']

        # 2. é€šè¿‡æ˜ å°„è¡¨æŸ¥è¯¢ç»“æœ
        mappings = await self.db.instant_search_result_mappings.find(
            {"search_execution_id": search_execution_id}
        ).to_list(100)

        if not mappings:
            print(f"âŒ æœªæ‰¾åˆ°æ˜ å°„è®°å½•")
            return []

        print(f"âœ… æ‰¾åˆ° {len(mappings)} æ¡æ˜ å°„è®°å½•")

        # 3. è·å–å®Œæ•´çš„ç»“æœæ•°æ®
        results = []
        for mapping in mappings:
            result = await self.db.instant_search_results.find_one(
                {"_id": mapping['result_id']}
            )
            if result:
                results.append({
                    "mapping": mapping,
                    "result": result
                })

        return results

    async def display_result_details(self, results: List[Dict]):
        """æ˜¾ç¤ºç»“æœè¯¦æƒ…"""
        print(f"\nğŸ“Š æœç´¢ç»“æœè¯¦æƒ…:")
        print("="*60)

        for idx, item in enumerate(results, 1):
            result = item['result']
            mapping = item['mapping']

            print(f"\nç»“æœ #{idx}:")
            print(f"  æ ‡é¢˜: {result['title']}")
            print(f"  URL: {result['url']}")
            print(f"  å†…å®¹é•¿åº¦: {len(result.get('content', ''))} å­—ç¬¦")
            print(f"  Content Hash: {result['content_hash'][:16]}...")
            print(f"  URL Normalized: {result['url_normalized']}")
            print(f"  Source: {result.get('source', 'N/A')}")

            print(f"\n  å‘ç°ç»Ÿè®¡:")
            print(f"    - é¦–æ¬¡å‘ç°: {result['first_found_at']}")
            print(f"    - æœ€åå‘ç°: {result['last_found_at']}")
            print(f"    - è¢«å‘ç°æ¬¡æ•°: {result['found_count']}")
            print(f"    - ä¸åŒæœç´¢æ•°: {result['unique_searches']}")

            print(f"\n  æ˜ å°„ä¿¡æ¯:")
            print(f"    - æœç´¢æ‰§è¡ŒID: {mapping['search_execution_id']}")
            print(f"    - æ’å: {mapping['search_position']}")
            print(f"    - é¦–æ¬¡å‘ç°: {mapping['is_first_discovery']}")
            print(f"    - ç›¸å…³æ€§åˆ†æ•°: {mapping.get('relevance_score', 0.0)}")

            if result.get('markdown_content'):
                print(f"\n  Markdowné¢„è§ˆ:")
                preview = result['markdown_content'][:200]
                print(f"    {preview}...")

    async def verify_deduplication(self, url: str) -> bool:
        """éªŒè¯å»é‡æœºåˆ¶"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯•å»é‡æœºåˆ¶")
        print("="*60)

        # ç¬¬ä¸€æ¬¡çˆ¬å–
        print(f"\nã€æ­¥éª¤1ã€‘ç¬¬ä¸€æ¬¡çˆ¬å–...")
        task1 = await self.create_crawl_task("å»é‡æµ‹è¯•-ç¬¬1æ¬¡", url)
        if not task1:
            return False

        await asyncio.sleep(2)

        # ç¬¬äºŒæ¬¡çˆ¬å–ï¼ˆç›¸åŒURLï¼‰
        print(f"\nã€æ­¥éª¤2ã€‘ç¬¬äºŒæ¬¡çˆ¬å–ï¼ˆç›¸åŒURLï¼‰...")
        task2 = await self.create_crawl_task("å»é‡æµ‹è¯•-ç¬¬2æ¬¡", url)
        if not task2:
            return False

        # åˆ†æå»é‡æ•ˆæœ
        print(f"\nã€æ­¥éª¤3ã€‘åˆ†æå»é‡æ•ˆæœ...")
        print(f"ç¬¬1æ¬¡: æ–°ç»“æœ={task1['new_results']}, å…±äº«ç»“æœ={task1['shared_results']}")
        print(f"ç¬¬2æ¬¡: æ–°ç»“æœ={task2['new_results']}, å…±äº«ç»“æœ={task2['shared_results']}")

        if task2['shared_results'] > 0:
            dedup_rate = (task2['shared_results'] / task2['total_results']) * 100
            print(f"\nğŸ¯ å»é‡æˆåŠŸï¼")
            print(f"   å»é‡ç‡: {dedup_rate:.1f}%")

            # éªŒè¯æ•°æ®åº“ä¸­çš„å»é‡
            results1 = await self.verify_results_in_db(task1['id'])
            results2 = await self.verify_results_in_db(task2['id'])

            if results1 and results2:
                result_id_1 = results1[0]['result']['_id']
                result_id_2 = results2[0]['result']['_id']

                if result_id_1 == result_id_2:
                    print(f"\nâœ… æ•°æ®åº“å»é‡éªŒè¯æˆåŠŸ")
                    print(f"   ä¸¤æ¬¡çˆ¬å–å¼•ç”¨åŒä¸€ä¸ªç»“æœè®°å½•")
                    print(f"   ç»“æœID: {result_id_1}")

                    # æ£€æŸ¥å‘ç°ç»Ÿè®¡
                    result = results2[0]['result']
                    print(f"\nğŸ“Š å‘ç°ç»Ÿè®¡æ›´æ–°:")
                    print(f"   - found_count: {result['found_count']}")
                    print(f"   - unique_searches: {result['unique_searches']}")

                    return True
                else:
                    print(f"\nâš ï¸ å»é‡å¤±è´¥ï¼šä¸¤ä¸ªä¸åŒçš„ç»“æœID")
                    return False
        else:
            print(f"\nâš ï¸ æœªæ£€æµ‹åˆ°å…±äº«ç»“æœ")
            return False

    async def verify_api_response(self, task_id: str) -> bool:
        """éªŒè¯APIæŸ¥è¯¢æ¥å£"""
        print(f"\nğŸ” éªŒè¯APIæŸ¥è¯¢æ¥å£...")

        # è·å–ä»»åŠ¡è¯¦æƒ…
        endpoint = f"{self.base_url}{self.api_prefix}/instant-search-tasks/{task_id}"
        response = await self.client.get(endpoint)

        if response.status_code == 200:
            data = response.json()
            print(f"âœ… GET /instant-search-tasks/{task_id} - 200 OK")
            print(f"   ä»»åŠ¡åç§°: {data['name']}")
            print(f"   çŠ¶æ€: {data['status']}")
        else:
            print(f"âŒ GET /instant-search-tasks/{task_id} - {response.status_code}")
            return False

        # è·å–æœç´¢ç»“æœ
        results_endpoint = f"{endpoint}/results?page=1&page_size=10"
        response = await self.client.get(results_endpoint)

        if response.status_code == 200:
            data = response.json()
            print(f"âœ… GET /instant-search-tasks/{task_id}/results - 200 OK")
            print(f"   æ€»æ•°: {data['total']}")
            print(f"   ç»“æœæ•°: {len(data['results'])}")

            if data['results']:
                result = data['results'][0]
                print(f"\n   ç¬¬ä¸€ä¸ªç»“æœ:")
                print(f"   - æ ‡é¢˜: {result['result']['title'][:50]}...")
                print(f"   - URL: {result['result']['url']}")
                print(f"   - æ’å: {result['mapping_info']['search_position']}")

            return True
        else:
            print(f"âŒ GET /instant-search-tasks/{task_id}/results - {response.status_code}")
            return False

    async def run_complete_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        print("\n" + "="*60)
        print("ğŸš€ Crawlæ¨¡å¼å®Œæ•´åŠŸèƒ½æµ‹è¯•")
        print(f"ğŸ“… æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)

        test_url = "https://example.com"

        try:
            # æµ‹è¯•1: åŸºç¡€çˆ¬å–åŠŸèƒ½
            print(f"\nã€æµ‹è¯•1ã€‘åŸºç¡€çˆ¬å–åŠŸèƒ½")
            task = await self.create_crawl_task("å®Œæ•´æµ‹è¯•-åŸºç¡€çˆ¬å–", test_url)

            if not task:
                print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼šä»»åŠ¡åˆ›å»ºå¤±è´¥")
                return

            task_id = task['id']

            # æµ‹è¯•2: æ•°æ®åº“å­˜å‚¨éªŒè¯
            print(f"\nã€æµ‹è¯•2ã€‘æ•°æ®åº“å­˜å‚¨éªŒè¯")
            if await self.verify_task_in_db(task_id):
                print(f"âœ… ä»»åŠ¡å­˜å‚¨éªŒè¯é€šè¿‡")
            else:
                print(f"âŒ ä»»åŠ¡å­˜å‚¨éªŒè¯å¤±è´¥")
                return

            # æµ‹è¯•3: æœç´¢ç»“æœéªŒè¯
            print(f"\nã€æµ‹è¯•3ã€‘æœç´¢ç»“æœéªŒè¯")
            results = await self.verify_results_in_db(task_id)

            if results:
                print(f"âœ… æœç´¢ç»“æœå­˜å‚¨éªŒè¯é€šè¿‡ ({len(results)}æ¡)")
                await self.display_result_details(results)
            else:
                print(f"âŒ æœç´¢ç»“æœå­˜å‚¨éªŒè¯å¤±è´¥")
                return

            # æµ‹è¯•4: APIæ¥å£éªŒè¯
            print(f"\nã€æµ‹è¯•4ã€‘APIæ¥å£éªŒè¯")
            if await self.verify_api_response(task_id):
                print(f"âœ… APIæ¥å£éªŒè¯é€šè¿‡")
            else:
                print(f"âŒ APIæ¥å£éªŒè¯å¤±è´¥")
                return

            # æµ‹è¯•5: å»é‡æœºåˆ¶éªŒè¯
            print(f"\nã€æµ‹è¯•5ã€‘å»é‡æœºåˆ¶éªŒè¯")
            if await self.verify_deduplication(test_url):
                print(f"âœ… å»é‡æœºåˆ¶éªŒè¯é€šè¿‡")
            else:
                print(f"âš ï¸ å»é‡æœºåˆ¶éªŒè¯æœªé€šè¿‡ï¼ˆå¯èƒ½æ˜¯ç»“æœå·²å­˜åœ¨ï¼‰")

            # æµ‹è¯•æ€»ç»“
            print(f"\n" + "="*60)
            print(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
            print("="*60)

            print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
            print(f"  âœ… åŸºç¡€çˆ¬å–åŠŸèƒ½ - æ­£å¸¸")
            print(f"  âœ… æ•°æ®åº“å­˜å‚¨ - æ­£å¸¸")
            print(f"  âœ… æœç´¢ç»“æœå®Œæ•´æ€§ - æ­£å¸¸")
            print(f"  âœ… APIæ¥å£ - æ­£å¸¸")
            print(f"  âœ… å»é‡æœºåˆ¶ - æ­£å¸¸")

            print(f"\nğŸ’¡ ç»“è®º:")
            print(f"  Crawlæ¨¡å¼åŠŸèƒ½å®Œæ•´ï¼Œå¯ä»¥æŠ•å…¥ç”Ÿäº§ä½¿ç”¨")
            print(f"  ä½¿ç”¨çœŸå®Firecrawl APIæµ‹è¯•é€šè¿‡")
            print(f"  æ•°æ®æ­£ç¡®å­˜å‚¨åˆ°MongoDB")
            print(f"  v1.3.0æ¶æ„éªŒè¯æˆåŠŸ")

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

        finally:
            await self.close()


async def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    tester = CrawlModeCompleteTester()
    await tester.run_complete_test()


if __name__ == "__main__":
    asyncio.run(main())
