"""
æµ‹è¯•metadataå­—æ®µæå–åŠŸèƒ½

éªŒè¯ä¸‰ä¸ªæ‰§è¡Œå™¨ï¼ˆCrawlExecutor, ScrapeExecutor, SearchExecutorï¼‰
æ˜¯å¦æ­£ç¡®ä»metadataæå–å­—æ®µåˆ°SearchResultæ ‡å‡†å­—æ®µï¼Œ
å¹¶ç¡®è®¤metadataä¸å†å­˜å‚¨åˆ°æ•°æ®åº“ã€‚

è¿è¡Œæ–¹å¼:
    python scripts/test_metadata_field_extraction.py
"""

import asyncio
import sys
import os
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.database.repositories import SearchResultRepository
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def check_field_extraction():
    """æ£€æŸ¥æœ€è¿‘çš„æœç´¢ç»“æœå­—æ®µæå–æƒ…å†µ"""

    print("\n" + "="*80)
    print("metadataå­—æ®µæå–éªŒè¯æµ‹è¯•")
    print("="*80)

    try:
        # è¿æ¥æ•°æ®åº“
        db = await get_mongodb_database()
        collection = db['search_results']

        # è·å–æœ€è¿‘10æ¡è®°å½•
        cursor = collection.find().sort("created_at", -1).limit(10)
        results = await cursor.to_list(length=10)

        if not results:
            print("\nâš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰æœç´¢ç»“æœè®°å½•")
            return

        print(f"\nğŸ“Š åˆ†ææœ€è¿‘ {len(results)} æ¡æœç´¢ç»“æœ...")
        print("="*80)

        # ç»Ÿè®¡å­—æ®µæå–æƒ…å†µ
        field_stats = {
            'title': {'count': 0, 'non_empty': 0},
            'url': {'count': 0, 'non_empty': 0},
            'published_date': {'count': 0, 'non_empty': 0},
            'author': {'count': 0, 'non_empty': 0},
            'language': {'count': 0, 'non_empty': 0},
            'article_tag': {'count': 0, 'non_empty': 0},
            'article_published_time': {'count': 0, 'non_empty': 0},
            'source_url': {'count': 0, 'non_empty': 0},
            'http_status_code': {'count': 0, 'non_empty': 0},
            'search_position': {'count': 0, 'non_empty': 0},
            'markdown_content': {'count': 0, 'non_empty': 0},
            'html_content': {'count': 0, 'non_empty': 0},
            'metadata': {'count': 0, 'non_empty': 0, 'size_bytes': []}
        }

        # åˆ†ææ¯æ¡è®°å½•
        for idx, result in enumerate(results, 1):
            print(f"\nğŸ“„ è®°å½• #{idx}")
            print(f"   ID: {result.get('_id')}")
            print(f"   Task ID: {result.get('task_id')}")
            print(f"   Source: {result.get('source', 'N/A')}")
            print(f"   Created: {result.get('created_at', 'N/A')}")

            # æ£€æŸ¥æ¯ä¸ªå­—æ®µ
            for field in field_stats.keys():
                if field in result:
                    field_stats[field]['count'] += 1
                    value = result[field]

                    if field == 'metadata':
                        # ç‰¹æ®Šå¤„ç†metadataå­—æ®µ
                        if value:  # éç©º
                            field_stats[field]['non_empty'] += 1
                            import json
                            size = len(json.dumps(value))
                            field_stats[field]['size_bytes'].append(size)
                            print(f"   âš ï¸  metadata: å­˜åœ¨ (å¤§å°: {size} å­—èŠ‚)")
                        else:
                            print(f"   âœ… metadata: ç©º (å·²ä¼˜åŒ–)")
                    else:
                        # å…¶ä»–å­—æ®µ
                        if value is not None and value != '':
                            field_stats[field]['non_empty'] += 1
                            # æ˜¾ç¤ºç®€åŒ–å€¼
                            display_value = str(value)[:50]
                            if len(str(value)) > 50:
                                display_value += "..."
                            print(f"   âœ… {field}: {display_value}")
                        else:
                            print(f"   âŒ {field}: None/ç©º")

        # æ‰“å°ç»Ÿè®¡ç»“æœ
        print("\n" + "="*80)
        print("ğŸ“Š å­—æ®µæå–ç»Ÿè®¡")
        print("="*80)

        print(f"\n{'å­—æ®µå':<25} {'å­˜åœ¨ç‡':<12} {'æœ‰å€¼ç‡':<12} {'è¯´æ˜'}")
        print("-"*80)

        for field, stats in field_stats.items():
            if field == 'metadata':
                continue  # metadataå•ç‹¬å¤„ç†

            exist_rate = (stats['count'] / len(results)) * 100
            non_empty_rate = (stats['non_empty'] / len(results)) * 100 if stats['count'] > 0 else 0

            status = "âœ…" if non_empty_rate >= 80 else "âš ï¸" if non_empty_rate >= 50 else "âŒ"

            print(f"{field:<25} {exist_rate:>5.1f}% ({stats['count']}/{len(results)}) "
                  f"{non_empty_rate:>5.1f}% ({stats['non_empty']}/{len(results)}) {status}")

        # metadataå­—æ®µç‰¹æ®Šç»Ÿè®¡
        print("\n" + "-"*80)
        print("metadataå­—æ®µå­˜å‚¨æ£€æŸ¥:")
        metadata_stats = field_stats['metadata']

        if metadata_stats['non_empty'] == 0:
            print(f"   âœ… æ‰€æœ‰è®°å½•çš„metadataéƒ½ä¸ºç©º (å·²ä¼˜åŒ–)")
            print(f"   âœ… v2.1.0ä¼˜åŒ–ç”Ÿæ•ˆï¼šä¸å†å­˜å‚¨metadataå­—æ®µ")
        else:
            print(f"   âš ï¸  å‘ç° {metadata_stats['non_empty']}/{len(results)} æ¡è®°å½•ä»æœ‰metadata")
            if metadata_stats['size_bytes']:
                avg_size = sum(metadata_stats['size_bytes']) / len(metadata_stats['size_bytes'])
                total_size = sum(metadata_stats['size_bytes'])
                print(f"   å¹³å‡å¤§å°: {avg_size:.1f} å­—èŠ‚")
                print(f"   æ€»å¤§å°: {total_size} å­—èŠ‚ ({total_size/1024:.2f} KB)")
                print(f"   â„¹ï¸  è¿™äº›å¯èƒ½æ˜¯æ—§æ•°æ®ï¼Œæ–°æ•°æ®åº”è¯¥ä¸å­˜å‚¨metadata")

        # éªŒè¯ç»“è®º
        print("\n" + "="*80)
        print("âœ… éªŒè¯ç»“è®º")
        print("="*80)

        # æ ¸å¿ƒå­—æ®µæ£€æŸ¥
        core_fields = ['title', 'url', 'markdown_content']
        core_ok = all(field_stats[f]['non_empty'] / len(results) >= 0.9 for f in core_fields)

        # metadataå­—æ®µæ£€æŸ¥
        metadata_ok = metadata_stats['non_empty'] == 0

        # å…ƒæ•°æ®å­—æ®µæ£€æŸ¥ï¼ˆå…è®¸è¾ƒä½çš„æå–ç‡ï¼Œå› ä¸ºå–å†³äºæ•°æ®æºï¼‰
        metadata_fields = ['author', 'language', 'published_date', 'http_status_code']
        metadata_extracted = any(field_stats[f]['non_empty'] > 0 for f in metadata_fields)

        if core_ok and metadata_ok and metadata_extracted:
            print("âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼š")
            print("   1. âœ… æ ¸å¿ƒå­—æ®µï¼ˆtitle, url, markdown_contentï¼‰æå–æ­£å¸¸")
            print("   2. âœ… metadataå­—æ®µä¸å†å­˜å‚¨ï¼ˆv2.1.0ä¼˜åŒ–ç”Ÿæ•ˆï¼‰")
            print("   3. âœ… å…ƒæ•°æ®å­—æ®µï¼ˆauthor, languageç­‰ï¼‰æˆåŠŸæå–")
            return True
        else:
            print("âš ï¸  éƒ¨åˆ†éªŒè¯æœªé€šè¿‡ï¼š")
            if not core_ok:
                print("   âŒ æ ¸å¿ƒå­—æ®µæå–ç‡ä½äº90%")
            if not metadata_ok:
                print("   âš ï¸  ä»æœ‰è®°å½•å­˜å‚¨metadataï¼ˆå¯èƒ½æ˜¯æ—§æ•°æ®ï¼‰")
            if not metadata_extracted:
                print("   âŒ å…ƒæ•°æ®å­—æ®µæœªæå–")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_source_distribution():
    """æµ‹è¯•ä¸åŒæ¥æºçš„è®°å½•åˆ†å¸ƒ"""

    print("\n" + "="*80)
    print("ğŸ“Š æ•°æ®æ¥æºåˆ†å¸ƒ")
    print("="*80)

    try:
        db = await get_mongodb_database()
        collection = db['search_results']

        # èšåˆç»Ÿè®¡ä¸åŒsourceçš„è®°å½•æ•°
        pipeline = [
            {"$group": {
                "_id": "$source",
                "count": {"$sum": 1},
                "with_metadata": {
                    "$sum": {
                        "$cond": [
                            {"$or": [
                                {"$ne": ["$metadata", {}]},
                                {"$ne": ["$metadata", None]}
                            ]},
                            1,
                            0
                        ]
                    }
                }
            }},
            {"$sort": {"count": -1}}
        ]

        results = await collection.aggregate(pipeline).to_list(length=None)

        print(f"\n{'æ¥æº':<15} {'è®°å½•æ•°':<12} {'æœ‰metadata':<12} {'è¯´æ˜'}")
        print("-"*80)

        for result in results:
            source = result['_id'] or 'unknown'
            count = result['count']
            with_metadata = result['with_metadata']
            metadata_rate = (with_metadata / count) * 100 if count > 0 else 0

            status = "âœ…" if metadata_rate == 0 else "âš ï¸"

            print(f"{source:<15} {count:<12} {with_metadata:<12} {status} {metadata_rate:.1f}%")

        print("\nè¯´æ˜:")
        print("  âœ… 0% metadata: æ–°æ•°æ®ï¼Œå·²ä¼˜åŒ–")
        print("  âš ï¸ >0% metadata: æ—§æ•°æ®ï¼Œå°šæœªæ¸…ç†")

    except Exception as e:
        print(f"\nâŒ ç»Ÿè®¡å¤±è´¥: {e}")


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""

    print("\n" + "="*80)
    print("metadataå­—æ®µæå–ä¼˜åŒ–éªŒè¯æµ‹è¯•")
    print("ç‰ˆæœ¬: v2.1.0")
    print("æ—¥æœŸ:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("="*80)

    # æ‰§è¡Œæµ‹è¯•
    result = await check_field_extraction()

    # ç»Ÿè®¡æ¥æºåˆ†å¸ƒ
    await test_source_distribution()

    # æ€»ç»“
    print("\n" + "="*80)
    print("æµ‹è¯•å®Œæˆ")
    print("="*80)

    if result:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("   - metadataå­—æ®µä¸å†å­˜å‚¨åˆ°æ•°æ®åº“")
        print("   - æ‰€æœ‰å­—æ®µæ­£ç¡®ä»metadataæå–")
        print("   - ä¸‰ä¸ªæ‰§è¡Œå™¨å®ç°ä¸€è‡´")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹è¯¦ç»†ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
