"""
å†…éƒ¨ç³»ç»ŸAPIç«¯ç‚¹

è¿™äº›æ¥å£ä»…ä¾›ç³»ç»Ÿå†…éƒ¨ä½¿ç”¨ï¼Œä¸æš´éœ²åœ¨å‰ç«¯APIæ–‡æ¡£ä¸­ã€‚
åŒ…æ‹¬æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡ã€ç³»ç»ŸçŠ¶æ€æŸ¥è¯¢ç­‰ç®¡ç†åŠŸèƒ½ã€‚
"""

import os
from datetime import datetime
from typing import Dict, Any
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field

from src.core.domain.entities.search_task import SearchTask
from src.core.domain.entities.search_config import UserSearchConfig, SearchConfigManager
from src.core.domain.entities.search_result import SearchResult, SearchResultBatch, ResultStatus
from src.infrastructure.search.firecrawl_search_adapter import FirecrawlSearchAdapter
from src.infrastructure.crawlers.firecrawl_adapter import FirecrawlAdapter
from src.infrastructure.database.repositories import SearchTaskRepository, SearchResultRepository
from src.infrastructure.database.memory_repositories import InMemorySearchTaskRepository
from src.infrastructure.database.connection import get_mongodb_database
from src.utils.logger import get_logger

logger = get_logger(__name__)

# åˆ›å»ºå†…éƒ¨APIè·¯ç”±ï¼Œè®¾ç½®include_in_schema=Falseéšè—åœ¨æ–‡æ¡£ä¸­
router = APIRouter(
    prefix="/internal",
    tags=["ğŸ”§ ç³»ç»Ÿå†…éƒ¨æ¥å£"],
    include_in_schema=False  # éšè—åœ¨APIæ–‡æ¡£ä¸­
)

# ä»“å‚¨å®ä¾‹
task_repository = None
result_repository = None


async def get_task_repository():
    """è·å–ä»»åŠ¡ä»“å‚¨å®ä¾‹"""
    global task_repository
    if task_repository is None:
        try:
            await get_mongodb_database()
            task_repository = SearchTaskRepository()
            logger.info("ä½¿ç”¨MongoDBä»»åŠ¡ä»“å‚¨")
        except Exception as e:
            logger.warning(f"MongoDBä¸å¯ç”¨ï¼Œä½¿ç”¨å†…å­˜ä»“å‚¨: {e}")
            task_repository = InMemorySearchTaskRepository()
    return task_repository


async def get_result_repository():
    """è·å–ç»“æœä»“å‚¨å®ä¾‹"""
    global result_repository
    if result_repository is None:
        try:
            await get_mongodb_database()
            result_repository = SearchResultRepository()
            logger.info("ä½¿ç”¨MongoDBç»“æœä»“å‚¨")
        except Exception as e:
            logger.warning(f"MongoDBä¸å¯ç”¨ï¼Œç»“æœä¿å­˜å°†å¤±è´¥: {e}")
            raise HTTPException(503, "ç»“æœä»“å‚¨ä¸å¯ç”¨")
    return result_repository


# ==========================================
# Pydantic æ•°æ®æ¨¡å‹
# ==========================================

class TaskExecutionResponse(BaseModel):
    """ä»»åŠ¡æ‰§è¡Œå“åº”"""
    success: bool = Field(..., description="æ‰§è¡Œæ˜¯å¦æˆåŠŸ")
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    task_name: str = Field(..., description="ä»»åŠ¡åç§°")
    total_results: int = Field(..., description="è·å¾—ç»“æœæ•°é‡")
    execution_time_ms: int = Field(..., description="æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰")
    credits_used: int = Field(..., description="æ¶ˆè€—ç§¯åˆ†")
    is_test_mode: bool = Field(..., description="æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼")
    error_message: str = Field(None, description="é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰")
    results_preview: list = Field(..., description="ç»“æœé¢„è§ˆï¼ˆå‰5æ¡ï¼‰")


class SystemTestModeStatus(BaseModel):
    """ç³»ç»Ÿæµ‹è¯•æ¨¡å¼çŠ¶æ€"""
    is_test_mode: bool = Field(..., description="æ˜¯å¦å¯ç”¨æµ‹è¯•æ¨¡å¼")
    max_limit: int = Field(..., description="æœ€å¤§é™åˆ¶æ•°é‡")
    default_limit: int = Field(..., description="é»˜è®¤é™åˆ¶æ•°é‡")
    search_timeout_seconds: int = Field(..., description="æœç´¢è¶…æ—¶ç§’æ•°")
    max_credits_per_search: int = Field(..., description="æ¯æ¬¡æœç´¢æœ€å¤§ç§¯åˆ†")
    max_credits_per_day: int = Field(..., description="æ¯æ—¥æœ€å¤§ç§¯åˆ†")
    cache_enabled: bool = Field(..., description="æ˜¯å¦å¯ç”¨ç¼“å­˜")
    log_level: str = Field(..., description="æ—¥å¿—çº§åˆ«")


class SystemHealthStatus(BaseModel):
    """ç³»ç»Ÿå¥åº·çŠ¶æ€"""
    status: str = Field(..., description="ç³»ç»ŸçŠ¶æ€")
    timestamp: datetime = Field(..., description="æ£€æŸ¥æ—¶é—´")
    database_connected: bool = Field(..., description="æ•°æ®åº“è¿æ¥çŠ¶æ€")
    search_service_available: bool = Field(..., description="æœç´¢æœåŠ¡å¯ç”¨çŠ¶æ€")
    active_tasks_count: int = Field(..., description="æ´»è·ƒä»»åŠ¡æ•°é‡")
    total_tasks_count: int = Field(..., description="æ€»ä»»åŠ¡æ•°é‡")
    system_config: SystemTestModeStatus = Field(..., description="ç³»ç»Ÿé…ç½®")


# ==========================================
# APIç«¯ç‚¹
# ==========================================

@router.post(
    "/search-tasks/{task_id}/execute",
    response_model=TaskExecutionResponse,
    summary="æ‰‹åŠ¨æ‰§è¡Œæœç´¢ä»»åŠ¡",
    description="æ‰‹åŠ¨è§¦å‘æœç´¢ä»»åŠ¡æ‰§è¡Œï¼Œé€šå¸¸ç”¨äºæµ‹è¯•æˆ–ç³»ç»Ÿç®¡ç†ã€‚ä»…ä¾›å†…éƒ¨ä½¿ç”¨ï¼Œä¸å¯¹å‰ç«¯æš´éœ²ã€‚"
)
async def execute_task_manually(task_id: str):
    """
    æ‰‹åŠ¨æ‰§è¡Œæœç´¢ä»»åŠ¡

    ä¼˜å…ˆçº§é€»è¾‘ï¼š
    1. å¦‚æœ crawl_url å­˜åœ¨ â†’ ä½¿ç”¨ Firecrawl Scrape API (ç½‘å€çˆ¬å–)
    2. å¦‚æœ crawl_url ä¸å­˜åœ¨ â†’ ä½¿ç”¨ Firecrawl Search API (å…³é”®è¯æœç´¢)
    """
    repo = await get_task_repository()
    task = await repo.get_by_id(task_id)
    if not task:
        raise HTTPException(404, f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

    if not task.is_active:
        raise HTTPException(400, "ä»»åŠ¡æœªå¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œ")

    try:
        # ========================================
        # ä¼˜å…ˆçº§é€»è¾‘ï¼šcrawl_url ä¼˜å…ˆäº query
        # ========================================
        if task.crawl_url:
            # æ–¹æ¡ˆ1ï¼šä½¿ç”¨ Firecrawl Scrape API çˆ¬å–æŒ‡å®šç½‘å€
            logger.info(f"ğŸŒ ä½¿ç”¨ç½‘å€çˆ¬å–æ¨¡å¼: {task.crawl_url}")
            result_batch = await _execute_crawl_task(task)
        else:
            # æ–¹æ¡ˆ2ï¼šä½¿ç”¨ Firecrawl Search API å…³é”®è¯æœç´¢
            logger.info(f"ğŸ” ä½¿ç”¨å…³é”®è¯æœç´¢æ¨¡å¼: {task.query}")
            result_batch = await _execute_search_task(task)

        # ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“ï¼ˆå¦‚æœæœ‰ç»“æœï¼‰
        if result_batch.results:
            try:
                result_repo = await get_result_repository()
                await result_repo.save_results(result_batch.results)
                logger.info(f"ä¿å­˜ç»“æœæˆåŠŸ: {len(result_batch.results)}æ¡ (ä»»åŠ¡ID: {task_id})")
            except Exception as e:
                logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
                # ä¸æŠ›å‡ºå¼‚å¸¸,ç»§ç»­å¤„ç†ä»»åŠ¡ç»Ÿè®¡

        # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
        task.record_execution(
            success=result_batch.success,
            results_count=result_batch.returned_count,
            credits_used=result_batch.credits_used
        )

        # æ›´æ–°åˆ°ä»“å‚¨
        await repo.update(task)

        logger.info(f"æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡æˆåŠŸ: {task.name} (ID: {task_id})")

        # è¿”å›æ‰§è¡Œç»“æœ
        return TaskExecutionResponse(
            success=result_batch.success,
            task_id=task_id,
            task_name=task.name,
            total_results=result_batch.returned_count,
            execution_time_ms=result_batch.execution_time_ms,
            credits_used=result_batch.credits_used,
            is_test_mode=result_batch.is_test_mode,
            error_message=None,
            results_preview=[r.to_summary() for r in result_batch.results[:5]]
        )

    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")

        # è®°å½•å¤±è´¥ç»Ÿè®¡
        task.record_execution(success=False)
        await repo.update(task)

        # è¿”å›é”™è¯¯ä¿¡æ¯
        return TaskExecutionResponse(
            success=False,
            task_id=task_id,
            task_name=task.name,
            total_results=0,
            execution_time_ms=0,
            credits_used=0,
            is_test_mode=True,
            error_message=str(e),
            results_preview=[]
        )


async def _execute_search_task(task: SearchTask) -> SearchResultBatch:
    """æ‰§è¡Œå…³é”®è¯æœç´¢ä»»åŠ¡ï¼ˆä½¿ç”¨ Firecrawl Search APIï¼‰"""
    adapter = FirecrawlSearchAdapter()
    user_config = UserSearchConfig.from_json(task.search_config)
    result_batch = await adapter.search(
        query=task.query,
        user_config=user_config,
        task_id=str(task.id)
    )
    return result_batch


async def _execute_crawl_task(task: SearchTask) -> SearchResultBatch:
    """æ‰§è¡Œç½‘å€çˆ¬å–ä»»åŠ¡ï¼ˆä½¿ç”¨ Firecrawl Scrape APIï¼‰"""
    from datetime import datetime

    start_time = datetime.utcnow()

    # åˆ›å»ºçˆ¬è™«é€‚é…å™¨
    crawler = FirecrawlAdapter()

    # æ„å»ºçˆ¬å–é€‰é¡¹ï¼ˆä» search_config æå–ï¼‰
    scrape_options = {
        "wait_for": task.search_config.get("wait_for", 1000),
        "include_tags": task.search_config.get("include_tags"),
        "exclude_tags": task.search_config.get("exclude_tags", ["nav", "footer", "header"])
    }

    # æ‰§è¡Œçˆ¬å–
    crawl_result = await crawler.scrape(task.crawl_url, **scrape_options)

    # å°† CrawlResult è½¬æ¢ä¸º SearchResult
    search_result = SearchResult(
        task_id=str(task.id),
        title=crawl_result.metadata.get("title", task.crawl_url),
        url=crawl_result.url,
        content=crawl_result.content[:5000] if crawl_result.content else "",
        snippet=crawl_result.content[:200] if crawl_result.content else "",
        source="crawl",
        markdown_content=crawl_result.markdown[:5000] if crawl_result.markdown else None,
        html_content=crawl_result.html,
        metadata=crawl_result.metadata or {},
        relevance_score=1.0,  # ç›´æ¥çˆ¬å–çš„é¡µé¢ç›¸å…³æ€§ä¸º100%
        status=ResultStatus.PROCESSED
    )

    # åˆ›å»ºç»“æœæ‰¹æ¬¡
    batch = SearchResultBatch(
        task_id=str(task.id),
        query=f"URLçˆ¬å–: {task.crawl_url}",
        search_config=task.search_config,
        is_test_mode=False
    )
    batch.add_result(search_result)
    batch.total_count = 1
    batch.credits_used = 1  # Scrape API é€šå¸¸æ¶ˆè€—1ä¸ªç§¯åˆ†

    # è®¡ç®—æ‰§è¡Œæ—¶é—´
    end_time = datetime.utcnow()
    batch.execution_time_ms = int((end_time - start_time).total_seconds() * 1000)

    logger.info(f"âœ… ç½‘å€çˆ¬å–å®Œæˆ: {task.crawl_url}, è€—æ—¶: {batch.execution_time_ms}ms")

    return batch


@router.get(
    "/system/test-mode-status",
    response_model=SystemTestModeStatus,
    summary="è·å–ç³»ç»Ÿæµ‹è¯•æ¨¡å¼çŠ¶æ€",
    description="è·å–ç³»ç»Ÿæµ‹è¯•æ¨¡å¼é…ç½®å’ŒçŠ¶æ€ä¿¡æ¯ï¼Œç”¨äºç³»ç»Ÿç®¡ç†å’Œè°ƒè¯•ã€‚ä»…ä¾›å†…éƒ¨ä½¿ç”¨ã€‚"
)
async def get_system_test_mode_status():
    """è·å–ç³»ç»Ÿæµ‹è¯•æ¨¡å¼çŠ¶æ€"""
    is_test_mode = os.getenv("TEST_MODE", "false").lower() == "true"
    config_manager = SearchConfigManager()
    
    return SystemTestModeStatus(
        is_test_mode=is_test_mode,
        max_limit=config_manager.system_config.MAX_LIMIT,
        default_limit=config_manager.system_config.DEFAULT_LIMIT,
        search_timeout_seconds=config_manager.system_config.SEARCH_TIMEOUT_SECONDS,
        max_credits_per_search=config_manager.system_config.MAX_CREDITS_PER_SEARCH,
        max_credits_per_day=config_manager.system_config.MAX_CREDITS_PER_DAY,
        cache_enabled=config_manager.system_config.ENABLE_CACHE,
        log_level=config_manager.system_config.LOG_LEVEL
    )


@router.get(
    "/system/health",
    response_model=SystemHealthStatus,
    summary="ç³»ç»Ÿå¥åº·çŠ¶æ€æ£€æŸ¥",
    description="è·å–ç³»ç»Ÿæ•´ä½“å¥åº·çŠ¶æ€ï¼ŒåŒ…æ‹¬æ•°æ®åº“è¿æ¥ã€æœåŠ¡å¯ç”¨æ€§ã€ä»»åŠ¡ç»Ÿè®¡ç­‰ã€‚ç”¨äºç›‘æ§å’Œè¿ç»´ã€‚"
)
async def get_system_health():
    """ç³»ç»Ÿå¥åº·çŠ¶æ€æ£€æŸ¥"""
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    database_connected = False
    try:
        repo = await get_task_repository()
        database_connected = True
    except Exception as e:
        logger.warning(f"æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
    
    # æ£€æŸ¥æœç´¢æœåŠ¡
    search_service_available = False
    try:
        adapter = FirecrawlSearchAdapter()
        # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æœåŠ¡å¯ç”¨æ€§æ£€æŸ¥
        search_service_available = True
    except Exception as e:
        logger.warning(f"æœç´¢æœåŠ¡æ£€æŸ¥å¤±è´¥: {e}")
    
    # è·å–ä»»åŠ¡ç»Ÿè®¡
    active_tasks_count = 0
    total_tasks_count = 0
    
    if database_connected:
        try:
            repo = await get_task_repository()
            # è·å–ä»»åŠ¡ç»Ÿè®¡ï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼‰
            tasks, total = await repo.list_tasks(page=1, page_size=1000)
            total_tasks_count = total
            active_tasks_count = sum(1 for task in tasks if task.is_active)
        except Exception as e:
            logger.warning(f"ä»»åŠ¡ç»Ÿè®¡è·å–å¤±è´¥: {e}")
    
    # è·å–ç³»ç»Ÿé…ç½®
    system_config = await get_system_test_mode_status()
    
    # ç¡®å®šæ•´ä½“çŠ¶æ€
    if database_connected and search_service_available:
        overall_status = "healthy"
    elif database_connected or search_service_available:
        overall_status = "degraded"
    else:
        overall_status = "unhealthy"
    
    return SystemHealthStatus(
        status=overall_status,
        timestamp=datetime.utcnow(),
        database_connected=database_connected,
        search_service_available=search_service_available,
        active_tasks_count=active_tasks_count,
        total_tasks_count=total_tasks_count,
        system_config=system_config
    )


@router.post(
    "/system/maintenance/clear-old-results",
    summary="æ¸…ç†æ—§æœç´¢ç»“æœ",
    description="æ¸…ç†æŒ‡å®šå¤©æ•°ä¹‹å‰çš„æœç´¢ç»“æœæ•°æ®ï¼Œé‡Šæ”¾å­˜å‚¨ç©ºé—´ã€‚ä»…ä¾›ç³»ç»Ÿç®¡ç†ä½¿ç”¨ã€‚"
)
async def clear_old_results(days: int = 30):
    """æ¸…ç†æ—§æœç´¢ç»“æœ"""
    if days < 1:
        raise HTTPException(400, "æ¸…ç†å¤©æ•°å¿…é¡»å¤§äº0")
    
    try:
        from src.api.v1.endpoints.search_results_frontend import clear_task_results
        from datetime import timedelta
        
        # è¿™é‡Œåº”è¯¥å®ç°çœŸæ­£çš„æ•°æ®åº“æ¸…ç†é€»è¾‘
        # ç›®å‰åªæ˜¯ç¤ºä¾‹å®ç°
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        
        # è®°å½•æ“ä½œæ—¥å¿—
        logger.info(f"å¼€å§‹æ¸…ç† {days} å¤©å‰çš„æœç´¢ç»“æœï¼Œæˆªæ­¢æ—¥æœŸ: {cutoff_date}")
        
        # å®é™…æ¸…ç†é€»è¾‘ä¼šåœ¨è¿™é‡Œå®ç°
        cleaned_count = 0  # æ¨¡æ‹Ÿæ¸…ç†æ•°é‡
        
        return {
            "success": True,
            "message": f"æ¸…ç†å®Œæˆ",
            "days": days,
            "cutoff_date": cutoff_date,
            "cleaned_count": cleaned_count
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†æ—§ç»“æœå¤±è´¥: {e}")
        raise HTTPException(500, f"æ¸…ç†æ“ä½œå¤±è´¥: {str(e)}")


@router.get(
    "/system/stats/overview",
    summary="ç³»ç»Ÿç»Ÿè®¡æ¦‚è§ˆ",
    description="è·å–ç³»ç»Ÿæ•´ä½“ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä»»åŠ¡æ•°é‡ã€æ‰§è¡Œæƒ…å†µã€ç§¯åˆ†æ¶ˆè€—ç­‰ã€‚ç”¨äºç®¡ç†é¢æ¿ã€‚"
)
async def get_system_stats_overview():
    """ç³»ç»Ÿç»Ÿè®¡æ¦‚è§ˆ"""
    
    try:
        repo = await get_task_repository()
        
        # è·å–æ‰€æœ‰ä»»åŠ¡
        tasks, total_count = await repo.list_tasks(page=1, page_size=1000)
        
        # ç»Ÿè®¡å„ç§çŠ¶æ€
        active_count = sum(1 for task in tasks if task.is_active)
        total_executions = sum(task.execution_count for task in tasks)
        total_successes = sum(task.success_count for task in tasks)
        total_credits = sum(task.total_credits_used for task in tasks)
        total_results = sum(task.total_results for task in tasks)
        
        # è®¡ç®—å¹³å‡æˆåŠŸç‡
        avg_success_rate = (total_successes / total_executions * 100) if total_executions > 0 else 0
        
        return {
            "total_tasks": total_count,
            "active_tasks": active_count,
            "inactive_tasks": total_count - active_count,
            "total_executions": total_executions,
            "total_successes": total_successes,
            "average_success_rate": round(avg_success_rate, 2),
            "total_results": total_results,
            "total_credits_used": total_credits,
            "average_results_per_execution": round(total_results / total_executions, 2) if total_executions > 0 else 0,
            "timestamp": datetime.utcnow()
        }
        
    except Exception as e:
        logger.error(f"è·å–ç³»ç»Ÿç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(500, f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")