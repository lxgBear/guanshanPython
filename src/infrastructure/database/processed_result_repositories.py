"""AIå¤„ç†ç»“æœæ•°æ®ä»“å‚¨

v2.0.0 èŒè´£åˆ†ç¦»æ¶æ„ï¼š
- ç®¡ç† processed_results é›†åˆçš„æ‰€æœ‰æ•°æ®è®¿é—®æ“ä½œ
- æ”¯æŒçŠ¶æ€ç®¡ç†å’Œç”¨æˆ·æ“ä½œ
- æä¾›AIæœåŠ¡æ‰€éœ€çš„æŸ¥è¯¢å’Œæ›´æ–°æ¥å£

v2.0.1 å­—æ®µæ‰©å±•ï¼š
- æ”¯æŒåŸå§‹å­—æ®µï¼ˆtitle, url, contentç­‰ï¼‰
- æ”¯æŒAIæœåŠ¡æ–°å¢å­—æ®µï¼ˆcontent_zh, cls_resultsç­‰ï¼‰
"""

from datetime import datetime
from typing import List, Optional, Dict, Any
from motor.motor_asyncio import AsyncIOMotorDatabase

from src.core.domain.entities.processed_result import ProcessedResult, ProcessedStatus
from src.infrastructure.database.connection import get_mongodb_database
from src.utils.logger import get_logger

logger = get_logger(__name__)


class ProcessedResultRepository:
    """AIå¤„ç†ç»“æœä»“å‚¨ï¼ˆv2.0.0 æ–°å¢ï¼‰"""

    def __init__(self):
        self.collection_name = "processed_results"

    async def _get_collection(self):
        """è·å–é›†åˆ"""
        db = await get_mongodb_database()
        return db[self.collection_name]

    def _result_to_dict(self, result: ProcessedResult) -> Dict[str, Any]:
        """å°†ProcessedResultå®ä½“è½¬æ¢ä¸ºå­—å…¸ï¼ˆv2.0.1 æ‰©å±•ï¼‰"""
        return {
            "_id": str(result.id),
            "raw_result_id": str(result.raw_result_id),
            "task_id": str(result.task_id),
            # åŸå§‹å­—æ®µï¼ˆv2.0.1 æ–°å¢ï¼‰
            "title": result.title,
            "url": result.url,
            "source_url": result.source_url,
            "content": result.content,
            "snippet": result.snippet,
            "markdown_content": result.markdown_content,
            "html_content": result.html_content,
            "author": result.author,
            "published_date": result.published_date,
            "language": result.language,
            "source": result.source,
            "metadata": result.metadata,
            "quality_score": result.quality_score,
            "relevance_score": result.relevance_score,
            "search_position": result.search_position,
            # AIå¤„ç†æ•°æ®
            "content_zh": result.content_zh,
            "title_generated": result.title_generated,
            "translated_title": result.translated_title,
            "translated_content": result.translated_content,
            "summary": result.summary,
            "key_points": result.key_points,
            "cls_results": result.cls_results,
            "sentiment": result.sentiment,
            "categories": result.categories,
            "html_ctx_llm": result.html_ctx_llm,
            "html_ctx_regex": result.html_ctx_regex,
            "article_published_time": result.article_published_time,
            "article_tag": result.article_tag,
            # AIå…ƒæ•°æ®
            "ai_model": result.ai_model,
            "ai_processing_time_ms": result.ai_processing_time_ms,
            "ai_confidence_score": result.ai_confidence_score,
            "ai_metadata": result.ai_metadata,
            "processing_status": result.processing_status,
            "http_status_code": result.http_status_code,
            "is_test_data": result.is_test_data,
            # ç”¨æˆ·æ“ä½œ
            "status": result.status.value,
            "user_rating": result.user_rating,
            "user_notes": result.user_notes,
            # æ—¶é—´æˆ³
            "created_at": result.created_at,
            "processed_at": result.processed_at,
            "updated_at": result.updated_at,
            # é”™è¯¯å¤„ç†
            "processing_error": result.processing_error,
            "retry_count": result.retry_count
        }

    def _dict_to_result(self, data: Dict[str, Any]) -> ProcessedResult:
        """å°†å­—å…¸è½¬æ¢ä¸ºProcessedResultå®ä½“ï¼ˆv2.0.1 æ‰©å±•ï¼‰"""
        return ProcessedResult(
            id=str(data.get("_id", "")),
            raw_result_id=str(data.get("raw_result_id", "")),
            task_id=str(data.get("task_id", "")),
            # åŸå§‹å­—æ®µï¼ˆv2.0.1 æ–°å¢ï¼‰
            title=data.get("title", ""),
            url=data.get("url", ""),
            source_url=data.get("source_url", ""),
            content=data.get("content", ""),
            snippet=data.get("snippet"),
            markdown_content=data.get("markdown_content"),
            html_content=data.get("html_content"),
            author=data.get("author"),
            published_date=data.get("published_date"),
            language=data.get("language"),
            source=data.get("source", "web"),
            metadata=data.get("metadata", {}),
            quality_score=data.get("quality_score", 0.0),
            relevance_score=data.get("relevance_score", 0.0),
            search_position=data.get("search_position", 0),
            # AIå¤„ç†æ•°æ®
            content_zh=data.get("content_zh"),
            title_generated=data.get("title_generated"),
            translated_title=data.get("translated_title"),
            translated_content=data.get("translated_content"),
            summary=data.get("summary"),
            key_points=data.get("key_points", []),
            cls_results=data.get("cls_results"),
            sentiment=data.get("sentiment"),
            categories=data.get("categories", []),
            html_ctx_llm=data.get("html_ctx_llm"),
            html_ctx_regex=data.get("html_ctx_regex"),
            article_published_time=data.get("article_published_time"),
            article_tag=data.get("article_tag"),
            # AIå…ƒæ•°æ®
            ai_model=data.get("ai_model"),
            ai_processing_time_ms=data.get("ai_processing_time_ms", 0),
            ai_confidence_score=data.get("ai_confidence_score", 0.0),
            ai_metadata=data.get("ai_metadata", {}),
            processing_status=data.get("processing_status", "pending"),
            http_status_code=data.get("http_status_code"),
            is_test_data=data.get("is_test_data", False),
            # ç”¨æˆ·æ“ä½œ
            status=ProcessedStatus(data.get("status", "pending")),
            user_rating=data.get("user_rating"),
            user_notes=data.get("user_notes"),
            # æ—¶é—´æˆ³
            created_at=data.get("created_at", datetime.utcnow()),
            processed_at=data.get("processed_at"),
            updated_at=data.get("updated_at", datetime.utcnow()),
            # é”™è¯¯å¤„ç†
            processing_error=data.get("processing_error"),
            retry_count=data.get("retry_count", 0)
        )

    # ==================== åˆ›å»ºå’Œåˆå§‹åŒ– ====================

    async def create_pending_result(self, raw_result_id: str, task_id: str) -> ProcessedResult:
        """
        åˆ›å»ºå¾…å¤„ç†çš„ç»“æœè®°å½•ï¼ˆv2.0.1 å¤åˆ¶åŸå§‹å­—æ®µï¼‰

        ä» search_results è·å–åŸå§‹æ•°æ®å¹¶å¤åˆ¶åˆ° processed_resultsï¼Œ
        é¿å…å‰ç«¯æŸ¥è¯¢æ—¶éœ€è¦ JOIN æ“ä½œã€‚

        Args:
            raw_result_id: åŸå§‹ç»“æœIDï¼ˆæ¥è‡ªsearch_resultsï¼‰
            task_id: ä»»åŠ¡ID

        Returns:
            åˆ›å»ºçš„ProcessedResultå®ä½“
        """
        try:
            collection = await self._get_collection()

            # 1. ä» search_results æŸ¥è¯¢åŸå§‹æ•°æ®
            db = await get_mongodb_database()
            search_results_collection = db['search_results']
            raw_data = await search_results_collection.find_one({"_id": raw_result_id})

            # 2. åˆ›å»ºå¾…å¤„ç†ç»“æœå®ä½“ï¼Œå¤åˆ¶åŸå§‹å­—æ®µ
            if raw_data:
                result = ProcessedResult(
                    raw_result_id=raw_result_id,
                    task_id=task_id,
                    status=ProcessedStatus.PENDING,
                    # å¤åˆ¶åŸå§‹å­—æ®µï¼ˆv2.0.1ï¼‰
                    title=raw_data.get("title", ""),
                    url=raw_data.get("url", ""),
                    source_url=raw_data.get("source_url", ""),
                    content=raw_data.get("content", ""),
                    snippet=raw_data.get("snippet"),
                    markdown_content=raw_data.get("markdown_content"),
                    html_content=raw_data.get("html_content"),
                    author=raw_data.get("author"),
                    published_date=raw_data.get("published_date"),
                    language=raw_data.get("language"),
                    source=raw_data.get("source", "web"),
                    metadata=raw_data.get("metadata", {}),
                    quality_score=raw_data.get("quality_score", 0.0),
                    relevance_score=raw_data.get("relevance_score", 0.0),
                    search_position=raw_data.get("search_position", 0)
                )
            else:
                # å¦‚æœæ‰¾ä¸åˆ°åŸå§‹æ•°æ®ï¼Œåˆ›å»ºæœ€å°è®°å½•
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŸå§‹ç»“æœæ•°æ®: {raw_result_id}")
                result = ProcessedResult(
                    raw_result_id=raw_result_id,
                    task_id=task_id,
                    status=ProcessedStatus.PENDING
                )

            # 3. ä¿å­˜åˆ°æ•°æ®åº“
            result_dict = self._result_to_dict(result)
            await collection.insert_one(result_dict)

            logger.info(f"âœ… åˆ›å»ºå¾…å¤„ç†ç»“æœ: raw_result_id={raw_result_id}, processed_id={result.id}")
            return result

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºå¾…å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    # ==================== çŠ¶æ€ç®¡ç† ====================

    async def update_processing_status(
        self,
        result_id: str,
        status: ProcessedStatus,
        **kwargs
    ) -> bool:
        """
        æ›´æ–°å¤„ç†çŠ¶æ€

        Args:
            result_id: ç»“æœID
            status: æ–°çŠ¶æ€
            **kwargs: å…¶ä»–æ›´æ–°å­—æ®µï¼ˆå¦‚ processing_error, ai_model ç­‰ï¼‰

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            collection = await self._get_collection()

            update_data = {
                "status": status.value,
                "updated_at": datetime.utcnow()
            }

            # åˆå¹¶é¢å¤–å­—æ®µ
            update_data.update(kwargs)

            # ç‰¹æ®Šå¤„ç†ï¼šCOMPLETEDçŠ¶æ€è®¾ç½®å¤„ç†å®Œæˆæ—¶é—´
            if status == ProcessedStatus.COMPLETED and "processed_at" not in kwargs:
                update_data["processed_at"] = datetime.utcnow()

            result = await collection.update_one(
                {"_id": result_id},
                {"$set": update_data}
            )

            if result.modified_count > 0:
                logger.info(f"âœ… æ›´æ–°å¤„ç†çŠ¶æ€: {result_id} -> {status.value}")
                return True

            logger.warning(f"âš ï¸ å¤„ç†çŠ¶æ€æœªæ›´æ–°ï¼ˆè®°å½•ä¸å­˜åœ¨æˆ–æ— å˜åŒ–ï¼‰: {result_id}")
            return False

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¤„ç†çŠ¶æ€å¤±è´¥: {e}")
            raise

    async def save_ai_result(
        self,
        result_id: str,
        translated_title: Optional[str] = None,
        translated_content: Optional[str] = None,
        summary: Optional[str] = None,
        key_points: Optional[List[str]] = None,
        sentiment: Optional[str] = None,
        categories: Optional[List[str]] = None,
        ai_model: Optional[str] = None,
        processing_time_ms: Optional[int] = None,
        ai_confidence_score: Optional[float] = None
    ) -> bool:
        """
        ä¿å­˜AIå¤„ç†ç»“æœ

        Args:
            result_id: ç»“æœID
            translated_title: ç¿»è¯‘åçš„æ ‡é¢˜
            translated_content: ç¿»è¯‘åçš„å†…å®¹
            summary: AIæ‘˜è¦
            key_points: å…³é”®ç‚¹åˆ—è¡¨
            sentiment: æƒ…æ„Ÿåˆ†æ
            categories: åˆ†ç±»æ ‡ç­¾
            ai_model: AIæ¨¡å‹åç§°
            processing_time_ms: å¤„ç†è€—æ—¶
            ai_confidence_score: ç½®ä¿¡åº¦åˆ†æ•°

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            collection = await self._get_collection()

            update_data = {
                "status": ProcessedStatus.COMPLETED.value,
                "processed_at": datetime.utcnow(),
                "updated_at": datetime.utcnow()
            }

            # åªæ›´æ–°éNoneçš„å­—æ®µ
            if translated_title is not None:
                update_data["translated_title"] = translated_title
            if translated_content is not None:
                update_data["translated_content"] = translated_content
            if summary is not None:
                update_data["summary"] = summary
            if key_points is not None:
                update_data["key_points"] = key_points
            if sentiment is not None:
                update_data["sentiment"] = sentiment
            if categories is not None:
                update_data["categories"] = categories
            if ai_model is not None:
                update_data["ai_model"] = ai_model
            if processing_time_ms is not None:
                update_data["ai_processing_time_ms"] = processing_time_ms
            if ai_confidence_score is not None:
                update_data["ai_confidence_score"] = ai_confidence_score

            result = await collection.update_one(
                {"_id": result_id},
                {"$set": update_data}
            )

            if result.modified_count > 0:
                logger.info(f"âœ… ä¿å­˜AIå¤„ç†ç»“æœ: {result_id}")
                return True

            logger.warning(f"âš ï¸ AIç»“æœæœªä¿å­˜ï¼ˆè®°å½•ä¸å­˜åœ¨ï¼‰: {result_id}")
            return False

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜AIå¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    # ==================== æŸ¥è¯¢æ–¹æ³• ====================

    async def get_by_id(self, result_id: str) -> Optional[ProcessedResult]:
        """æ ¹æ®IDè·å–å¤„ç†ç»“æœ"""
        try:
            collection = await self._get_collection()
            data = await collection.find_one({"_id": result_id})

            if data:
                return self._dict_to_result(data)
            return None

        except Exception as e:
            logger.error(f"âŒ è·å–å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    async def get_by_raw_result_id(self, raw_result_id: str) -> Optional[ProcessedResult]:
        """æ ¹æ®åŸå§‹ç»“æœIDè·å–å¤„ç†ç»“æœ"""
        try:
            collection = await self._get_collection()
            data = await collection.find_one({"raw_result_id": raw_result_id})

            if data:
                return self._dict_to_result(data)
            return None

        except Exception as e:
            logger.error(f"âŒ æ ¹æ®åŸå§‹ç»“æœIDè·å–å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    async def get_by_task(
        self,
        task_id: str,
        status: Optional[ProcessedStatus] = None,
        page: int = 1,
        page_size: int = 20
    ) -> tuple[List[ProcessedResult], int]:
        """
        è·å–ä»»åŠ¡çš„å¤„ç†ç»“æœï¼ˆæ”¯æŒçŠ¶æ€ç­›é€‰å’Œåˆ†é¡µï¼‰

        Args:
            task_id: ä»»åŠ¡ID
            status: çŠ¶æ€ç­›é€‰ï¼ˆå¯é€‰ï¼‰
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡

        Returns:
            (ç»“æœåˆ—è¡¨, æ€»æ•°)
        """
        try:
            collection = await self._get_collection()

            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            query = {"task_id": task_id}
            if status is not None:
                query["status"] = status.value

            # æ€»æ•°
            total = await collection.count_documents(query)

            # åˆ†é¡µæŸ¥è¯¢
            skip = (page - 1) * page_size
            cursor = collection.find(query).sort("created_at", -1).skip(skip).limit(page_size)

            results = []
            async for data in cursor:
                results.append(self._dict_to_result(data))

            return results, total

        except Exception as e:
            logger.error(f"âŒ è·å–ä»»åŠ¡å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    # ==================== ç”¨æˆ·æ“ä½œ ====================

    async def update_user_action(
        self,
        result_id: str,
        status: Optional[ProcessedStatus] = None,
        user_rating: Optional[int] = None,
        user_notes: Optional[str] = None
    ) -> bool:
        """
        æ›´æ–°ç”¨æˆ·æ“ä½œï¼ˆç•™å­˜ã€åˆ é™¤ã€è¯„åˆ†ã€å¤‡æ³¨ï¼‰

        Args:
            result_id: ç»“æœID
            status: æ–°çŠ¶æ€ï¼ˆARCHIVEDæˆ–DELETEDï¼‰
            user_rating: ç”¨æˆ·è¯„åˆ†ï¼ˆ1-5ï¼‰
            user_notes: ç”¨æˆ·å¤‡æ³¨

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            collection = await self._get_collection()

            update_data = {"updated_at": datetime.utcnow()}

            if status is not None:
                update_data["status"] = status.value
            if user_rating is not None:
                if not 1 <= user_rating <= 5:
                    raise ValueError("ç”¨æˆ·è¯„åˆ†å¿…é¡»åœ¨1-5ä¹‹é—´")
                update_data["user_rating"] = user_rating
            if user_notes is not None:
                update_data["user_notes"] = user_notes

            result = await collection.update_one(
                {"_id": result_id},
                {"$set": update_data}
            )

            if result.modified_count > 0:
                logger.info(f"âœ… æ›´æ–°ç”¨æˆ·æ“ä½œ: {result_id}")
                return True

            logger.warning(f"âš ï¸ ç”¨æˆ·æ“ä½œæœªæ›´æ–°ï¼ˆè®°å½•ä¸å­˜åœ¨ï¼‰: {result_id}")
            return False

        except ValueError as e:
            logger.error(f"âŒ ç”¨æˆ·æ“ä½œå‚æ•°é”™è¯¯: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç”¨æˆ·æ“ä½œå¤±è´¥: {e}")
            raise

    # ==================== ç»Ÿè®¡å’Œåˆ†æ ====================

    async def get_status_statistics(self, task_id: str) -> Dict[str, int]:
        """
        è·å–ä»»åŠ¡çš„çŠ¶æ€ç»Ÿè®¡

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            çŠ¶æ€è®¡æ•°å­—å…¸ {"pending": 10, "completed": 5, ...}
        """
        try:
            collection = await self._get_collection()

            pipeline = [
                {"$match": {"task_id": task_id}},
                {"$group": {
                    "_id": "$status",
                    "count": {"$sum": 1}
                }}
            ]

            status_counts = {status.value: 0 for status in ProcessedStatus}

            async for doc in collection.aggregate(pipeline):
                status_counts[doc["_id"]] = doc["count"]

            return status_counts

        except Exception as e:
            logger.error(f"âŒ è·å–çŠ¶æ€ç»Ÿè®¡å¤±è´¥: {e}")
            raise

    async def get_failed_results(self, max_retry: int = 3) -> List[ProcessedResult]:
        """
        è·å–å¤±è´¥çš„ç»“æœï¼ˆç”¨äºé‡è¯•ï¼‰

        Args:
            max_retry: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            å¤±è´¥çš„ç»“æœåˆ—è¡¨ï¼ˆretry_count < max_retryï¼‰
        """
        try:
            collection = await self._get_collection()

            cursor = collection.find({
                "status": ProcessedStatus.FAILED.value,
                "retry_count": {"$lt": max_retry}
            }).sort("updated_at", 1)  # æŒ‰æ›´æ–°æ—¶é—´å‡åºï¼ˆä¼˜å…ˆé‡è¯•æ—§çš„ï¼‰

            results = []
            async for data in cursor:
                results.append(self._dict_to_result(data))

            if results:
                logger.info(f"ğŸ“‹ æ‰¾åˆ°{len(results)}ä¸ªå¯é‡è¯•çš„å¤±è´¥ç»“æœ")

            return results

        except Exception as e:
            logger.error(f"âŒ è·å–å¤±è´¥ç»“æœå¤±è´¥: {e}")
            raise

    # ==================== æ‰¹é‡æ“ä½œ ====================

    async def bulk_create_pending_results(
        self,
        raw_result_ids: List[str],
        task_id: str
    ) -> List[ProcessedResult]:
        """
        æ‰¹é‡åˆ›å»ºå¾…å¤„ç†ç»“æœï¼ˆv2.0.1 å¤åˆ¶åŸå§‹å­—æ®µï¼‰

        ä» search_results è·å–åŸå§‹æ•°æ®å¹¶å¤åˆ¶åˆ° processed_resultsï¼Œ
        é¿å…å‰ç«¯æŸ¥è¯¢æ—¶éœ€è¦ JOIN æ“ä½œã€‚

        Args:
            raw_result_ids: åŸå§‹ç»“æœIDåˆ—è¡¨
            task_id: ä»»åŠ¡ID

        Returns:
            åˆ›å»ºçš„ProcessedResultåˆ—è¡¨
        """
        try:
            collection = await self._get_collection()

            # 1. ä» search_results æŸ¥è¯¢åŸå§‹æ•°æ®
            db = await get_mongodb_database()
            search_results_collection = db['search_results']

            # æ‰¹é‡æŸ¥è¯¢åŸå§‹ç»“æœ
            search_results_cursor = search_results_collection.find({
                "_id": {"$in": raw_result_ids}
            })

            # æ„å»º ID -> åŸå§‹ç»“æœçš„æ˜ å°„
            search_results_map = {}
            async for raw_data in search_results_cursor:
                search_results_map[str(raw_data["_id"])] = raw_data

            # 2. åˆ›å»ºæ‰€æœ‰å¾…å¤„ç†ç»“æœå®ä½“ï¼Œå¤åˆ¶åŸå§‹å­—æ®µ
            results = []
            for raw_id in raw_result_ids:
                raw_data = search_results_map.get(raw_id)

                if raw_data:
                    # å¤åˆ¶åŸå§‹å­—æ®µåˆ° ProcessedResult
                    result = ProcessedResult(
                        raw_result_id=raw_id,
                        task_id=task_id,
                        status=ProcessedStatus.PENDING,
                        # å¤åˆ¶åŸå§‹å­—æ®µï¼ˆv2.0.1ï¼‰
                        title=raw_data.get("title", ""),
                        url=raw_data.get("url", ""),
                        source_url=raw_data.get("source_url", ""),
                        content=raw_data.get("content", ""),
                        snippet=raw_data.get("snippet"),
                        markdown_content=raw_data.get("markdown_content"),
                        html_content=raw_data.get("html_content"),
                        author=raw_data.get("author"),
                        published_date=raw_data.get("published_date"),
                        language=raw_data.get("language"),
                        source=raw_data.get("source", "web"),
                        metadata=raw_data.get("metadata", {}),
                        quality_score=raw_data.get("quality_score", 0.0),
                        relevance_score=raw_data.get("relevance_score", 0.0),
                        search_position=raw_data.get("search_position", 0)
                    )
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°åŸå§‹æ•°æ®ï¼Œåˆ›å»ºæœ€å°è®°å½•
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åŸå§‹ç»“æœæ•°æ®: {raw_id}")
                    result = ProcessedResult(
                        raw_result_id=raw_id,
                        task_id=task_id,
                        status=ProcessedStatus.PENDING
                    )

                results.append(result)

            # 3. æ‰¹é‡æ’å…¥
            if results:
                result_dicts = [self._result_to_dict(r) for r in results]
                await collection.insert_many(result_dicts)
                logger.info(f"âœ… æ‰¹é‡åˆ›å»ºå¾…å¤„ç†ç»“æœ: {len(results)}æ¡ï¼ˆå·²å¤åˆ¶åŸå§‹å­—æ®µï¼‰")

            return results

        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡åˆ›å»ºå¾…å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise

    async def delete_by_task(self, task_id: str) -> int:
        """
        åˆ é™¤ä»»åŠ¡çš„æ‰€æœ‰å¤„ç†ç»“æœ

        Args:
            task_id: ä»»åŠ¡ID

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            collection = await self._get_collection()
            result = await collection.delete_many({"task_id": task_id})

            logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä»»åŠ¡å¤„ç†ç»“æœ: {task_id}, åˆ é™¤æ•°é‡: {result.deleted_count}")
            return result.deleted_count

        except Exception as e:
            logger.error(f"âŒ åˆ é™¤ä»»åŠ¡å¤„ç†ç»“æœå¤±è´¥: {e}")
            raise
