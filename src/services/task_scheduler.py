"""
å®šæ—¶æœç´¢ä»»åŠ¡è°ƒåº¦å™¨æœåŠ¡

åŸºäºAPSchedulerå®ç°çš„åå°ä»»åŠ¡è°ƒåº¦å™¨ï¼Œè´Ÿè´£ï¼š
1. å®šæœŸæ£€æŸ¥å’Œæ‰§è¡Œæœç´¢ä»»åŠ¡
2. ç®¡ç†ä»»åŠ¡è°ƒåº¦ç”Ÿå‘½å‘¨æœŸ
3. æ‰§è¡Œç»“æœè®°å½•å’Œç»Ÿè®¡
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.jobstores.memory import MemoryJobStore

from src.core.domain.entities.search_task import SearchTask, TaskStatus, ScheduleInterval
from src.core.domain.entities.search_config import UserSearchConfig
from src.infrastructure.database.repositories import SearchTaskRepository, SearchResultRepository
from src.infrastructure.database.memory_repositories import InMemorySearchTaskRepository
from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.search.firecrawl_search_adapter import FirecrawlSearchAdapter
from src.services.interfaces.task_scheduler_interface import (
    ITaskScheduler, SchedulerStartError, SchedulerStopError,
    TaskScheduleError, TaskRemoveError, TaskUpdateError,
    TaskNotFoundError, TaskExecutionError
)
from src.utils.logger import get_logger

logger = get_logger(__name__)


class TaskSchedulerService(ITaskScheduler):
    """å®šæ—¶æœç´¢ä»»åŠ¡è°ƒåº¦æœåŠ¡"""
    
    def __init__(self):
        self.scheduler: Optional[AsyncIOScheduler] = None
        self.task_repository: Optional[SearchTaskRepository] = None
        self.result_repository: Optional[SearchResultRepository] = None
        self.search_adapter: Optional[FirecrawlSearchAdapter] = None
        self._is_running = False

        # é…ç½®è°ƒåº¦å™¨
        self._setup_scheduler()
    
    def _setup_scheduler(self):
        """é…ç½®APScheduler"""
        jobstores = {
            'default': MemoryJobStore()
        }
        
        executors = {
            'default': AsyncIOExecutor()
        }
        
        job_defaults = {
            'coalesce': False,  # ä¸åˆå¹¶å»¶è¿Ÿçš„ä»»åŠ¡
            'max_instances': 3,  # æœ€å¤§å¹¶å‘å®ä¾‹æ•°
            'misfire_grace_time': 300  # ä»»åŠ¡é”™è¿‡æ—¶é—´çš„å®¹å¿åº¦ï¼ˆç§’ï¼‰
        }
        
        self.scheduler = AsyncIOScheduler(
            jobstores=jobstores,
            executors=executors,
            job_defaults=job_defaults,
            timezone='Asia/Shanghai'
        )
    
    async def _get_task_repository(self):
        """è·å–ä»»åŠ¡ä»“å‚¨å®ä¾‹"""
        if self.task_repository is None:
            try:
                await get_mongodb_database()
                self.task_repository = SearchTaskRepository()
                logger.info("è°ƒåº¦å™¨ä½¿ç”¨MongoDBä»“å‚¨")
            except Exception as e:
                logger.warning(f"MongoDBä¸å¯ç”¨ï¼Œè°ƒåº¦å™¨ä½¿ç”¨å†…å­˜ä»“å‚¨: {e}")
                self.task_repository = InMemorySearchTaskRepository()
        return self.task_repository

    async def _get_result_repository(self):
        """è·å–ç»“æœä»“å‚¨å®ä¾‹"""
        if self.result_repository is None:
            try:
                await get_mongodb_database()
                self.result_repository = SearchResultRepository()
                logger.info("è°ƒåº¦å™¨ä½¿ç”¨MongoDBç»“æœä»“å‚¨")
            except Exception as e:
                logger.warning(f"MongoDBä¸å¯ç”¨ï¼Œæœç´¢ç»“æœå°†ä»…ä¿å­˜åˆ°å†…å­˜: {e}")
                self.result_repository = None
        return self.result_repository
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨æœåŠ¡"""
        if self._is_running:
            logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return
        
        try:
            # åˆå§‹åŒ–ä¾èµ–
            await self._get_task_repository()
            await self._get_result_repository()
            self.search_adapter = FirecrawlSearchAdapter()

            # å¯åŠ¨è°ƒåº¦å™¨
            self.scheduler.start()
            self._is_running = True
            
            # æ·»åŠ ä¸»æ£€æŸ¥ä»»åŠ¡ï¼ˆæ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼‰
            self.scheduler.add_job(
                self._check_and_execute_tasks,
                trigger=IntervalTrigger(minutes=1),
                id='main_task_checker',
                name='ä¸»ä»»åŠ¡æ£€æŸ¥å™¨',
                replace_existing=True
            )
            
            # åŠ è½½ç°æœ‰æ´»è·ƒä»»åŠ¡
            await self._load_active_tasks()
            
            logger.info("ğŸš€ å®šæ—¶æœç´¢ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨è°ƒåº¦å™¨å¤±è´¥: {e}")
            raise
    
    async def stop(self, deactivate_tasks: bool = False):
        """åœæ­¢è°ƒåº¦å™¨æœåŠ¡

        Args:
            deactivate_tasks: æ˜¯å¦åŒæ—¶åœç”¨æ‰€æœ‰æ´»è·ƒä»»åŠ¡ï¼ˆè®¾ç½®is_active=Falseï¼‰
        """
        if not self._is_running:
            return

        try:
            # å¦‚æœéœ€è¦åœç”¨æ‰€æœ‰ä»»åŠ¡ï¼Œå…ˆæ›´æ–°æ•°æ®åº“
            if deactivate_tasks:
                try:
                    repo = await self._get_task_repository()
                    # è·å–æ‰€æœ‰æ´»è·ƒä»»åŠ¡
                    active_tasks, _ = await repo.list_tasks(
                        page=1,
                        page_size=10000,
                        is_active=True
                    )

                    # å°†æ‰€æœ‰æ´»è·ƒä»»åŠ¡è®¾ç½®ä¸ºéæ´»è·ƒ
                    deactivated_count = 0
                    for task in active_tasks:
                        task.is_active = False
                        task.status = TaskStatus.DISABLED
                        task.updated_at = datetime.utcnow()
                        await repo.update(task)
                        deactivated_count += 1

                    if deactivated_count > 0:
                        logger.info(f"â¹ï¸ å·²åœç”¨ {deactivated_count} ä¸ªæ´»è·ƒä»»åŠ¡")
                except Exception as e:
                    logger.error(f"åœç”¨ä»»åŠ¡å¤±è´¥: {e}")
                    # ç»§ç»­æ‰§è¡Œè°ƒåº¦å™¨åœæ­¢æ“ä½œ

            self.scheduler.shutdown(wait=True)
            self._is_running = False
            logger.info("â¹ï¸ å®šæ—¶æœç´¢ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
        except Exception as e:
            logger.error(f"åœæ­¢è°ƒåº¦å™¨å¤±è´¥: {e}")
    
    async def _load_active_tasks(self):
        """åŠ è½½æ‰€æœ‰æ´»è·ƒçš„æœç´¢ä»»åŠ¡åˆ°è°ƒåº¦å™¨"""
        try:
            repo = await self._get_task_repository()
            
            # è·å–æ‰€æœ‰æ´»è·ƒä»»åŠ¡
            tasks, _ = await repo.list_tasks(
                page=1,
                page_size=1000,
                is_active=True
            )
            
            loaded_count = 0
            for task in tasks:
                try:
                    await self._schedule_task(task)
                    loaded_count += 1
                except Exception as e:
                    logger.error(f"åŠ è½½ä»»åŠ¡å¤±è´¥ {task.name} (ID: {task.id}): {e}")
            
            logger.info(f"ğŸ“‹ åŠ è½½äº† {loaded_count} ä¸ªæ´»è·ƒæœç´¢ä»»åŠ¡")
            
        except Exception as e:
            logger.error(f"åŠ è½½æ´»è·ƒä»»åŠ¡å¤±è´¥: {e}")
    
    async def _schedule_task(self, task: SearchTask):
        """å°†å•ä¸ªä»»åŠ¡æ·»åŠ åˆ°è°ƒåº¦å™¨"""
        try:
            # è·å–è°ƒåº¦é—´éš”é…ç½®
            interval = ScheduleInterval.from_value(task.schedule_interval)
            
            # åˆ›å»ºCronè§¦å‘å™¨
            trigger = CronTrigger.from_crontab(interval.cron_expression)
            
            # æ·»åŠ ä»»åŠ¡åˆ°è°ƒåº¦å™¨
            job_id = f"search_task_{task.id}"
            self.scheduler.add_job(
                self._execute_search_task,
                trigger=trigger,
                args=[task.id],
                id=job_id,
                name=f"æœç´¢ä»»åŠ¡: {task.name}",
                replace_existing=True
            )
            
            # æ›´æ–°ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            next_run = trigger.get_next_fire_time(None, datetime.now())
            if next_run:
                task.next_run_time = next_run
                repo = await self._get_task_repository()
                await repo.update(task)
            
            logger.info(f"âœ… ä»»åŠ¡å·²è°ƒåº¦: {task.name} - {interval.description}")
            
        except Exception as e:
            logger.error(f"è°ƒåº¦ä»»åŠ¡å¤±è´¥ {task.name}: {e}")
            raise
    
    async def add_task(self, task: SearchTask):
        """æ·»åŠ æ–°ä»»åŠ¡åˆ°è°ƒåº¦å™¨"""
        if not self._is_running:
            logger.warning("è°ƒåº¦å™¨æœªè¿è¡Œï¼Œæ— æ³•æ·»åŠ ä»»åŠ¡")
            return
        
        if task.is_active:
            await self._schedule_task(task)
            logger.info(f"â• æ–°å¢è°ƒåº¦ä»»åŠ¡: {task.name}")
    
    async def remove_task(self, task_id: str):
        """ä»è°ƒåº¦å™¨ç§»é™¤ä»»åŠ¡"""
        try:
            job_id = f"search_task_{task_id}"
            if self.scheduler.get_job(job_id):
                self.scheduler.remove_job(job_id)
                logger.info(f"â– ç§»é™¤è°ƒåº¦ä»»åŠ¡: {task_id}")
        except Exception as e:
            logger.error(f"ç§»é™¤ä»»åŠ¡å¤±è´¥ {task_id}: {e}")
    
    async def update_task(self, task: SearchTask):
        """æ›´æ–°è°ƒåº¦å™¨ä¸­çš„ä»»åŠ¡"""
        await self.remove_task(str(task.id))
        if task.is_active:
            await self.add_task(task)
    
    async def _check_and_execute_tasks(self):
        """ä¸»æ£€æŸ¥å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡éœ€è¦æ‰§è¡Œ"""
        try:
            logger.debug("ğŸ” æ‰§è¡Œä¸»ä»»åŠ¡æ£€æŸ¥...")
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–æ£€æŸ¥é€»è¾‘
            # æ¯”å¦‚æ£€æŸ¥å¤±è´¥ä»»åŠ¡çš„é‡è¯•ã€ä»»åŠ¡å¥åº·çŠ¶æ€ç­‰
            
            # è·å–è°ƒåº¦å™¨çŠ¶æ€
            jobs = self.scheduler.get_jobs()
            active_jobs = len([job for job in jobs if job.id != 'main_task_checker'])
            
            if active_jobs > 0:
                logger.debug(f"ğŸ“Š å½“å‰æ´»è·ƒä»»åŠ¡æ•°: {active_jobs}")
            
        except Exception as e:
            logger.error(f"ä¸»ä»»åŠ¡æ£€æŸ¥å¤±è´¥: {e}")
    
    async def _execute_search_task(self, task_id: str):
        """æ‰§è¡Œå•ä¸ªæœç´¢ä»»åŠ¡"""
        start_time = datetime.utcnow()
        logger.info(f"ğŸ” å¼€å§‹æ‰§è¡Œæœç´¢ä»»åŠ¡: {task_id}")
        
        try:
            # è·å–ä»»åŠ¡è¯¦æƒ…
            repo = await self._get_task_repository()
            task = await repo.get_by_id(task_id)
            
            if not task:
                logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
                return
            
            if not task.is_active:
                logger.info(f"ä»»åŠ¡å·²ç¦ç”¨ï¼Œè·³è¿‡æ‰§è¡Œ: {task.name}")
                return
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.last_executed_at = start_time
            
            # æ‰§è¡Œæœç´¢
            user_config = UserSearchConfig.from_json(task.search_config)
            result_batch = await self.search_adapter.search(
                query=task.query,
                user_config=user_config,
                task_id=str(task.id)
            )

            # ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“
            if result_batch.results:
                try:
                    result_repo = await self._get_result_repository()
                    if result_repo:
                        await result_repo.save_results(result_batch.results)
                        logger.info(f"âœ… æœç´¢ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“: {len(result_batch.results)}æ¡")
                    else:
                        logger.warning("âš ï¸ MongoDBä¸å¯ç”¨ï¼Œæœç´¢ç»“æœæœªä¿å­˜")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“å¤±è´¥: {e}")
                    # å¤±è´¥ä¸å½±å“ä»»åŠ¡ç»§ç»­æ‰§è¡Œ
            
            # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
            task.record_execution(
                success=result_batch.success,
                results_count=result_batch.returned_count,
                credits_used=result_batch.credits_used
            )
            
            # è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            interval = ScheduleInterval.from_value(task.schedule_interval)
            trigger = CronTrigger.from_crontab(interval.cron_expression)
            next_run = trigger.get_next_fire_time(None, datetime.now())
            if next_run:
                task.next_run_time = next_run
            
            # ä¿å­˜ä»»åŠ¡æ›´æ–°
            await repo.update(task)
            
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            
            logger.info(
                f"âœ… æœç´¢ä»»åŠ¡æ‰§è¡Œå®Œæˆ: {task.name} | "
                f"ç»“æœæ•°: {result_batch.returned_count} | "
                f"è€—æ—¶: {execution_time:.2f}s | "
                f"ä¸‹æ¬¡æ‰§è¡Œ: {next_run.strftime('%Y-%m-%d %H:%M:%S') if next_run else 'N/A'}"
            )
            
        except Exception as e:
            logger.error(f"âŒ æœç´¢ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {task_id}: {e}")
            
            # è®°å½•å¤±è´¥
            try:
                repo = await self._get_task_repository()
                task = await repo.get_by_id(task_id)
                if task:
                    task.record_execution(success=False)
                    await repo.update(task)
            except Exception as update_error:
                logger.error(f"æ›´æ–°å¤±è´¥ç»Ÿè®¡æ—¶å‡ºé”™: {update_error}")
    
    def is_running(self) -> bool:
        """æ£€æŸ¥è°ƒåº¦å™¨æ˜¯å¦åœ¨è¿è¡Œ"""
        return hasattr(self, '_is_running') and self._is_running
    
    async def pause_task(self, task_id: str) -> None:
        """æš‚åœæŒ‡å®šä»»åŠ¡"""
        try:
            job_id = f"search_task_{task_id}"
            if self.scheduler and self.scheduler.get_job(job_id):
                self.scheduler.pause_job(job_id)
                logger.info(f"â¸ï¸ æš‚åœä»»åŠ¡: {task_id}")
            else:
                raise TaskNotFoundError(f"ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}")
        except Exception as e:
            logger.error(f"æš‚åœä»»åŠ¡å¤±è´¥ {task_id}: {e}")
            if "not found" in str(e).lower():
                raise TaskNotFoundError(f"ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}")
            raise TaskScheduleError(f"æš‚åœä»»åŠ¡å¤±è´¥: {str(e)}")
    
    async def resume_task(self, task_id: str) -> None:
        """æ¢å¤æŒ‡å®šä»»åŠ¡"""
        try:
            job_id = f"search_task_{task_id}"
            if self.scheduler and self.scheduler.get_job(job_id):
                self.scheduler.resume_job(job_id)
                logger.info(f"â–¶ï¸ æ¢å¤ä»»åŠ¡: {task_id}")
            else:
                raise TaskNotFoundError(f"ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}")
        except Exception as e:
            logger.error(f"æ¢å¤ä»»åŠ¡å¤±è´¥ {task_id}: {e}")
            if "not found" in str(e).lower():
                raise TaskNotFoundError(f"ä»»åŠ¡æœªæ‰¾åˆ°: {task_id}")
            raise TaskScheduleError(f"æ¢å¤ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    async def execute_task_now(self, task_id: str) -> Dict[str, Any]:
        """ç«‹å³æ‰§è¡ŒæŒ‡å®šä»»åŠ¡ï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰"""
        try:
            # ç›´æ¥è°ƒç”¨æ‰§è¡Œå‡½æ•°
            await self._execute_search_task(task_id)
            
            # è·å–ä»»åŠ¡æ‰§è¡Œç»“æœ
            repo = await self._get_task_repository()
            task = await repo.get_by_id(task_id)
            
            if not task:
                raise TaskNotFoundError(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            
            return {
                "task_id": task_id,
                "task_name": task.name,
                "executed_at": datetime.utcnow().isoformat(),
                "status": "completed",
                "last_execution_success": task.success_count > 0,
                "execution_count": task.execution_count
            }
            
        except TaskNotFoundError:
            raise
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡å¤±è´¥ {task_id}: {e}")
            raise TaskExecutionError(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
    
    def get_task_next_run(self, task_id: str) -> Optional[datetime]:
        """è·å–æŒ‡å®šä»»åŠ¡çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´"""
        if not self.scheduler:
            return None
            
        job_id = f"search_task_{task_id}"
        job = self.scheduler.get_job(job_id)
        
        return job.next_run_time if job else None
    
    def get_running_tasks(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡åˆ—è¡¨"""
        if not self.scheduler:
            return {"running_tasks": [], "count": 0}
        
        running_jobs = self.scheduler.get_jobs()
        task_jobs = [
            job for job in running_jobs 
            if job.id.startswith('search_task_') and job.id != 'main_task_checker'
        ]
        
        return {
            "running_tasks": [
                {
                    "task_id": job.id.replace('search_task_', ''),
                    "task_name": job.name,
                    "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
                    "is_paused": job.next_run_time is None
                }
                for job in task_jobs
            ],
            "count": len(task_jobs)
        }

    def get_status(self) -> dict:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        if not self._is_running:
            return {
                "status": "stopped",
                "active_jobs": 0,
                "next_run_time": None
            }
        
        jobs = self.scheduler.get_jobs()
        active_jobs = [job for job in jobs if job.id != 'main_task_checker']
        
        # è·å–æœ€è¿‘çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
        next_run_times = [job.next_run_time for job in active_jobs if job.next_run_time]
        next_run = min(next_run_times) if next_run_times else None
        
        return {
            "status": "running",
            "active_jobs": len(active_jobs),
            "next_run_time": next_run.isoformat() if next_run else None,
            "jobs": [
                {
                    "id": job.id,
                    "name": job.name,
                    "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None
                }
                for job in active_jobs
            ]
        }


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_scheduler_instance: Optional[TaskSchedulerService] = None


async def get_scheduler() -> TaskSchedulerService:
    """è·å–è°ƒåº¦å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _scheduler_instance
    if _scheduler_instance is None:
        _scheduler_instance = TaskSchedulerService()
    return _scheduler_instance


@asynccontextmanager
async def scheduler_lifespan():
    """è°ƒåº¦å™¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨"""
    scheduler = await get_scheduler()
    try:
        await scheduler.start()
        yield scheduler
    finally:
        await scheduler.stop()


# ç”¨äºFastAPIåº”ç”¨çš„ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
async def start_scheduler():
    """å¯åŠ¨è°ƒåº¦å™¨ï¼ˆç”¨äºFastAPI startupäº‹ä»¶ï¼‰"""
    scheduler = await get_scheduler()
    await scheduler.start()


async def stop_scheduler():
    """åœæ­¢è°ƒåº¦å™¨ï¼ˆç”¨äºFastAPI shutdownäº‹ä»¶ï¼‰"""
    global _scheduler_instance
    if _scheduler_instance:
        await _scheduler_instance.stop()
        _scheduler_instance = None