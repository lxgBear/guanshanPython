"""æ™ºèƒ½æ€»ç»“æŠ¥å‘Šä¸šåŠ¡é€»è¾‘æœåŠ¡"""
from typing import List, Optional, Dict, Any
from datetime import datetime
import asyncio
import time

from src.core.domain.entities.summary_report import (
    SummaryReport,
    SummaryReportTask,
    SummaryReportDataItem,
    SummaryReportVersion
)
from src.infrastructure.database.summary_report_repositories import (
    SummaryReportRepository,
    SummaryReportTaskRepository,
    SummaryReportDataItemRepository,
    SummaryReportVersionRepository
)
from src.infrastructure.database.connection import get_mongodb_database
from src.utils.logger import get_logger

logger = get_logger(__name__)

# Redisç¼“å­˜æ˜¯å¯é€‰çš„
try:
    from src.infrastructure.cache import redis_client, cache_key_gen
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    redis_client = None
    cache_key_gen = None
    logger.warning("Redisæ¨¡å—æœªå®‰è£…ï¼Œç¼“å­˜åŠŸèƒ½å°†è¢«ç¦ç”¨")


class LLMService:
    """
    LLMæœåŠ¡ï¼ˆé¢„ç•™æ¥å£ï¼‰

    å¾…LLMæ¨¡å—å¼€å‘å®Œæˆåå®ç°
    ç”¨äºè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ç”ŸæˆæŠ¥å‘Šæ€»ç»“
    """

    async def generate_summary(
        self,
        report_id: str,
        content_items: List[Dict[str, Any]],
        generation_mode: str = "comprehensive"
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆæŠ¥å‘Šæ€»ç»“ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            report_id: æŠ¥å‘ŠID
            content_items: å†…å®¹é¡¹åˆ—è¡¨
            generation_mode: ç”Ÿæˆæ¨¡å¼ (comprehensive/summary/analysis)

        Returns:
            ç”Ÿæˆç»“æœå­—å…¸:
            {
                "success": bool,
                "content": str,  # ç”Ÿæˆçš„å†…å®¹
                "model": str,    # ä½¿ç”¨çš„æ¨¡å‹
                "tokens_used": int,
                "generation_time": float
            }
        """
        # TODO: å®ç°LLMè°ƒç”¨é€»è¾‘
        logger.warning("âš ï¸  LLMæœåŠ¡æœªå®ç°ï¼Œè¿”å›å ä½å†…å®¹")
        return {
            "success": False,
            "content": "",
            "model": "pending",
            "tokens_used": 0,
            "generation_time": 0.0,
            "error": "LLM module not yet implemented"
        }

    async def refine_content(
        self,
        original_content: str,
        refinement_instructions: str
    ) -> Dict[str, Any]:
        """
        ä¼˜åŒ–å†…å®¹ï¼ˆé¢„ç•™æ¥å£ï¼‰

        ç”¨äºæ ¹æ®ç”¨æˆ·æŒ‡ç¤ºä¼˜åŒ–å’Œæ”¹è¿›å·²ç”Ÿæˆçš„å†…å®¹
        """
        # TODO: å®ç°å†…å®¹ä¼˜åŒ–é€»è¾‘
        logger.warning("âš ï¸  LLMå†…å®¹ä¼˜åŒ–æœåŠ¡æœªå®ç°")
        return {
            "success": False,
            "refined_content": original_content,
            "error": "LLM refinement not yet implemented"
        }


class AIAnalysisService:
    """
    AIåˆ†ææœåŠ¡ï¼ˆé¢„ç•™æ¥å£ï¼‰

    å¾…AIæ¨¡å—å¼€å‘å®Œæˆåå®ç°
    ç”¨äºæ•°æ®åˆ†æã€è¶‹åŠ¿è¯†åˆ«ã€å…³é”®ä¿¡æ¯æå–ç­‰
    """

    async def analyze_data(
        self,
        report_id: str,
        data_items: List[Dict[str, Any]],
        analysis_type: str = "trend"
    ) -> Dict[str, Any]:
        """
        åˆ†ææ•°æ®ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            report_id: æŠ¥å‘ŠID
            data_items: æ•°æ®é¡¹åˆ—è¡¨
            analysis_type: åˆ†æç±»å‹ (trend/keyword/sentiment/classification)

        Returns:
            åˆ†æç»“æœå­—å…¸:
            {
                "success": bool,
                "analysis_results": dict,
                "insights": list,
                "recommendations": list
            }
        """
        # TODO: å®ç°AIåˆ†æé€»è¾‘
        logger.warning("âš ï¸  AIåˆ†ææœåŠ¡æœªå®ç°ï¼Œè¿”å›å ä½å†…å®¹")
        return {
            "success": False,
            "analysis_results": {},
            "insights": [],
            "recommendations": [],
            "error": "AI analysis module not yet implemented"
        }

    async def extract_keywords(
        self,
        content: str,
        max_keywords: int = 10
    ) -> List[str]:
        """
        æå–å…³é”®è¯ï¼ˆé¢„ç•™æ¥å£ï¼‰
        """
        # TODO: å®ç°å…³é”®è¯æå–
        logger.warning("âš ï¸  AIå…³é”®è¯æå–æœåŠ¡æœªå®ç°")
        return []


class SummaryReportService:
    """æ™ºèƒ½æ€»ç»“æŠ¥å‘Šç®¡ç†æœåŠ¡"""

    def __init__(self):
        self.db = None
        self.report_repo = None
        self.task_repo = None
        self.data_item_repo = None
        self.version_repo = None
        self.llm_service = LLMService()
        self.ai_service = AIAnalysisService()

    async def _init_repos(self):
        """åˆå§‹åŒ–ä»“å‚¨"""
        if not self.db:
            self.db = await get_mongodb_database()
            self.report_repo = SummaryReportRepository(self.db)
            self.task_repo = SummaryReportTaskRepository(self.db)
            self.data_item_repo = SummaryReportDataItemRepository(self.db)
            self.version_repo = SummaryReportVersionRepository(self.db)

    # ==========================================
    # æŠ¥å‘Šç®¡ç†
    # ==========================================

    async def create_report(
        self,
        title: str,
        description: Optional[str],
        report_type: str,
        created_by: str,
        **kwargs
    ) -> SummaryReport:
        """åˆ›å»ºæ€»ç»“æŠ¥å‘Š"""
        await self._init_repos()

        report = SummaryReport(
            title=title,
            description=description,
            report_type=report_type,
            created_by=created_by,
            **kwargs
        )

        return await self.report_repo.create(report)

    async def get_report(self, report_id: str) -> Optional[SummaryReport]:
        """è·å–æŠ¥å‘Šè¯¦æƒ…"""
        await self._init_repos()
        report = await self.report_repo.find_by_id(report_id)

        if report:
            # å¢åŠ æŸ¥çœ‹æ¬¡æ•°
            await self.report_repo.increment_view_count(report_id)

        return report

    async def list_reports(
        self,
        created_by: Optional[str] = None,
        status: Optional[str] = None,
        report_type: Optional[str] = None,
        limit: int = 50,
        skip: int = 0
    ) -> List[SummaryReport]:
        """åˆ—å‡ºæŠ¥å‘Š"""
        await self._init_repos()
        return await self.report_repo.find_all(
            created_by=created_by,
            status=status,
            report_type=report_type,
            limit=limit,
            skip=skip
        )

    async def update_report(
        self,
        report_id: str,
        update_data: Dict[str, Any]
    ) -> bool:
        """æ›´æ–°æŠ¥å‘Š"""
        await self._init_repos()
        return await self.report_repo.update(report_id, update_data)

    async def delete_report(self, report_id: str) -> bool:
        """åˆ é™¤æŠ¥å‘Šï¼ˆçº§è”åˆ é™¤å…³è”æ•°æ®ï¼‰"""
        await self._init_repos()

        # åˆ é™¤å…³è”çš„ä»»åŠ¡
        await self.task_repo.delete_by_report(report_id)

        # åˆ é™¤å…³è”çš„æ•°æ®é¡¹
        await self.data_item_repo.delete_by_report(report_id)

        # åˆ é™¤ç‰ˆæœ¬å†å²
        await self.version_repo.delete_by_report(report_id)

        # åˆ é™¤æŠ¥å‘Š
        return await self.report_repo.delete(report_id)

    # ==========================================
    # ä»»åŠ¡å…³è”ç®¡ç†
    # ==========================================

    async def add_task_to_report(
        self,
        report_id: str,
        task_id: str,
        task_type: str,
        task_name: str,
        added_by: str,
        priority: int = 0
    ) -> SummaryReportTask:
        """æ·»åŠ ä»»åŠ¡åˆ°æŠ¥å‘Š"""
        await self._init_repos()

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        exists = await self.task_repo.exists(report_id, task_id, task_type)
        if exists:
            raise ValueError(f"Task {task_id} already added to report {report_id}")

        report_task = SummaryReportTask(
            report_id=report_id,
            task_id=task_id,
            task_type=task_type,
            task_name=task_name,
            added_by=added_by,
            priority=priority
        )

        result = await self.task_repo.create(report_task)

        # æ›´æ–°æŠ¥å‘Šçš„ä»»åŠ¡è®¡æ•°
        count = await self.task_repo.count_by_report(report_id)
        await self.report_repo.update_task_count(report_id, count)

        # ==========================================
        # ç¼“å­˜å¤±æ•ˆï¼šåˆ é™¤è¯¥æŠ¥å‘Šçš„æ‰€æœ‰æœç´¢ç¼“å­˜
        # ==========================================
        if REDIS_AVAILABLE:
            cache_pattern = cache_key_gen.report_pattern(report_id)
            deleted_count = await redis_client.delete_pattern(cache_pattern)
            if deleted_count > 0:
                logger.info(f"ğŸ—‘ï¸ ç¼“å­˜å¤±æ•ˆ: {cache_pattern}, åˆ é™¤ {deleted_count} ä¸ªç¼“å­˜é”®")

        return result

    async def get_report_tasks(
        self,
        report_id: str,
        is_active: Optional[bool] = None
    ) -> List[SummaryReportTask]:
        """è·å–æŠ¥å‘Šçš„æ‰€æœ‰ä»»åŠ¡"""
        await self._init_repos()
        return await self.task_repo.find_by_report(report_id, is_active)

    async def remove_task_from_report(
        self,
        report_id: str,
        task_id: str,
        task_type: str
    ) -> bool:
        """ä»æŠ¥å‘Šä¸­ç§»é™¤ä»»åŠ¡"""
        await self._init_repos()
        result = await self.task_repo.delete(report_id, task_id, task_type)

        if result:
            # æ›´æ–°æŠ¥å‘Šçš„ä»»åŠ¡è®¡æ•°
            count = await self.task_repo.count_by_report(report_id)
            await self.report_repo.update_task_count(report_id, count)

            # ==========================================
            # ç¼“å­˜å¤±æ•ˆï¼šåˆ é™¤è¯¥æŠ¥å‘Šçš„æ‰€æœ‰æœç´¢ç¼“å­˜
            # ==========================================
            if REDIS_AVAILABLE:
                cache_pattern = cache_key_gen.report_pattern(report_id)
                deleted_count = await redis_client.delete_pattern(cache_pattern)
                if deleted_count > 0:
                    logger.info(f"ğŸ—‘ï¸ ç¼“å­˜å¤±æ•ˆ: {cache_pattern}, åˆ é™¤ {deleted_count} ä¸ªç¼“å­˜é”®")

        return result

    # ==========================================
    # æ•°æ®é¡¹ç®¡ç†
    # ==========================================

    async def add_data_item(
        self,
        report_id: str,
        source_type: str,
        title: str,
        content: str,
        added_by: str,
        **kwargs
    ) -> SummaryReportDataItem:
        """æ·»åŠ æ•°æ®é¡¹åˆ°æŠ¥å‘Š"""
        await self._init_repos()

        data_item = SummaryReportDataItem(
            report_id=report_id,
            source_type=source_type,
            title=title,
            content=content,
            added_by=added_by,
            **kwargs
        )

        result = await self.data_item_repo.create(data_item)

        # æ›´æ–°æŠ¥å‘Šçš„æ•°æ®é¡¹è®¡æ•°
        count = await self.data_item_repo.count_by_report(report_id)
        await self.report_repo.update_data_item_count(report_id, count)

        return result

    async def get_report_data_items(
        self,
        report_id: str,
        is_visible: Optional[bool] = None,
        limit: int = 100
    ) -> List[SummaryReportDataItem]:
        """è·å–æŠ¥å‘Šçš„æ‰€æœ‰æ•°æ®é¡¹"""
        await self._init_repos()
        return await self.data_item_repo.find_by_report(
            report_id,
            is_visible=is_visible,
            limit=limit
        )

    async def search_data_items(
        self,
        report_id: str,
        search_query: str,
        limit: int = 50
    ) -> List[SummaryReportDataItem]:
        """
        æ¨¡ç³Šæœç´¢æ•°æ®é¡¹ï¼ˆè”è¡¨æŸ¥è¯¢ï¼‰

        ä»ç”¨æˆ·é€‰æ‹©çš„å®šæ—¶ä»»åŠ¡å’Œæœç´¢ä»»åŠ¡è¡¨ä¸­è·å–å†…å®¹
        """
        await self._init_repos()

        # ä½¿ç”¨å…¨æ–‡æœç´¢
        return await self.data_item_repo.search(report_id, search_query, limit)

    async def _search_scheduled_results(
        self,
        task_ids: List[str],
        search_query: str,
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢å®šæ—¶ä»»åŠ¡çš„æœç´¢ç»“æœï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        ä½¿ç”¨ä¼˜åŒ–çš„èšåˆç®¡é“å’ŒæŸ¥è¯¢æç¤º
        """
        if not task_ids:
            return []

        try:
            # ä¼˜åŒ–çš„èšåˆç®¡é“ï¼šå…ˆè¿‡æ»¤åè”è¡¨
            pipeline = [
                # ç¬¬ä¸€é˜¶æ®µï¼šç²¾ç¡®åŒ¹é…ï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
                {
                    "$match": {
                        "task_id": {"$in": task_ids},
                        "$text": {"$search": search_query}
                    }
                },
                # ç¬¬äºŒé˜¶æ®µï¼šæŒ‰ç›¸å…³æ€§æ’åº
                {
                    "$sort": {"score": {"$meta": "textScore"}}
                },
                # ç¬¬ä¸‰é˜¶æ®µï¼šé™åˆ¶ç»“æœæ•°
                {"$limit": limit},
                # ç¬¬å››é˜¶æ®µï¼šè”è¡¨æŸ¥è¯¢ï¼ˆåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µï¼‰
                {
                    "$lookup": {
                        "from": "search_tasks",
                        "let": {"taskId": "$task_id"},
                        "pipeline": [
                            {
                                "$match": {
                                    "$expr": {"$eq": ["$id", "$$taskId"]}
                                }
                            },
                            # åªè¿”å›éœ€è¦çš„å­—æ®µï¼ˆå‡å°‘æ•°æ®ä¼ è¾“ï¼‰
                            {
                                "$project": {
                                    "_id": 0,
                                    "id": 1,
                                    "name": 1,
                                    "query": 1
                                }
                            }
                        ],
                        "as": "task_info"
                    }
                },
                # ç¬¬äº”é˜¶æ®µï¼šæŠ•å½±ï¼ˆåªè¿”å›éœ€è¦çš„å­—æ®µï¼‰
                {
                    "$project": {
                        "_id": 0,
                        "result_id": 1,
                        "task_id": 1,
                        "title": 1,
                        "url": 1,
                        "markdown_content": 1,
                        "created_at": 1,
                        "task_info": {"$arrayElemAt": ["$task_info", 0]},
                        "relevance_score": {"$meta": "textScore"}
                    }
                }
            ]

            # ä½¿ç”¨hintå¼ºåˆ¶ä½¿ç”¨æœ€ä¼˜ç´¢å¼•
            cursor = self.db.search_results.aggregate(
                pipeline,
                hint="idx_task_created"  # å¼ºåˆ¶ä½¿ç”¨ task_id + created_at ç´¢å¼•
            )

            results = await cursor.to_list(length=limit)
            logger.debug(f"ğŸ“Š æŸ¥è¯¢å®šæ—¶ä»»åŠ¡ç»“æœ: {len(results)} æ¡")
            return results

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å®šæ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return []

    async def _search_instant_results(
        self,
        task_ids: List[str],
        search_query: str,
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢å³æ—¶ä»»åŠ¡çš„æœç´¢ç»“æœï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        ä½¿ç”¨ä¼˜åŒ–çš„èšåˆç®¡é“å’ŒæŸ¥è¯¢æç¤º
        """
        if not task_ids:
            return []

        try:
            # ä¼˜åŒ–çš„èšåˆç®¡é“ï¼šå…ˆè¿‡æ»¤åè”è¡¨
            pipeline = [
                # ç¬¬ä¸€é˜¶æ®µï¼šç²¾ç¡®åŒ¹é…ï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
                {
                    "$match": {
                        "execution_id": {"$in": task_ids},
                        "$text": {"$search": search_query}
                    }
                },
                # ç¬¬äºŒé˜¶æ®µï¼šæŒ‰ç›¸å…³æ€§æ’åº
                {
                    "$sort": {"score": {"$meta": "textScore"}}
                },
                # ç¬¬ä¸‰é˜¶æ®µï¼šé™åˆ¶ç»“æœæ•°
                {"$limit": limit},
                # ç¬¬å››é˜¶æ®µï¼šè”è¡¨æŸ¥è¯¢ï¼ˆåªæŸ¥è¯¢éœ€è¦çš„å­—æ®µï¼‰
                {
                    "$lookup": {
                        "from": "instant_search_tasks",
                        "let": {"execId": "$execution_id"},
                        "pipeline": [
                            {
                                "$match": {
                                    "$expr": {"$eq": ["$execution_id", "$$execId"]}
                                }
                            },
                            # åªè¿”å›éœ€è¦çš„å­—æ®µ
                            {
                                "$project": {
                                    "_id": 0,
                                    "execution_id": 1,
                                    "query": 1,
                                    "created_at": 1
                                }
                            }
                        ],
                        "as": "task_info"
                    }
                },
                # ç¬¬äº”é˜¶æ®µï¼šæŠ•å½±
                {
                    "$project": {
                        "_id": 0,
                        "result_id": 1,
                        "execution_id": 1,
                        "title": 1,
                        "url": 1,
                        "markdown_content": 1,
                        "created_at": 1,
                        "task_info": {"$arrayElemAt": ["$task_info", 0]},
                        "relevance_score": {"$meta": "textScore"}
                    }
                }
            ]

            # ä½¿ç”¨hintå¼ºåˆ¶ä½¿ç”¨æœ€ä¼˜ç´¢å¼•
            cursor = self.db.instant_search_results.aggregate(
                pipeline,
                hint="idx_execution_created"  # å¼ºåˆ¶ä½¿ç”¨ execution_id + created_at ç´¢å¼•
            )

            results = await cursor.to_list(length=limit)
            logger.debug(f"ğŸ“Š æŸ¥è¯¢å³æ—¶ä»»åŠ¡ç»“æœ: {len(results)} æ¡")
            return results

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å³æ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return []

    async def search_across_tasks(
        self,
        report_id: str,
        search_query: str,
        limit: int = 50
    ) -> Dict[str, Any]:
        """
        è·¨ä»»åŠ¡è”è¡¨æŸ¥è¯¢æœç´¢ç»“æœï¼ˆä¼˜åŒ–ç‰ˆ + Redisç¼“å­˜ï¼‰

        æ€§èƒ½ä¼˜åŒ–ç­–ç•¥ï¼š
        1. Redisç¼“å­˜ï¼š5åˆ†é’ŸTTLï¼Œå‡å°‘é‡å¤æŸ¥è¯¢å‹åŠ›
        2. åˆ†é˜¶æ®µæŸ¥è¯¢ï¼šå…ˆè·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆå°è¡¨ï¼‰ï¼Œå†åˆ†ç¦»ç±»å‹
        3. å¹¶è¡ŒæŸ¥è¯¢ï¼šä½¿ç”¨asyncio.gatheråŒæ—¶æŸ¥è¯¢scheduledå’Œinstantç»“æœ
        4. æŸ¥è¯¢æç¤ºï¼šä½¿ç”¨hintå¼ºåˆ¶ä½¿ç”¨æœ€ä¼˜ç´¢å¼•
        5. ç»“æœé™åˆ¶ï¼šæ¯ä¸ªä»»åŠ¡ç±»å‹é™åˆ¶ç»“æœæ•°ï¼Œé¿å…è¿‡è½½
        6. æŠ•å½±ä¼˜åŒ–ï¼šåªè¿”å›éœ€è¦çš„å­—æ®µï¼Œå‡å°‘æ•°æ®ä¼ è¾“

        æ€§èƒ½ç›®æ ‡ï¼š
        - ç¼“å­˜å‘½ä¸­: <50ms
        - 2ä¸ªä»»åŠ¡: <1s (å†·æŸ¥è¯¢)
        - 3-5ä¸ªä»»åŠ¡: <2s (å†·æŸ¥è¯¢)
        - 6-10ä¸ªä»»åŠ¡: <3s (å†·æŸ¥è¯¢)
        """
        await self._init_repos()

        # ==========================================
        # Redisç¼“å­˜æ£€æŸ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # ==========================================
        cache_key = None
        if REDIS_AVAILABLE:
            cache_key = cache_key_gen.search_result(report_id, search_query, limit)
            cached_result = await redis_client.get(cache_key)

            if cached_result:
                logger.info(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_key}")
                return cached_result

            logger.debug(f"ğŸ” ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡ŒæŸ¥è¯¢: {cache_key}")

        # ==========================================
        # é˜¶æ®µ1: è·å–æ´»è·ƒä»»åŠ¡åˆ—è¡¨ï¼ˆä½¿ç”¨è¦†ç›–ç´¢å¼•ï¼Œå°è¡¨æŸ¥è¯¢ï¼‰
        # ==========================================
        report_tasks = await self.task_repo.find_by_report(
            report_id,
            is_active=True
        )

        if not report_tasks:
            empty_result = {
                "scheduled_results": [],
                "instant_results": [],
                "merged_results": [],
                "total_count": 0,
                "query_time": 0,
                "task_stats": {
                    "scheduled_tasks": 0,
                    "instant_tasks": 0,
                    "total_tasks": 0
                }
            }
            # ç¼“å­˜ç©ºç»“æœï¼ˆè¾ƒçŸ­TTLï¼‰
            if REDIS_AVAILABLE and cache_key:
                await redis_client.set(cache_key, empty_result, ttl=60)
            return empty_result

        # ==========================================
        # é˜¶æ®µ2: åˆ†ç¦»ä»»åŠ¡ç±»å‹ï¼ˆå†…å­˜æ“ä½œï¼Œé¿å…å¤æ‚æ¡ä»¶ï¼‰
        # ==========================================
        scheduled_task_ids = [
            rt.task_id for rt in report_tasks
            if rt.task_type == "scheduled"
        ]
        instant_task_ids = [
            rt.task_id for rt in report_tasks
            if rt.task_type == "instant"
        ]

        logger.info(
            f"ğŸ” è·¨ä»»åŠ¡æœç´¢ - æŠ¥å‘Š: {report_id}, "
            f"å®šæ—¶ä»»åŠ¡: {len(scheduled_task_ids)}, "
            f"å³æ—¶ä»»åŠ¡: {len(instant_task_ids)}"
        )

        # ==========================================
        # é˜¶æ®µ3: å¹¶è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨asyncio.gatherï¼Œæœ€å¤§åŒ–æ€§èƒ½ï¼‰
        # ==========================================
        start_time = time.time()

        # å¹¶å‘æ‰§è¡Œä¸¤ä¸ªæŸ¥è¯¢
        scheduled_results, instant_results = await asyncio.gather(
            self._search_scheduled_results(
                scheduled_task_ids,
                search_query,
                limit
            ),
            self._search_instant_results(
                instant_task_ids,
                search_query,
                limit
            ),
            return_exceptions=True  # æ•è·å¼‚å¸¸è€Œä¸ä¸­æ–­
        )

        # å¤„ç†å¼‚å¸¸ç»“æœ
        if isinstance(scheduled_results, Exception):
            logger.error(f"âŒ å®šæ—¶ä»»åŠ¡æŸ¥è¯¢å¼‚å¸¸: {scheduled_results}")
            scheduled_results = []

        if isinstance(instant_results, Exception):
            logger.error(f"âŒ å³æ—¶ä»»åŠ¡æŸ¥è¯¢å¼‚å¸¸: {instant_results}")
            instant_results = []

        # ==========================================
        # é˜¶æ®µ4: åˆå¹¶ç»“æœå¹¶æ’åºï¼ˆæŒ‰ç›¸å…³æ€§åˆ†æ•°ï¼‰
        # ==========================================
        all_results = []
        for result in scheduled_results:
            result["source_type"] = "scheduled"
            all_results.append(result)
        for result in instant_results:
            result["source_type"] = "instant"
            all_results.append(result)

        # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
        all_results.sort(
            key=lambda x: x.get("relevance_score", 0),
            reverse=True
        )

        # é™åˆ¶æ€»ç»“æœæ•°
        if len(all_results) > limit:
            all_results = all_results[:limit]

        query_time = time.time() - start_time

        logger.info(
            f"âœ… è·¨ä»»åŠ¡æœç´¢å®Œæˆ - æ€»ç»“æœ: {len(all_results)}, "
            f"æŸ¥è¯¢æ—¶é—´: {query_time:.3f}s"
        )

        # æ„å»ºæŸ¥è¯¢ç»“æœ
        search_result = {
            "scheduled_results": scheduled_results,
            "instant_results": instant_results,
            "merged_results": all_results,
            "total_count": len(all_results),
            "query_time": query_time,
            "task_stats": {
                "scheduled_tasks": len(scheduled_task_ids),
                "instant_tasks": len(instant_task_ids),
                "total_tasks": len(report_tasks)
            }
        }

        # ==========================================
        # Redisç¼“å­˜ç»“æœï¼ˆ5åˆ†é’ŸTTLï¼‰
        # ==========================================
        if REDIS_AVAILABLE and cache_key:
            await redis_client.set(cache_key, search_result, ttl=300)
            logger.debug(f"ğŸ’¾ ç¼“å­˜å·²è®¾ç½®: {cache_key}, TTL: 300s")

        return search_result

    async def update_data_item(
        self,
        item_id: str,
        update_data: Dict[str, Any]
    ) -> bool:
        """æ›´æ–°æ•°æ®é¡¹"""
        await self._init_repos()
        return await self.data_item_repo.update(item_id, update_data)

    async def delete_data_item(self, item_id: str, report_id: str) -> bool:
        """åˆ é™¤æ•°æ®é¡¹"""
        await self._init_repos()
        result = await self.data_item_repo.delete(item_id)

        if result:
            # æ›´æ–°æŠ¥å‘Šçš„æ•°æ®é¡¹è®¡æ•°
            count = await self.data_item_repo.count_by_report(report_id)
            await self.report_repo.update_data_item_count(report_id, count)

        return result

    # ==========================================
    # å†…å®¹ç¼–è¾‘å’Œç‰ˆæœ¬ç®¡ç†
    # ==========================================

    async def update_report_content(
        self,
        report_id: str,
        content_text: str,
        content_format: str = "markdown",
        is_manual: bool = False,
        updated_by: str = "",
        change_description: Optional[str] = None
    ) -> bool:
        """æ›´æ–°æŠ¥å‘Šå†…å®¹ï¼ˆæ”¯æŒå¯Œæ–‡æœ¬ç¼–è¾‘ï¼‰"""
        await self._init_repos()

        # è·å–å½“å‰æŠ¥å‘Š
        report = await self.report_repo.find_by_id(report_id)
        if not report:
            return False

        # å¦‚æœå¯ç”¨è‡ªåŠ¨ç‰ˆæœ¬ç®¡ç†ï¼Œåˆ›å»ºç‰ˆæœ¬å¿«ç…§
        if report.auto_version and is_manual:
            version = SummaryReportVersion(
                report_id=report_id,
                version_number=report.version + 1,
                content_snapshot=report.content.copy(),
                change_description=change_description or "Manual content update",
                change_type="manual" if is_manual else "auto_generated",
                created_by=updated_by,
                content_size=len(content_text)
            )
            await self.version_repo.create(version)

        # æ›´æ–°å†…å®¹
        return await self.report_repo.update_content(
            report_id,
            content_text,
            content_format,
            is_manual
        )

    async def get_report_versions(
        self,
        report_id: str,
        limit: int = 20
    ) -> List[SummaryReportVersion]:
        """è·å–æŠ¥å‘Šç‰ˆæœ¬å†å²"""
        await self._init_repos()
        return await self.version_repo.find_by_report(report_id, limit)

    async def rollback_to_version(
        self,
        report_id: str,
        version_number: int,
        updated_by: str
    ) -> bool:
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        await self._init_repos()

        # è·å–ç›®æ ‡ç‰ˆæœ¬
        version = await self.version_repo.find_by_version_number(report_id, version_number)
        if not version:
            return False

        # æ¢å¤å†…å®¹
        content_snapshot = version.content_snapshot
        content_text = content_snapshot.get("text", "")
        content_format = content_snapshot.get("format", "markdown")

        return await self.update_report_content(
            report_id,
            content_text,
            content_format,
            is_manual=True,
            updated_by=updated_by,
            change_description=f"Rollback to version {version_number}"
        )

    # ==========================================
    # LLM/AI ç”ŸæˆåŠŸèƒ½ï¼ˆé¢„ç•™æ¥å£ï¼‰
    # ==========================================

    async def generate_report_with_llm(
        self,
        report_id: str,
        generation_mode: str = "comprehensive",
        llm_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            report_id: æŠ¥å‘ŠID
            generation_mode: ç”Ÿæˆæ¨¡å¼
            llm_config: LLMé…ç½®å‚æ•°

        Returns:
            ç”Ÿæˆç»“æœ
        """
        await self._init_repos()

        # æ›´æ–°æŠ¥å‘ŠçŠ¶æ€ä¸ºç”Ÿæˆä¸­
        await self.report_repo.update_status(report_id, "generating")

        try:
            # è·å–æŠ¥å‘Šçš„æ‰€æœ‰æ•°æ®é¡¹
            data_items = await self.data_item_repo.find_by_report(report_id)

            # è½¬æ¢ä¸ºLLMè¾“å…¥æ ¼å¼
            content_items = [
                {
                    "title": item.title,
                    "content": item.content,
                    "url": item.url,
                    "importance": item.importance
                }
                for item in data_items
            ]

            # è°ƒç”¨LLMæœåŠ¡ç”Ÿæˆå†…å®¹
            result = await self.llm_service.generate_summary(
                report_id,
                content_items,
                generation_mode
            )

            if result["success"]:
                # æ›´æ–°æŠ¥å‘Šå†…å®¹
                await self.update_report_content(
                    report_id,
                    result["content"],
                    content_format="markdown",
                    is_manual=False,
                    change_description="LLM generated content"
                )

                # æ›´æ–°ç”Ÿæˆé…ç½®
                gen_config = {
                    "llm_model": result.get("model"),
                    "ai_analysis_type": generation_mode,
                    "generation_params": llm_config or {}
                }
                await self.report_repo.update(report_id, {
                    "generation_config": gen_config
                })

                # æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆ
                await self.report_repo.update_status(report_id, "completed")
            else:
                # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                await self.report_repo.update_status(report_id, "failed")

            return result

        except Exception as e:
            logger.error(f"âŒ LLMç”Ÿæˆå¤±è´¥: {e}")
            await self.report_repo.update_status(report_id, "failed")
            return {
                "success": False,
                "error": str(e)
            }

    async def analyze_report_data_with_ai(
        self,
        report_id: str,
        analysis_type: str = "trend"
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIåˆ†ææŠ¥å‘Šæ•°æ®ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            report_id: æŠ¥å‘ŠID
            analysis_type: åˆ†æç±»å‹

        Returns:
            åˆ†æç»“æœ
        """
        await self._init_repos()

        # è·å–æŠ¥å‘Šçš„æ‰€æœ‰æ•°æ®é¡¹
        data_items = await self.data_item_repo.find_by_report(report_id)

        # è½¬æ¢ä¸ºAIåˆ†æè¾“å…¥æ ¼å¼
        analysis_items = [
            {
                "title": item.title,
                "content": item.content,
                "metadata": item.metadata,
                "tags": item.tags
            }
            for item in data_items
        ]

        # è°ƒç”¨AIåˆ†ææœåŠ¡
        return await self.ai_service.analyze_data(
            report_id,
            analysis_items,
            analysis_type
        )

    # ==========================================
    # ä»»åŠ¡ç»“æœè·å–ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
    # ==========================================

    async def get_task_results_for_report(
        self,
        report_id: str,
        task_ids: Optional[List[str]] = None,
        cursor: Optional[str] = None,
        limit: int = 50
    ) -> Dict[str, Any]:
        """
        è·å–æŠ¥å‘Šå…³è”ä»»åŠ¡çš„æ‰€æœ‰ç»“æœï¼ˆæ”¯æŒæ¸¸æ ‡åˆ†é¡µï¼‰

        æ”¹è¿›åŠŸèƒ½ï¼šç”¨äºå‰ç«¯åˆå§‹åŒ–æ•°æ®åˆ—è¡¨ï¼Œå‡å°‘APIè°ƒç”¨

        Args:
            report_id: æŠ¥å‘ŠID
            task_ids: æŒ‡å®šä»»åŠ¡IDåˆ—è¡¨ï¼ˆå¯é€‰ï¼Œä¸ºNoneæ—¶è¿”å›æ‰€æœ‰å…³è”ä»»åŠ¡çš„ç»“æœï¼‰
            cursor: åˆ†é¡µæ¸¸æ ‡ï¼ˆæ ¼å¼: "task_type:task_id:created_at"ï¼‰
            limit: åˆ†é¡µå¤§å°

        Returns:
            {
                "items": [...]  # ä»»åŠ¡ç»“æœåˆ—è¡¨
                "meta": {
                    "has_next": bool,
                    "next_cursor": str,
                    "count": int,
                    "task_stats": {...}
                }
            }
        """
        await self._init_repos()

        # è·å–æŠ¥å‘Šå…³è”çš„ä»»åŠ¡
        report_tasks = await self.task_repo.find_by_report(report_id, is_active=True)

        if not report_tasks:
            return {
                "items": [],
                "meta": {
                    "has_next": False,
                    "next_cursor": None,
                    "count": 0,
                    "task_stats": {
                        "scheduled_count": 0,
                        "instant_count": 0,
                        "total_count": 0
                    }
                }
            }

        # å¦‚æœæŒ‡å®šäº†task_idsï¼Œè¿‡æ»¤ä»»åŠ¡åˆ—è¡¨
        if task_ids:
            task_id_set = set(task_ids)
            report_tasks = [
                task for task in report_tasks
                if task.task_id in task_id_set
            ]

        # åˆ†ç¦»å®šæ—¶ä»»åŠ¡å’Œå³æ—¶ä»»åŠ¡
        scheduled_task_ids = [
            t.task_id for t in report_tasks if t.task_type == "scheduled"
        ]
        instant_task_ids = [
            t.task_id for t in report_tasks if t.task_type == "instant"
        ]

        # å¹¶è¡ŒæŸ¥è¯¢ä¸¤ç§ä»»åŠ¡çš„ç»“æœ
        scheduled_results, instant_results = await asyncio.gather(
            self._get_all_scheduled_results(scheduled_task_ids, limit),
            self._get_all_instant_results(instant_task_ids, limit),
            return_exceptions=True
        )

        # å¤„ç†å¼‚å¸¸
        if isinstance(scheduled_results, Exception):
            logger.error(f"âŒ è·å–å®šæ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {scheduled_results}")
            scheduled_results = []
        if isinstance(instant_results, Exception):
            logger.error(f"âŒ è·å–å³æ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {instant_results}")
            instant_results = []

        # åˆå¹¶ç»“æœå¹¶æ·»åŠ source_typeæ ‡è®°
        all_results = []
        for result in scheduled_results:
            result["source_type"] = "scheduled"
            all_results.append(result)
        for result in instant_results:
            result["source_type"] = "instant"
            all_results.append(result)

        # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        all_results.sort(
            key=lambda x: x.get("created_at", datetime.min),
            reverse=True
        )

        # åº”ç”¨æ¸¸æ ‡åˆ†é¡µ
        if cursor:
            # è§£ææ¸¸æ ‡: "source_type:created_at_timestamp"
            try:
                cursor_parts = cursor.split(":")
                if len(cursor_parts) == 2:
                    cursor_source_type, cursor_timestamp = cursor_parts
                    cursor_dt = datetime.fromtimestamp(float(cursor_timestamp))

                    # è¿‡æ»¤å‡ºæ¸¸æ ‡ä¹‹åçš„ç»“æœ
                    all_results = [
                        r for r in all_results
                        if r.get("created_at", datetime.max) < cursor_dt or
                        (r.get("created_at") == cursor_dt and r.get("source_type") != cursor_source_type)
                    ]
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸¸æ ‡è§£æå¤±è´¥: {e}, å¿½ç•¥æ¸¸æ ‡")

        # é™åˆ¶ç»“æœæ•°é‡ï¼ˆå–limit+1ç”¨äºåˆ¤æ–­æ˜¯å¦æœ‰ä¸‹ä¸€é¡µï¼‰
        has_next = len(all_results) > limit
        if has_next:
            items = all_results[:limit]
        else:
            items = all_results

        # ç”Ÿæˆä¸‹ä¸€é¡µæ¸¸æ ‡
        next_cursor = None
        if has_next and items:
            last_item = items[-1]
            last_created_at = last_item.get("created_at")
            if last_created_at:
                timestamp = last_created_at.timestamp()
                source_type = last_item.get("source_type", "scheduled")
                next_cursor = f"{source_type}:{timestamp}"

        return {
            "items": items,
            "meta": {
                "has_next": has_next,
                "next_cursor": next_cursor,
                "count": len(items),
                "task_stats": {
                    "scheduled_count": len(scheduled_task_ids),
                    "instant_count": len(instant_task_ids),
                    "total_count": len(report_tasks)
                }
            }
        }

    async def _get_all_scheduled_results(
        self,
        task_ids: List[str],
        limit: int
    ) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å®šæ—¶ä»»åŠ¡çš„ç»“æœï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        if not task_ids:
            return []

        try:
            # æŸ¥è¯¢æ‰€æœ‰ç»“æœï¼ˆä¸éœ€è¦å…¨æ–‡æœç´¢ï¼‰
            query = {"task_id": {"$in": task_ids}}

            cursor = self.db.search_results.find(query).sort("created_at", -1).limit(limit * 2)
            results = await cursor.to_list(length=limit * 2)

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "result_id": result.get("result_id") or str(result.get("_id")),
                    "task_id": result.get("task_id"),
                    "title": result.get("title"),
                    "url": result.get("url"),
                    "markdown_content": result.get("markdown_content"),
                    "created_at": result.get("created_at"),
                    "metadata": result.get("metadata", {})
                })

            logger.debug(f"ğŸ“Š è·å–å®šæ—¶ä»»åŠ¡ç»“æœ: {len(formatted_results)} æ¡")
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ è·å–å®šæ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return []

    async def _get_all_instant_results(
        self,
        task_ids: List[str],
        limit: int
    ) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å³æ—¶ä»»åŠ¡çš„ç»“æœï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        if not task_ids:
            return []

        try:
            # æŸ¥è¯¢æ‰€æœ‰ç»“æœï¼ˆä¸éœ€è¦å…¨æ–‡æœç´¢ï¼‰
            query = {"task_id": {"$in": task_ids}}

            cursor = self.db.instant_search_results.find(query).sort("created_at", -1).limit(limit * 2)
            results = await cursor.to_list(length=limit * 2)

            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "result_id": result.get("result_id") or str(result.get("_id")),
                    "task_id": result.get("task_id") or result.get("execution_id"),
                    "title": result.get("title"),
                    "url": result.get("url"),
                    "markdown_content": result.get("markdown_content"),
                    "created_at": result.get("created_at"),
                    "metadata": result.get("metadata", {})
                })

            logger.debug(f"ğŸ“Š è·å–å³æ—¶ä»»åŠ¡ç»“æœ: {len(formatted_results)} æ¡")
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ è·å–å³æ—¶ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
            return []


# å…¨å±€æœåŠ¡å®ä¾‹
summary_report_service = SummaryReportService()
