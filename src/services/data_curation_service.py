"""æ•°æ®æ•´ç¼–æœåŠ¡

æä¾›æ•°æ®æºç®¡ç†çš„æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼ŒåŒ…æ‹¬ï¼š
- æ•°æ®æºCRUDæ“ä½œ
- çŠ¶æ€åŒæ­¥ç®¡ç†ï¼ˆMongoDBäº‹åŠ¡ï¼‰
- åŸå§‹æ•°æ®å¼•ç”¨ç®¡ç†
- æ‰¹é‡æ“ä½œæ”¯æŒ
"""

from typing import List, Optional, Dict, Any
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorDatabase

from src.core.domain.entities.data_source import (
    DataSource,
    DataSourceStatus,
    RawDataReference
)
from src.core.domain.entities.search_result import SearchResult
from src.core.domain.entities.instant_search_result import InstantSearchResult
from src.infrastructure.database.data_source_repositories import DataSourceRepository
from src.utils.logger import get_logger

logger = get_logger(__name__)


class DataCurationService:
    """æ•°æ®æ•´ç¼–æœåŠ¡

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ•°æ®æºç”Ÿå‘½å‘¨æœŸç®¡ç†
    - çŠ¶æ€åŒæ­¥ï¼ˆä½¿ç”¨MongoDBäº‹åŠ¡ï¼‰
    - åŸå§‹æ•°æ®å¼•ç”¨ç®¡ç†
    """

    def __init__(self, db: AsyncIOMotorDatabase):
        """åˆå§‹åŒ–æœåŠ¡

        Args:
            db: MongoDBæ•°æ®åº“å®ä¾‹
        """
        self.db = db
        self.data_source_repo = DataSourceRepository(db)
        self.search_results_collection = db.search_results
        self.instant_search_results_collection = db.instant_search_results

    # ==========================================
    # æ•°æ®æºåŸºç¡€æ“ä½œ
    # ==========================================

    async def create_data_source(
        self,
        title: str,
        description: str,
        created_by: str,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> DataSource:
        """åˆ›å»ºæ•°æ®æºï¼ˆè‰ç¨¿çŠ¶æ€ï¼‰

        Args:
            title: æ•°æ®æºæ ‡é¢˜
            description: æ•°æ®æºæè¿°
            created_by: åˆ›å»ºè€…
            tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            metadata: æ‰©å±•å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰

        Returns:
            åˆ›å»ºçš„æ•°æ®æºå®ä½“
        """
        data_source = DataSource(
            title=title,
            description=description,
            created_by=created_by,
            updated_by=created_by,
            tags=tags or [],
            metadata=metadata or {}
        )

        await self.data_source_repo.create(data_source)
        logger.info(f"âœ… åˆ›å»ºæ•°æ®æº: {data_source.id} - {title}")

        return data_source

    async def get_data_source(self, data_source_id: str) -> Optional[DataSource]:
        """è·å–æ•°æ®æºè¯¦æƒ…

        Args:
            data_source_id: æ•°æ®æºID

        Returns:
            æ•°æ®æºå®ä½“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        return await self.data_source_repo.find_by_id(data_source_id)

    async def list_data_sources(
        self,
        created_by: Optional[str] = None,
        status: Optional[str] = None,
        source_type: Optional[str] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: int = 50,
        skip: int = 0
    ) -> tuple[List[DataSource], int]:
        """åˆ—å‡ºæ•°æ®æºï¼ˆæ”¯æŒè¿‡æ»¤å’Œåˆ†é¡µï¼‰

        Args:
            created_by: åˆ›å»ºè€…è¿‡æ»¤
            status: çŠ¶æ€è¿‡æ»¤
            source_type: æ•°æ®æºç±»å‹è¿‡æ»¤
            start_date: å¼€å§‹æ—¥æœŸè¿‡æ»¤
            end_date: ç»“æŸæ—¥æœŸè¿‡æ»¤
            limit: æ¯é¡µæ•°é‡
            skip: è·³è¿‡æ•°é‡

        Returns:
            (æ•°æ®æºåˆ—è¡¨, æ€»æ•°)
        """
        data_sources = await self.data_source_repo.find_all(
            created_by=created_by,
            status=status,
            source_type=source_type,
            start_date=start_date,
            end_date=end_date,
            limit=limit,
            skip=skip
        )

        total = await self.data_source_repo.count(
            created_by=created_by,
            status=status,
            source_type=source_type,
            start_date=start_date,
            end_date=end_date
        )

        return data_sources, total

    async def update_data_source_info(
        self,
        data_source_id: str,
        title: Optional[str] = None,
        description: Optional[str] = None,
        tags: Optional[List[str]] = None,
        updated_by: str = ""
    ) -> bool:
        """æ›´æ–°æ•°æ®æºåŸºç¡€ä¿¡æ¯ï¼ˆä»…è‰ç¨¿çŠ¶æ€å¯ç¼–è¾‘ï¼‰

        Args:
            data_source_id: æ•°æ®æºID
            title: æ–°æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            description: æ–°æè¿°ï¼ˆå¯é€‰ï¼‰
            tags: æ–°æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            updated_by: æ›´æ–°è€…

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨æˆ–ä¸å¯ç¼–è¾‘
        """
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_edit():
            raise ValueError(
                f"Cannot edit data source in status '{data_source.status.value}'"
            )

        update_data = {"updated_by": updated_by}

        if title is not None:
            update_data["title"] = title

        if description is not None:
            update_data["description"] = description

        if tags is not None:
            update_data["tags"] = tags

        return await self.data_source_repo.update(data_source_id, update_data)

    async def update_data_source_content(
        self,
        data_source_id: str,
        edited_content: str,
        updated_by: str
    ) -> bool:
        """æ›´æ–°æ•°æ®æºç¼–è¾‘å†…å®¹ï¼ˆä»…è‰ç¨¿çŠ¶æ€å¯ç¼–è¾‘ï¼‰

        Args:
            data_source_id: æ•°æ®æºID
            edited_content: ç¼–è¾‘å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼‰
            updated_by: æ›´æ–°è€…

        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨æˆ–ä¸å¯ç¼–è¾‘
        """
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_edit():
            raise ValueError(
                f"Cannot edit data source in status '{data_source.status.value}'"
            )

        update_data = {
            "edited_content": edited_content,
            "content_version": data_source.content_version + 1,
            "updated_by": updated_by
        }

        return await self.data_source_repo.update(data_source_id, update_data)

    # ==========================================
    # åŸå§‹æ•°æ®ç®¡ç†ï¼ˆå¸¦çŠ¶æ€åŒæ­¥ï¼‰
    # ==========================================

    async def add_raw_data_to_source(
        self,
        data_source_id: str,
        data_id: str,
        data_type: str,
        added_by: str
    ) -> bool:
        """æ·»åŠ åŸå§‹æ•°æ®åˆ°æ•°æ®æº

        çŠ¶æ€åŒæ­¥ï¼šåŸå§‹æ•°æ® pending/archived â†’ processing

        Args:
            data_source_id: æ•°æ®æºID
            data_id: åŸå§‹æ•°æ®ID
            data_type: æ•°æ®ç±»å‹ï¼ˆscheduledæˆ–instantï¼‰
            added_by: æ·»åŠ è€…

        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨ã€ä¸å¯ç¼–è¾‘æˆ–åŸå§‹æ•°æ®ä¸å­˜åœ¨
        """
        # éªŒè¯æ•°æ®æº
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_edit():
            raise ValueError(
                f"Cannot add data to data source in status '{data_source.status.value}'"
            )

        # è·å–åŸå§‹æ•°æ®
        if data_type == "scheduled":
            collection = self.search_results_collection
        elif data_type == "instant":
            collection = self.instant_search_results_collection
        else:
            raise ValueError(f"Invalid data type: {data_type}")

        raw_data_doc = await collection.find_one({"id": data_id})
        if not raw_data_doc:
            raise ValueError(f"Raw data '{data_id}' not found in {data_type} collection")

        # æ£€æŸ¥å½“å‰çŠ¶æ€
        current_status = raw_data_doc.get("status", "pending")
        if current_status not in ["pending", "archived"]:
            raise ValueError(
                f"Cannot add raw data with status '{current_status}' to data source. "
                f"Only 'pending' or 'archived' data can be added."
            )

        # ä½¿ç”¨äº‹åŠ¡åŒæ­¥æ›´æ–°
        async with await self.db.client.start_session() as session:
            async with session.start_transaction():
                try:
                    # 1. æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ â†’ processing
                    await collection.update_one(
                        {"id": data_id},
                        {
                            "$set": {
                                "status": "processing",
                                "updated_at": datetime.utcnow()
                            }
                        },
                        session=session
                    )

                    # 2. æ·»åŠ åˆ°æ•°æ®æºå¼•ç”¨åˆ—è¡¨
                    ref = RawDataReference(
                        data_id=data_id,
                        data_type=data_type,
                        title=raw_data_doc.get("title", ""),
                        url=raw_data_doc.get("url", ""),
                        snippet=raw_data_doc.get("snippet", "") or raw_data_doc.get("content", "")[:200],
                        added_by=added_by
                    )

                    await self.data_source_repo.add_raw_data_ref(
                        data_source_id,
                        ref,
                        session=session
                    )

                    # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    data_source.add_raw_data(
                        data_id=data_id,
                        data_type=data_type,
                        title=ref.title,
                        url=ref.url,
                        snippet=ref.snippet,
                        added_by=added_by
                    )

                    await self.data_source_repo.update_statistics(
                        data_source_id,
                        data_source.total_raw_data_count,
                        data_source.scheduled_data_count,
                        data_source.instant_data_count,
                        session=session
                    )

                    logger.info(
                        f"âœ… æ·»åŠ åŸå§‹æ•°æ®åˆ°æ•°æ®æº: {data_id} ({data_type}) â†’ {data_source_id} "
                        f"(çŠ¶æ€: {current_status} â†’ processing)"
                    )

                    return True

                except Exception as e:
                    logger.error(f"âŒ æ·»åŠ åŸå§‹æ•°æ®å¤±è´¥ï¼ˆäº‹åŠ¡å›æ»šï¼‰: {str(e)}")
                    raise

    async def remove_raw_data_from_source(
        self,
        data_source_id: str,
        data_id: str,
        data_type: str,
        removed_by: str
    ) -> bool:
        """ä»æ•°æ®æºç§»é™¤åŸå§‹æ•°æ®

        çŠ¶æ€åŒæ­¥ï¼šåŸå§‹æ•°æ® processing â†’ archived

        Args:
            data_source_id: æ•°æ®æºID
            data_id: åŸå§‹æ•°æ®ID
            data_type: æ•°æ®ç±»å‹ï¼ˆscheduledæˆ–instantï¼‰
            removed_by: ç§»é™¤è€…

        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨æˆ–ä¸å¯ç¼–è¾‘
        """
        # éªŒè¯æ•°æ®æº
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_edit():
            raise ValueError(
                f"Cannot remove data from data source in status '{data_source.status.value}'"
            )

        # è·å–åŸå§‹æ•°æ®é›†åˆ
        if data_type == "scheduled":
            collection = self.search_results_collection
        elif data_type == "instant":
            collection = self.instant_search_results_collection
        else:
            raise ValueError(f"Invalid data type: {data_type}")

        # ä½¿ç”¨äº‹åŠ¡åŒæ­¥æ›´æ–°
        async with await self.db.client.start_session() as session:
            async with session.start_transaction():
                try:
                    # 1. æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ â†’ archived
                    await collection.update_one(
                        {"id": data_id},
                        {
                            "$set": {
                                "status": "archived",
                                "updated_at": datetime.utcnow()
                            }
                        },
                        session=session
                    )

                    # 2. ä»æ•°æ®æºå¼•ç”¨åˆ—è¡¨ç§»é™¤
                    await self.data_source_repo.remove_raw_data_ref(
                        data_source_id,
                        data_id,
                        session=session
                    )

                    # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    data_source.remove_raw_data(data_id, removed_by)

                    await self.data_source_repo.update_statistics(
                        data_source_id,
                        data_source.total_raw_data_count,
                        data_source.scheduled_data_count,
                        data_source.instant_data_count,
                        session=session
                    )

                    logger.info(
                        f"âœ… ä»æ•°æ®æºç§»é™¤åŸå§‹æ•°æ®: {data_id} ({data_type}) â† {data_source_id} "
                        f"(çŠ¶æ€: processing â†’ archived)"
                    )

                    return True

                except Exception as e:
                    logger.error(f"âŒ ç§»é™¤åŸå§‹æ•°æ®å¤±è´¥ï¼ˆäº‹åŠ¡å›æ»šï¼‰: {str(e)}")
                    raise

    # ==========================================
    # æ•°æ®æºçŠ¶æ€ç®¡ç†ï¼ˆå¸¦äº‹åŠ¡ï¼‰
    # ==========================================

    async def confirm_data_source(
        self,
        data_source_id: str,
        confirmed_by: str
    ) -> bool:
        """ç¡®å®šæ•°æ®æº

        çŠ¶æ€è½¬æ¢ï¼šDRAFT â†’ CONFIRMED
        çŠ¶æ€åŒæ­¥ï¼šåŸå§‹æ•°æ® processing â†’ completed

        Args:
            data_source_id: æ•°æ®æºID
            confirmed_by: ç¡®å®šè€…

        Returns:
            æ˜¯å¦ç¡®å®šæˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨æˆ–ä¸å¯ç¡®å®š
        """
        # éªŒè¯æ•°æ®æº
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_confirm():
            raise ValueError(
                f"Cannot confirm data source in status '{data_source.status.value}' "
                f"or with no raw data (count: {data_source.total_raw_data_count})"
            )

        # ä½¿ç”¨äº‹åŠ¡åŒæ­¥æ›´æ–°
        async with await self.db.client.start_session() as session:
            async with session.start_transaction():
                try:
                    # 1. æ›´æ–°æ•°æ®æºçŠ¶æ€ â†’ CONFIRMED
                    data_source.confirm(confirmed_by)

                    await self.data_source_repo.update(
                        data_source_id,
                        {
                            "status": data_source.status.value,
                            "confirmed_by": data_source.confirmed_by,
                            "confirmed_at": data_source.confirmed_at,
                            "updated_by": data_source.updated_by
                        },
                        session=session
                    )

                    # 2. æ‰¹é‡æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ â†’ completed
                    scheduled_ids = data_source.get_raw_data_ids_by_type("scheduled")
                    instant_ids = data_source.get_raw_data_ids_by_type("instant")

                    if scheduled_ids:
                        await self.search_results_collection.update_many(
                            {"id": {"$in": scheduled_ids}},
                            {
                                "$set": {
                                    "status": "completed",
                                    "processed_at": datetime.utcnow()
                                }
                            },
                            session=session
                        )

                    if instant_ids:
                        await self.instant_search_results_collection.update_many(
                            {"id": {"$in": instant_ids}},
                            {
                                "$set": {
                                    "status": "completed",
                                    "updated_at": datetime.utcnow()
                                }
                            },
                            session=session
                        )

                    logger.info(
                        f"âœ… ç¡®å®šæ•°æ®æº: {data_source_id} "
                        f"(æ›´æ–°äº† {len(scheduled_ids)} æ¡scheduledæ•°æ®, "
                        f"{len(instant_ids)} æ¡instantæ•°æ® â†’ completed)"
                    )

                    return True

                except Exception as e:
                    logger.error(f"âŒ ç¡®å®šæ•°æ®æºå¤±è´¥ï¼ˆäº‹åŠ¡å›æ»šï¼‰: {str(e)}")
                    raise

    async def revert_data_source_to_draft(
        self,
        data_source_id: str,
        reverted_by: str
    ) -> bool:
        """æ¢å¤æ•°æ®æºä¸ºè‰ç¨¿

        çŠ¶æ€è½¬æ¢ï¼šCONFIRMED â†’ DRAFT
        çŠ¶æ€åŒæ­¥ï¼šåŸå§‹æ•°æ® completed â†’ processing

        Args:
            data_source_id: æ•°æ®æºID
            reverted_by: æ“ä½œè€…

        Returns:
            æ˜¯å¦æ¢å¤æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨æˆ–ä¸å¯æ¢å¤
        """
        # éªŒè¯æ•°æ®æº
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        if not data_source.can_revert_to_draft():
            raise ValueError(
                f"Cannot revert data source in status '{data_source.status.value}' to draft"
            )

        # ä½¿ç”¨äº‹åŠ¡åŒæ­¥æ›´æ–°
        async with await self.db.client.start_session() as session:
            async with session.start_transaction():
                try:
                    # 1. æ›´æ–°æ•°æ®æºçŠ¶æ€ â†’ DRAFT
                    data_source.revert_to_draft(reverted_by)

                    await self.data_source_repo.update(
                        data_source_id,
                        {
                            "status": data_source.status.value,
                            "confirmed_by": None,
                            "confirmed_at": None,
                            "updated_by": data_source.updated_by
                        },
                        session=session
                    )

                    # 2. æ‰¹é‡æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ â†’ processing
                    scheduled_ids = data_source.get_raw_data_ids_by_type("scheduled")
                    instant_ids = data_source.get_raw_data_ids_by_type("instant")

                    if scheduled_ids:
                        await self.search_results_collection.update_many(
                            {"id": {"$in": scheduled_ids}},
                            {
                                "$set": {
                                    "status": "processing",
                                    "processed_at": None
                                }
                            },
                            session=session
                        )

                    if instant_ids:
                        await self.instant_search_results_collection.update_many(
                            {"id": {"$in": instant_ids}},
                            {
                                "$set": {
                                    "status": "processing",
                                    "updated_at": datetime.utcnow()
                                }
                            },
                            session=session
                        )

                    logger.info(
                        f"âœ… æ¢å¤æ•°æ®æºä¸ºè‰ç¨¿: {data_source_id} "
                        f"(æ›´æ–°äº† {len(scheduled_ids)} æ¡scheduledæ•°æ®, "
                        f"{len(instant_ids)} æ¡instantæ•°æ® â†’ processing)"
                    )

                    return True

                except Exception as e:
                    logger.error(f"âŒ æ¢å¤æ•°æ®æºå¤±è´¥ï¼ˆäº‹åŠ¡å›æ»šï¼‰: {str(e)}")
                    raise

    async def delete_data_source(
        self,
        data_source_id: str,
        deleted_by: str
    ) -> bool:
        """åˆ é™¤æ•°æ®æº

        çŠ¶æ€åŒæ­¥ï¼š
        - è‰ç¨¿çŠ¶æ€ï¼šåŸå§‹æ•°æ® processing â†’ archived
        - å·²ç¡®å®šçŠ¶æ€ï¼šåŸå§‹æ•°æ®ä¿æŒ completedï¼ˆä¸å˜ï¼‰

        Args:
            data_source_id: æ•°æ®æºID
            deleted_by: åˆ é™¤è€…

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ

        Raises:
            ValueError: å¦‚æœæ•°æ®æºä¸å­˜åœ¨
        """
        # éªŒè¯æ•°æ®æº
        data_source = await self.get_data_source(data_source_id)
        if not data_source:
            raise ValueError(f"Data source '{data_source_id}' not found")

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€
        need_status_sync = (data_source.status == DataSourceStatus.DRAFT)

        # ä½¿ç”¨äº‹åŠ¡åŒæ­¥æ›´æ–°
        async with await self.db.client.start_session() as session:
            async with session.start_transaction():
                try:
                    # 1. å¦‚æœæ˜¯è‰ç¨¿çŠ¶æ€ï¼Œæ‰¹é‡æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ â†’ archived
                    if need_status_sync:
                        scheduled_ids = data_source.get_raw_data_ids_by_type("scheduled")
                        instant_ids = data_source.get_raw_data_ids_by_type("instant")

                        if scheduled_ids:
                            await self.search_results_collection.update_many(
                                {"id": {"$in": scheduled_ids}},
                                {
                                    "$set": {
                                        "status": "archived",
                                        "processed_at": datetime.utcnow()
                                    }
                                },
                                session=session
                            )

                        if instant_ids:
                            await self.instant_search_results_collection.update_many(
                                {"id": {"$in": instant_ids}},
                                {
                                    "$set": {
                                        "status": "archived",
                                        "updated_at": datetime.utcnow()
                                    }
                                },
                                session=session
                            )

                        logger.info(
                            f"ğŸ“Š æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€: {len(scheduled_ids)} æ¡scheduledæ•°æ®, "
                            f"{len(instant_ids)} æ¡instantæ•°æ® â†’ archived"
                        )

                    # 2. åˆ é™¤æ•°æ®æº
                    await self.data_source_repo.delete(data_source_id, session=session)

                    logger.info(
                        f"âœ… åˆ é™¤æ•°æ®æº: {data_source_id} "
                        f"(çŠ¶æ€: {data_source.status.value}, "
                        f"çŠ¶æ€åŒæ­¥: {'æ˜¯' if need_status_sync else 'å¦'})"
                    )

                    return True

                except Exception as e:
                    logger.error(f"âŒ åˆ é™¤æ•°æ®æºå¤±è´¥ï¼ˆäº‹åŠ¡å›æ»šï¼‰: {str(e)}")
                    raise

    # ==========================================
    # æ‰¹é‡æ“ä½œ
    # ==========================================

    async def batch_archive_raw_data(
        self,
        data_ids: List[str],
        data_type: str,
        updated_by: str
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç•™å­˜åŸå§‹æ•°æ®

        çŠ¶æ€æ›´æ–°ï¼šä»»æ„çŠ¶æ€ â†’ archived

        Args:
            data_ids: åŸå§‹æ•°æ®IDåˆ—è¡¨
            data_type: æ•°æ®ç±»å‹ï¼ˆscheduledæˆ–instantï¼‰
            updated_by: æ›´æ–°è€…

        Returns:
            æ“ä½œç»“æœç»Ÿè®¡
        """
        if data_type == "scheduled":
            collection = self.search_results_collection
        elif data_type == "instant":
            collection = self.instant_search_results_collection
        else:
            raise ValueError(f"Invalid data type: {data_type}")

        result = await collection.update_many(
            {"id": {"$in": data_ids}},
            {
                "$set": {
                    "status": "archived",
                    "updated_at": datetime.utcnow()
                }
            }
        )

        logger.info(
            f"âœ… æ‰¹é‡ç•™å­˜åŸå§‹æ•°æ®: {result.modified_count}/{len(data_ids)} æ¡ ({data_type})"
        )

        return {
            "total": len(data_ids),
            "updated": result.modified_count,
            "status": "archived"
        }

    async def batch_delete_raw_data(
        self,
        data_ids: List[str],
        data_type: str,
        deleted_by: str
    ) -> Dict[str, Any]:
        """æ‰¹é‡è½¯åˆ é™¤åŸå§‹æ•°æ®

        çŠ¶æ€æ›´æ–°ï¼šä»»æ„çŠ¶æ€ â†’ deleted

        Args:
            data_ids: åŸå§‹æ•°æ®IDåˆ—è¡¨
            data_type: æ•°æ®ç±»å‹ï¼ˆscheduledæˆ–instantï¼‰
            deleted_by: åˆ é™¤è€…

        Returns:
            æ“ä½œç»“æœç»Ÿè®¡
        """
        if data_type == "scheduled":
            collection = self.search_results_collection
        elif data_type == "instant":
            collection = self.instant_search_results_collection
        else:
            raise ValueError(f"Invalid data type: {data_type}")

        result = await collection.update_many(
            {"id": {"$in": data_ids}},
            {
                "$set": {
                    "status": "deleted",
                    "updated_at": datetime.utcnow()
                }
            }
        )

        logger.info(
            f"âœ… æ‰¹é‡åˆ é™¤åŸå§‹æ•°æ®: {result.modified_count}/{len(data_ids)} æ¡ ({data_type})"
        )

        return {
            "total": len(data_ids),
            "updated": result.modified_count,
            "status": "deleted"
        }
