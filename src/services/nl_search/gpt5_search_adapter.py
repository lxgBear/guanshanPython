"""
GPT-5 Search API é€‚é…å™¨ (api.gpt.ge)
ç”¨äºæ‰§è¡Œæœç´¢æŸ¥è¯¢å¹¶è¿”å› URL å’Œæ ‡é¢˜åˆ—è¡¨

æ¶æ„å‡çº§ v2.0:
- ä½¿ç”¨ gpt-5-search-api æ¨¡å‹ (api.gpt.ge)
- æ ‡å‡† OpenAI chat/completions æ¥å£
- æ”¯æŒæµ‹è¯•æ¨¡å¼ï¼ˆè¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼‰
- å¼‚æ­¥ HTTP å®¢æˆ·ç«¯
- é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
- ç»“æœè¿‡æ»¤å’Œæ’åº
- URL annotations è§£æ
"""
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
import asyncio

try:
    import httpx
    from tenacity import (
        retry,
        stop_after_attempt,
        wait_exponential,
        retry_if_exception_type
    )
except ImportError:
    httpx = None
    retry = None
    stop_after_attempt = None
    wait_exponential = None
    retry_if_exception_type = None

from src.services.nl_search.config import nl_search_config


logger = logging.getLogger(__name__)


class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç±»"""

    def __init__(
        self,
        title: str,
        url: str,
        snippet: str = "",
        position: int = 0,
        score: float = 0.0,
        source: str = "search"
    ):
        self.title = title
        self.url = url
        self.snippet = snippet
        self.position = position
        self.score = score
        self.source = source

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "title": self.title,
            "url": self.url,
            "snippet": self.snippet,
            "position": self.position,
            "score": self.score,
            "source": self.source
        }


class GPT5SearchAdapter:
    """GPT-5 Search API é€‚é…å™¨ (api.gpt.ge)

    åŠŸèƒ½:
    - ä½¿ç”¨ gpt-5-search-api æ¨¡å‹æ‰§è¡Œæœç´¢æŸ¥è¯¢
    - è¿”å› URLã€æ ‡é¢˜å’Œå†…å®¹æ‘˜è¦
    - æ”¯æŒæµ‹è¯•æ¨¡å¼å’ŒçœŸå® API
    - ç»“æœè¿‡æ»¤å’Œæ’åº
    - è§£æ URL annotations
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        test_mode: bool = False,
        timeout: int = 30
    ):
        """
        åˆå§‹åŒ–æœç´¢é€‚é…å™¨

        Args:
            api_key: api.gpt.ge API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            base_url: API Base URLï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            test_mode: æ˜¯å¦æµ‹è¯•æ¨¡å¼ï¼ˆè¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼‰
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.api_key = api_key or nl_search_config.llm_api_key
        self.base_url = base_url or nl_search_config.llm_base_url
        self.test_mode = test_mode
        self.timeout = timeout
        self.max_results = nl_search_config.max_search_results
        self.search_model = nl_search_config.search_model
        self.max_tokens = nl_search_config.search_max_tokens

        # HTTP å®¢æˆ·ç«¯
        if httpx is None:
            logger.warning("httpx åŒ…æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install httpx")
            self.client = None
        else:
            self.client = httpx.AsyncClient(
                timeout=httpx.Timeout(timeout),
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
            )

        # API ç«¯ç‚¹ (æ ‡å‡† OpenAI chat/completions)
        self.search_api_url = f"{self.base_url}/chat/completions"

        logger.info(
            f"GPT5SearchAdapter initialized: model={self.search_model}, "
            f"url={self.search_api_url}, test_mode={self.test_mode}"
        )

    async def search(
        self,
        query: str,
        max_results: Optional[int] = None,
        language: str = "zh-cn"
    ) -> List[SearchResult]:
        """
        æ‰§è¡Œæœç´¢æŸ¥è¯¢

        Args:
            query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
            max_results: æœ€å¤§ç»“æœæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            language: æœç´¢è¯­è¨€ï¼ˆé»˜è®¤ä¸­æ–‡ï¼‰

        Returns:
            SearchResult åˆ—è¡¨

        Raises:
            Exception: æœç´¢å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        if not query or not query.strip():
            logger.warning("æœç´¢æŸ¥è¯¢ä¸ºç©º")
            return []

        max_results = max_results or self.max_results

        # æµ‹è¯•æ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿæ•°æ®
        if self.test_mode:
            logger.info(f"[æµ‹è¯•æ¨¡å¼] æœç´¢æŸ¥è¯¢: {query}")
            return self._generate_test_results(query, max_results)

        # çœŸå®æœç´¢
        if not self.api_key:
            logger.error("æœç´¢ API Key æœªé…ç½®")
            raise ValueError("æœç´¢ API Key æœªé…ç½®ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")

        if not self.client:
            logger.error("HTTP å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            raise RuntimeError("HTTP å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæœç´¢")

        try:
            # è°ƒç”¨æœç´¢ APIï¼ˆå¸¦é‡è¯•ï¼‰
            results = await self._execute_search_with_retry(
                query=query,
                max_results=max_results,
                language=language
            )

            logger.info(f"æœç´¢æˆåŠŸ: {query} -> {len(results)} ä¸ªç»“æœ")
            return results

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}", exc_info=True)
            raise

    async def _execute_search_with_retry(
        self,
        query: str,
        max_results: int,
        language: str
    ) -> List[SearchResult]:
        """
        æ‰§è¡Œæœç´¢ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰

        ä½¿ç”¨ tenacity åº“å®ç°é‡è¯•ï¼š
        - æœ€å¤šé‡è¯• 3 æ¬¡
        - æŒ‡æ•°é€€é¿ï¼ˆ1s, 2s, 4sï¼‰
        - ä»…å¯¹ç½‘ç»œé”™è¯¯é‡è¯•
        """
        if retry is None:
            # å¦‚æœ tenacity æœªå®‰è£…ï¼Œç›´æ¥æ‰§è¡Œ
            return await self._execute_search(query, max_results, language)

        # å®šä¹‰é‡è¯•è£…é¥°å™¨
        @retry(
            stop=stop_after_attempt(3),
            wait=wait_exponential(multiplier=1, min=1, max=10),
            retry=retry_if_exception_type((
                httpx.TimeoutException,
                httpx.ConnectError,
                httpx.NetworkError
            )),
            reraise=True
        )
        async def _search_with_retry():
            return await self._execute_search(query, max_results, language)

        return await _search_with_retry()

    async def _execute_search(
        self,
        query: str,
        max_results: int,
        language: str
    ) -> List[SearchResult]:
        """
        æ‰§è¡Œæœç´¢ API è°ƒç”¨ (gpt-5-search-api via chat/completions)
        """
        # æ„å»ºè¯·æ±‚ä½“ (OpenAI chat/completions format)
        payload = self._build_search_payload(query, language)

        # å‘é€è¯·æ±‚
        logger.debug(f"å‘é€æœç´¢è¯·æ±‚: {self.search_api_url}")
        logger.debug(f"Payload: {json.dumps(payload, ensure_ascii=False)}")

        response = await self.client.post(self.search_api_url, json=payload)

        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != 200:
            error_msg = f"æœç´¢ API è¿”å›é”™è¯¯: {response.status_code}, {response.text}"
            logger.error(error_msg)
            raise Exception(error_msg)

        # è§£æå“åº”
        try:
            data = response.json()
            results = self._parse_gpt5_search_response(data)

            # ç»“æœè¿‡æ»¤å’Œæ’åº
            results = self._filter_and_sort_results(results, max_results)

            logger.info(f"æœç´¢æˆåŠŸè§£æ: {len(results)} ä¸ªç»“æœ")

            # æ§åˆ¶å°æ‰“å°æœç´¢ç»“æœ
            self._print_search_results(query, results)

            return results

        except json.JSONDecodeError as e:
            logger.error(f"æœç´¢ç»“æœè§£æå¤±è´¥: {e}")
            raise
        except Exception as e:
            logger.error(f"æœç´¢ç»“æœå¤„ç†å¤±è´¥: {e}", exc_info=True)
            raise

    def _build_search_payload(
        self,
        query: str,
        language: str
    ) -> Dict[str, Any]:
        """
        æ„å»ºæœç´¢ API è¯·æ±‚ä½“ (OpenAI chat/completions format)

        å‚æ•°:
        - model: gpt-5-search-api
        - messages: ç”¨æˆ·æŸ¥è¯¢
        - max_tokens: æœ€å¤§å“åº” tokens
        """
        # æ„å»ºæœç´¢æç¤ºè¯
        search_prompt = f"æœç´¢: {query}"
        if language and language != "zh-cn":
            search_prompt = f"Search: {query}"

        return {
            "model": self.search_model,
            "messages": [
                {
                    "role": "user",
                    "content": search_prompt
                }
            ],
            "max_tokens": self.max_tokens,
            "temperature": 0.3  # æœç´¢ä»»åŠ¡ä½¿ç”¨è¾ƒä½æ¸©åº¦
        }

    def _parse_gpt5_search_response(self, data: Dict[str, Any]) -> List[SearchResult]:
        """
        è§£æ gpt-5-search-api å“åº”

        OpenAI chat/completions å“åº”æ ¼å¼:
        {
            "id": "chatcmpl-...",
            "object": "chat.completion",
            "model": "gpt-5-search-api-2025-10-14",
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "æœç´¢ç»“æœå†…å®¹...",
                    "annotations": [{
                        "type": "url_citation",
                        "url_citation": {
                            "url": "https://example.com",
                            "title": "æ ‡é¢˜",
                            "start_index": 0,
                            "end_index": 100
                        }
                    }]
                }
            }]
        }
        """
        results = []

        try:
            # æå– choice
            choices = data.get("choices", [])
            if not choices:
                logger.warning("å“åº”ä¸­æ²¡æœ‰ choices")
                return results

            first_choice = choices[0]
            message = first_choice.get("message", {})

            # æå–ä¸»è¦å†…å®¹
            content = message.get("content", "")

            # æå– URL annotations
            annotations = message.get("annotations", [])

            # è§£ææ¯ä¸ª annotation
            for idx, annotation in enumerate(annotations):
                try:
                    if annotation.get("type") == "url_citation":
                        url_citation = annotation.get("url_citation", {})

                        # æå– URL å’Œæ ‡é¢˜
                        url = url_citation.get("url", "")
                        title = url_citation.get("title", "")
                        start_idx = url_citation.get("start_index", 0)
                        end_idx = url_citation.get("end_index", 0)

                        # æå–å†…å®¹ç‰‡æ®µä½œä¸º snippet
                        snippet = content[start_idx:end_idx] if start_idx < end_idx else ""

                        if url:
                            result = SearchResult(
                                title=title or url,
                                url=url,
                                snippet=snippet[:200],  # é™åˆ¶æ‘˜è¦é•¿åº¦
                                position=idx + 1,
                                score=1.0 - (idx * 0.05),  # åˆ†æ•°é€’å‡
                                source="gpt-5-search-api"
                            )
                            results.append(result)

                except Exception as e:
                    logger.warning(f"è§£æ annotation å¤±è´¥: {e}, annotation={annotation}")
                    continue

            # å¦‚æœæ²¡æœ‰ annotations,å°è¯•ä»å†…å®¹ä¸­æå–
            if not results:
                logger.warning("å“åº”ä¸­æ²¡æœ‰ URL annotations,ä½¿ç”¨å†…å®¹ä½œä¸ºå•ä¸€ç»“æœ")
                if content:
                    results.append(SearchResult(
                        title="æœç´¢ç»“æœ",
                        url="",
                        snippet=content[:500],
                        position=1,
                        score=1.0,
                        source="gpt-5-search-api"
                    ))

        except Exception as e:
            logger.error(f"è§£æ GPT-5 æœç´¢å“åº”å¤±è´¥: {e}, data={data}")
            raise

        return results

    def _filter_and_sort_results(
        self,
        results: List[SearchResult],
        max_results: int
    ) -> List[SearchResult]:
        """
        è¿‡æ»¤å’Œæ’åºæœç´¢ç»“æœ

        ç­–ç•¥:
        1. å»é‡ï¼ˆç›¸åŒ URLï¼‰
        2. æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åº
        3. é™åˆ¶ç»“æœæ•°é‡
        """
        # 1. å»é‡
        seen_urls = set()
        unique_results = []

        for result in results:
            if result.url not in seen_urls:
                seen_urls.add(result.url)
                unique_results.append(result)

        # 2. æ’åºï¼ˆæŒ‰ score é™åºï¼Œå†æŒ‰ position å‡åºï¼‰
        unique_results.sort(key=lambda r: (-r.score, r.position))

        # 3. é™åˆ¶æ•°é‡
        return unique_results[:max_results]

    def _print_search_results(self, query: str, results: List[SearchResult]) -> None:
        """
        åœ¨æ§åˆ¶å°æ‰“å°æœç´¢ç»“æœ

        Args:
            query: æœç´¢æŸ¥è¯¢
            results: æœç´¢ç»“æœåˆ—è¡¨
        """
        print("\n" + "=" * 80)
        print(f"ğŸ” æœç´¢æŸ¥è¯¢: {query}")
        print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªç»“æœ (æœ€å¤šæ˜¾ç¤º5æ¡)")
        print("=" * 80)

        for idx, result in enumerate(results[:5], 1):
            print(f"\n[{idx}] {result.title}")
            print(f"    ğŸ”— URL: {result.url}")
            if result.snippet:
                # é™åˆ¶æ‘˜è¦æ˜¾ç¤ºé•¿åº¦
                snippet = result.snippet[:150] + "..." if len(result.snippet) > 150 else result.snippet
                print(f"    ğŸ“ æ‘˜è¦: {snippet}")
            print(f"    â­ è¯„åˆ†: {result.score:.2f} | æ¥æº: {result.source}")

        print("\n" + "=" * 80 + "\n")

    def _generate_test_results(
        self,
        query: str,
        max_results: int
    ) -> List[SearchResult]:
        """
        ç”Ÿæˆæµ‹è¯•æ¨¡å¼çš„æ¨¡æ‹Ÿç»“æœ

        æ ¹æ®æŸ¥è¯¢å…³é”®è¯ç”Ÿæˆç›¸å…³çš„æ¨¡æ‹Ÿæ•°æ®
        """
        # æ¨¡æ‹Ÿæ•°æ®æ¨¡æ¿
        templates = [
            {
                "title": f"{query} - æœ€æ–°æŠ€æœ¯è§£æ",
                "url": f"https://example.com/article/{query.replace(' ', '-')}-1",
                "snippet": f"æœ¬æ–‡æ·±å…¥åˆ†æäº†{query}çš„æœ€æ–°å‘å±•è¶‹åŠ¿å’ŒæŠ€æœ¯çªç ´...",
            },
            {
                "title": f"æ·±å…¥ç†è§£{query}ï¼šåŸç†ä¸å®è·µ",
                "url": f"https://example.com/tutorial/{query.replace(' ', '-')}-2",
                "snippet": f"ä»åŸºç¡€åˆ°é«˜çº§ï¼Œå…¨é¢è®²è§£{query}çš„æ ¸å¿ƒåŸç†å’Œå®æˆ˜åº”ç”¨...",
            },
            {
                "title": f"{query}å®Œæ•´æŒ‡å— - 2024ç‰ˆ",
                "url": f"https://example.com/guide/{query.replace(' ', '-')}-3",
                "snippet": f"2024å¹´æœ€å…¨é¢çš„{query}æŒ‡å—ï¼Œæ¶µç›–æœ€æ–°æŠ€æœ¯å’Œæœ€ä½³å®è·µ...",
            },
            {
                "title": f"{query}æ¡ˆä¾‹ç ”ç©¶ä¸åˆ†æ",
                "url": f"https://example.com/case/{query.replace(' ', '-')}-4",
                "snippet": f"é€šè¿‡çœŸå®æ¡ˆä¾‹åˆ†æ{query}åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„åº”ç”¨å’Œæ•ˆæœ...",
            },
            {
                "title": f"{query}æŠ€æœ¯åšå®¢ - å®˜æ–¹æ–‡æ¡£",
                "url": f"https://docs.example.com/{query.replace(' ', '-')}",
                "snippet": f"å®˜æ–¹æä¾›çš„{query}æŠ€æœ¯æ–‡æ¡£ã€APIå‚è€ƒå’Œæœ€ä½³å®è·µ...",
            },
            {
                "title": f"{query}ç¤¾åŒºè®¨è®ºç²¾é€‰",
                "url": f"https://forum.example.com/topic/{query.replace(' ', '-')}",
                "snippet": f"ç¤¾åŒºä¸“å®¶åˆ†äº«çš„{query}ä½¿ç”¨ç»éªŒå’Œé—®é¢˜è§£ç­”...",
            },
            {
                "title": f"{query}æ€§èƒ½ä¼˜åŒ–æŒ‡å—",
                "url": f"https://example.com/performance/{query.replace(' ', '-')}",
                "snippet": f"ä¼˜åŒ–{query}æ€§èƒ½çš„å®ç”¨æŠ€å·§å’Œå·¥å…·æ¨è...",
            },
            {
                "title": f"{query}å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ",
                "url": f"https://example.com/faq/{query.replace(' ', '-')}",
                "snippet": f"æ±‡æ€»{query}ä½¿ç”¨è¿‡ç¨‹ä¸­çš„å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ...",
            },
            {
                "title": f"{query}å¼€æºé¡¹ç›®æ¨è",
                "url": f"https://github.com/awesome/{query.replace(' ', '-')}",
                "snippet": f"ä¼˜è´¨çš„{query}ç›¸å…³å¼€æºé¡¹ç›®å’Œå·¥å…·åº“...",
            },
            {
                "title": f"{query}æœ€æ–°åŠ¨æ€ - è¡Œä¸šèµ„è®¯",
                "url": f"https://news.example.com/{query.replace(' ', '-')}",
                "snippet": f"å…³äº{query}çš„æœ€æ–°è¡Œä¸šåŠ¨æ€å’ŒæŠ€æœ¯èµ„è®¯...",
            }
        ]

        # ç”Ÿæˆç»“æœ
        results = []
        for i, template in enumerate(templates[:max_results]):
            result = SearchResult(
                title=template["title"],
                url=template["url"],
                snippet=template["snippet"],
                position=i + 1,
                score=1.0 - (i * 0.05),  # åˆ†æ•°é€’å‡
                source="test"
            )
            results.append(result)

        return results

    async def batch_search(
        self,
        queries: List[str],
        max_results_per_query: Optional[int] = None
    ) -> Dict[str, List[SearchResult]]:
        """
        æ‰¹é‡æœç´¢

        Args:
            queries: æœç´¢æŸ¥è¯¢åˆ—è¡¨
            max_results_per_query: æ¯ä¸ªæŸ¥è¯¢çš„æœ€å¤§ç»“æœæ•°

        Returns:
            å­—å…¸: {query: [SearchResult]}
        """
        if not queries:
            return {}

        max_results = max_results_per_query or self.max_results

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æœç´¢
        tasks = [
            self.search(query, max_results)
            for query in queries
        ]

        results_list = await asyncio.gather(*tasks, return_exceptions=True)

        # ç»„è£…ç»“æœ
        batch_results = {}
        for query, results in zip(queries, results_list):
            if isinstance(results, Exception):
                logger.error(f"æ‰¹é‡æœç´¢å¤±è´¥: {query} -> {results}")
                batch_results[query] = []
            else:
                batch_results[query] = results

        return batch_results

    async def close(self):
        """å…³é—­ HTTP å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close()
