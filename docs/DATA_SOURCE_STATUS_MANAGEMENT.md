# æ•°æ®æºçŠ¶æ€ç®¡ç†ä¸æ•´ç¼–åŠŸèƒ½ - æŠ€æœ¯è®¾è®¡æ–‡æ¡£

**ç‰ˆæœ¬**: v1.0.0
**åˆ›å»ºæ—¥æœŸ**: 2025-10-23
**å…³è”é¡¹ç›®**: Summary Report V2.0
**è®¾è®¡ç›®æ ‡**: ä¸ºåŸå§‹æœç´¢æ•°æ®æ·»åŠ ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œå®ç°æ•°æ®æºæ•´ç¼–æµç¨‹

---

## ğŸ“‹ ç›®å½•

1. [éœ€æ±‚åˆ†æ](#1-éœ€æ±‚åˆ†æ)
2. [æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
3. [æ•°æ®åº“è®¾è®¡](#3-æ•°æ®åº“è®¾è®¡)
4. [å®ä½“å±‚è®¾è®¡](#4-å®ä½“å±‚è®¾è®¡)
5. [APIè®¾è®¡](#5-apiè®¾è®¡)
6. [ä¸šåŠ¡æµç¨‹](#6-ä¸šåŠ¡æµç¨‹)
7. [æ•°æ®åº“è¿ç§»](#7-æ•°æ®åº“è¿ç§»)
8. [å®æ–½è®¡åˆ’](#8-å®æ–½è®¡åˆ’)
9. [æµ‹è¯•ç­–ç•¥](#9-æµ‹è¯•ç­–ç•¥)

---

## 1. éœ€æ±‚åˆ†æ

### 1.1 èƒŒæ™¯

å½“å‰ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
1. **æ•°æ®æ··ä¹±**ï¼šåŸå§‹æœç´¢ç»“æœæ²¡æœ‰çŠ¶æ€ç®¡ç†ï¼Œæ— æ³•åŒºåˆ†å·²å¤„ç†/æœªå¤„ç†æ•°æ®
2. **è´¨é‡ä½ä¸‹**ï¼šæ‰€æœ‰æœç´¢ç»“æœç›´æ¥ç”¨äºæŠ¥å‘Šç”Ÿæˆï¼Œæœªç»äººå·¥ç­›é€‰
3. **æ•°æ®é‡å¤**ï¼šç›¸åŒå†…å®¹å¯èƒ½è¢«å¤šæ¬¡ä½¿ç”¨ï¼Œç¼ºä¹æ•´ç¼–æœºåˆ¶
4. **å‰ç«¯æŠ¥é”™é£é™©**ï¼šç°æœ‰æ•°æ®åº“æ•°æ®ç¼ºå°‘statuså­—æ®µï¼ŒæŸ¥è¯¢å¯èƒ½å‡ºé”™

### 1.2 æ ¸å¿ƒéœ€æ±‚

#### éœ€æ±‚1ï¼šåŸå§‹æ•°æ®çŠ¶æ€ç®¡ç†

ä¸º`search_results`ï¼ˆå®šæ—¶ä»»åŠ¡ç»“æœï¼‰å’Œ`instant_search_results`ï¼ˆå³æ—¶æœç´¢ç»“æœï¼‰æ·»åŠ 5ç§çŠ¶æ€ï¼š

| çŠ¶æ€ | è‹±æ–‡æ ‡è¯† | è¯´æ˜ | åˆå§‹çŠ¶æ€ |
|------|---------|------|---------|
| å¾…å¤„ç† | `pending` | åˆšé‡‡é›†çš„åŸå§‹æ•°æ® | âœ… æ˜¯ |
| å·²ç•™å­˜ | `archived` | ç”¨æˆ·æ ‡è®°ä¸ºé‡è¦ï¼Œæš‚ä¸å¤„ç† | âŒ |
| å¤„ç†ä¸­ | `processing` | å·²è¢«é€‰ä¸­ç”¨äºæ•´ç¼–ï¼Œæ­£åœ¨æ•°æ®æºè¡¨ä¸­ç¼–è¾‘ | âŒ |
| å·²å®Œæˆ | `completed` | æ•´ç¼–å®Œæˆä¸”å®¡æ ¸é€šè¿‡ | âŒ |
| å·²åˆ é™¤ | `deleted` | è½¯åˆ é™¤ï¼Œä¿ç•™ç”¨äºå®¡è®¡ | âŒ |

#### éœ€æ±‚2ï¼šæ•°æ®æºæ•´ç¼–æµç¨‹

ç”¨æˆ·å·¥ä½œæµç¨‹ï¼š
```
1. æŸ¥çœ‹åŸå§‹æ•°æ®åˆ—è¡¨ï¼ˆpendingçŠ¶æ€ï¼‰
   â†“
2. è¿›å…¥å•æ¡æ•°æ®è¯¦æƒ…
   â†“
3. åˆ›å»º/ç¼–è¾‘æ•°æ®æºï¼ˆè¿›å…¥æ•°æ®æºè¡¨ï¼‰
   â†“
4. é€‰æ‹©å¤šæ¡åŸå§‹æ•°æ®è¿›è¡Œåˆå¹¶æ•´ç¼–
   â†“
5. ç”Ÿæˆå¯Œæ–‡æœ¬å†…å®¹ + åˆ†ç±»
   â†“
6. ä¿å­˜ â†’ åŸå§‹æ•°æ®çŠ¶æ€å˜ä¸º processing
   â†“
7. å®¡æ ¸é€šè¿‡ â†’ æ•°æ®æºå’ŒåŸå§‹æ•°æ®çŠ¶æ€å˜ä¸º completed
```

#### éœ€æ±‚3ï¼šæŸ¥è¯¢å¢å¼º

ä¸ºåŸå§‹æ•°æ®æŸ¥è¯¢æ·»åŠ ï¼š
- **çŠ¶æ€è¿‡æ»¤**ï¼šæ”¯æŒå¤šçŠ¶æ€ç­›é€‰
- **æ—¶é—´æŸ¥è¯¢**ï¼š
  - å‘å¸ƒæ—¶é—´èŒƒå›´ï¼ˆ`published_date`ï¼‰- å¯ä¸ºç©º
  - é‡‡é›†æ—¶é—´èŒƒå›´ï¼ˆ`created_at`/`first_found_at`ï¼‰- å¿…æœ‰å€¼
- **æ‰¹é‡æ“ä½œ**ï¼š
  - æ‰¹é‡ç•™å­˜ï¼ˆpending â†’ archivedï¼‰
  - æ‰¹é‡åˆ é™¤ï¼ˆpending/archived â†’ deletedï¼‰
  - ä¸šåŠ¡è§„åˆ™ï¼šprocessing/completedçŠ¶æ€ä¸èƒ½åˆ é™¤

#### éœ€æ±‚4ï¼šæ•°æ®è¿ç§»

ä¸ºé¿å…å‰ç«¯æŸ¥è¯¢å‡ºé”™ï¼Œå¿…é¡»ï¼š
1. ä¸ºæ‰€æœ‰ç°æœ‰`search_results`æ•°æ®æ·»åŠ `status`å­—æ®µï¼Œé»˜è®¤å€¼`pending`
2. ä¸ºæ‰€æœ‰ç°æœ‰`instant_search_results`æ•°æ®æ·»åŠ `status`å­—æ®µï¼Œé»˜è®¤å€¼`pending`
3. æ·»åŠ ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 æœ¯è¯­å®šä¹‰

| æœ¯è¯­ | å®šä¹‰ | å¯¹åº”è¡¨ |
|------|------|--------|
| **åŸå§‹æ•°æ®** | ä»æœç´¢å¼•æ“/çˆ¬è™«ç›´æ¥è·å–çš„æœªç»å¤„ç†çš„æ•°æ® | `search_results`, `instant_search_results` |
| **æ•°æ®æº** | ç»è¿‡äººå·¥æ•´ç¼–ã€åˆ†ç±»çš„é«˜è´¨é‡å†…å®¹ï¼Œå¯ç”¨äºç”ŸæˆæŠ¥å‘Š | `data_sources` |
| **æ•´ç¼–** | é€‰æ‹©å¤šæ¡åŸå§‹æ•°æ®ï¼Œåˆå¹¶ã€ç¼–è¾‘ã€åˆ†ç±»ï¼Œç”Ÿæˆå¯Œæ–‡æœ¬å†…å®¹ | ç”¨æˆ·æ“ä½œæµç¨‹ |
| **å®¡æ ¸é€šè¿‡** | æ•°æ®æºå†…å®¹ç»è¿‡å®¡æ ¸ï¼Œç¡®è®¤è´¨é‡ï¼Œå¯ç”¨äºæŠ¥å‘Šç”Ÿæˆ | çŠ¶æ€æµè½¬ |

### 2.2 çŠ¶æ€è½¬æ¢å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pending â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â”‚
     â”‚                      â”‚
     â”‚ æ‰¹é‡ç•™å­˜              â”‚ æ‰¹é‡åˆ é™¤
     â†“                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚ archived â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
     â”‚                      â”‚
     â”‚ é€‰æ‹©æ•´ç¼–              â”‚
     â†“                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ processing â”‚        â”‚ deleted â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ å®¡æ ¸é€šè¿‡
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ completed â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**çŠ¶æ€è½¬æ¢è§„åˆ™**ï¼š
- âœ… `pending` â†’ `archived` ï¼ˆæ‰¹é‡ç•™å­˜ï¼‰
- âœ… `pending` â†’ `processing` ï¼ˆåˆ›å»ºæ•°æ®æºå¹¶é€‰æ‹©ï¼‰
- âœ… `pending` â†’ `deleted` ï¼ˆæ‰¹é‡åˆ é™¤ï¼‰
- âœ… `archived` â†’ `processing` ï¼ˆåç»­é€‰æ‹©æ•´ç¼–ï¼‰
- âœ… `archived` â†’ `deleted` ï¼ˆåˆ é™¤ç•™å­˜æ•°æ®ï¼‰
- âœ… `processing` â†’ `completed` ï¼ˆå®¡æ ¸é€šè¿‡ï¼‰
- âŒ `processing` â†’ `deleted` ï¼ˆä¸å…è®¸åˆ é™¤ï¼‰
- âŒ `completed` â†’ `deleted` ï¼ˆä¸å…è®¸åˆ é™¤ï¼‰

### 2.3 æ•°æ®æµæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              åŸå§‹æ•°æ®é‡‡é›†å±‚                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å®šæ—¶ä»»åŠ¡æœç´¢ç»“æœ    â”‚    å³æ—¶æœç´¢ç»“æœ                â”‚
â”‚  (search_results)   â”‚  (instant_search_results)    â”‚
â”‚  status: pending    â”‚   status: pending            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                       â”‚
           â”‚  ç”¨æˆ·ç­›é€‰ + æ•´ç¼–      â”‚
           â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 æ•°æ®æºå±‚                              â”‚
â”‚              (data_sources)                          â”‚
â”‚  â€¢ å¯Œæ–‡æœ¬å†…å®¹ï¼ˆåˆå¹¶æ•´ç¼–ï¼‰                             â”‚
â”‚  â€¢ åˆ†ç±»æ ‡ç­¾                                          â”‚
â”‚  â€¢ è´¨é‡è¯„åˆ†                                          â”‚
â”‚  â€¢ çŠ¶æ€ï¼šdraft/completed                             â”‚
â”‚  â€¢ å…³è”åŸå§‹æ•°æ®IDåˆ—è¡¨                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚  ç”¨æˆ·é€‰æ‹©æ•°æ®æº
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            æ™ºèƒ½æ€»ç»“æŠ¥å‘Šå±‚                             â”‚
â”‚         (summary_reports)                            â”‚
â”‚  â€¢ é€‰æ‹©å¤šä¸ªæ•°æ®æº                                     â”‚
â”‚  â€¢ LLMç”Ÿæˆæ€»ç»“                                       â”‚
â”‚  â€¢ å¯Œæ–‡æœ¬ç¼–è¾‘                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. æ•°æ®åº“è®¾è®¡

### 3.1 ç°æœ‰è¡¨ä¿®æ”¹

#### 3.1.1 search_results è¡¨

**ä¿®æ”¹å†…å®¹**ï¼šæ·»åŠ `status`å­—æ®µ

```javascript
{
  "id": "UUID",
  "task_id": "UUID",

  // æ ¸å¿ƒæ•°æ®
  "title": "string",
  "url": "string",
  "content": "string",
  "snippet": "string",

  // å…ƒæ•°æ®
  "source": "string",
  "published_date": "datetime | null",  // å‘å¸ƒæ—¶é—´ï¼ˆå¯ä¸ºç©ºï¼‰
  "author": "string | null",
  "language": "string | null",

  // Firecrawl å­—æ®µ
  "markdown_content": "string | null",
  "html_content": "string | null",
  "metadata": "object",

  // è´¨é‡æŒ‡æ ‡
  "relevance_score": "float",
  "quality_score": "float",

  // âœ¨ æ–°å¢ï¼šçŠ¶æ€ç®¡ç†
  "status": "string",  // pending, archived, processing, completed, deleted

  // æ—¶é—´æˆ³
  "created_at": "datetime",  // é‡‡é›†æ—¶é—´
  "updated_at": "datetime",
  "processed_at": "datetime | null"
}
```

**ç´¢å¼•è®¾è®¡**ï¼š
```javascript
// 1. å¤åˆç´¢å¼•ï¼šçŠ¶æ€ + ä»»åŠ¡ + åˆ›å»ºæ—¶é—´ï¼ˆæ”¯æŒåˆ†é¡µæŸ¥è¯¢ï¼‰
db.search_results.createIndex(
  { "status": 1, "task_id": 1, "created_at": -1 }
)

// 2. å‘å¸ƒæ—¶é—´ç´¢å¼•ï¼ˆæ”¯æŒæ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼‰
db.search_results.createIndex({ "published_date": 1 })

// 3. é‡‡é›†æ—¶é—´ç´¢å¼•ï¼ˆæ”¯æŒæ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼‰
db.search_results.createIndex({ "created_at": 1 })
```

#### 3.1.2 instant_search_results è¡¨

**ä¿®æ”¹å†…å®¹**ï¼šæ·»åŠ `status`å­—æ®µ

```javascript
{
  "id": "string (é›ªèŠ±ID)",
  "task_id": "string",

  // æ ¸å¿ƒå†…å®¹
  "title": "string",
  "url": "string",
  "content": "string",
  "snippet": "string | null",

  // v1.3.0 å»é‡å’Œè§„èŒƒåŒ–
  "content_hash": "string",  // MD5(title + url + content)
  "url_normalized": "string",

  // Firecrawl å­—æ®µ
  "markdown_content": "string | null",
  "html_content": "string | null",

  // å…ƒæ•°æ®
  "source": "string",
  "published_date": "datetime | null",  // å‘å¸ƒæ—¶é—´ï¼ˆå¯ä¸ºç©ºï¼‰
  "author": "string | null",
  "language": "string | null",
  "metadata": "object",

  // è´¨é‡æŒ‡æ ‡
  "relevance_score": "float",
  "quality_score": "float",

  // v1.3.0 å‘ç°ç»Ÿè®¡
  "first_found_at": "datetime",  // é¦–æ¬¡å‘ç°æ—¶é—´ï¼ˆå¯ä½œä¸ºé‡‡é›†æ—¶é—´ï¼‰
  "last_found_at": "datetime",
  "found_count": "int",
  "unique_searches": "int",

  // âœ¨ æ–°å¢ï¼šçŠ¶æ€ç®¡ç†
  "status": "string",  // pending, archived, processing, completed, deleted

  // æ—¶é—´æˆ³
  "created_at": "datetime",
  "updated_at": "datetime"
}
```

**ç´¢å¼•è®¾è®¡**ï¼š
```javascript
// 1. å¤åˆç´¢å¼•ï¼šçŠ¶æ€ + ä»»åŠ¡ + é¦–æ¬¡å‘ç°æ—¶é—´
db.instant_search_results.createIndex(
  { "status": 1, "task_id": 1, "first_found_at": -1 }
)

// 2. å‘å¸ƒæ—¶é—´ç´¢å¼•
db.instant_search_results.createIndex({ "published_date": 1 })

// 3. é‡‡é›†æ—¶é—´ç´¢å¼•
db.instant_search_results.createIndex({ "first_found_at": 1 })
```

### 3.2 æ–°å¢è¡¨ï¼šdata_sources

**æ•°æ®æºè¡¨** - å­˜å‚¨ç»è¿‡æ•´ç¼–çš„é«˜è´¨é‡å†…å®¹

```javascript
{
  // ä¸»é”®
  "source_id": "string (é›ªèŠ±ID)",

  // æ ¸å¿ƒå†…å®¹
  "title": "string",
  "content": {
    "format": "markdown | html",
    "text": "string",  // å¯Œæ–‡æœ¬å†…å®¹
    "manual_edits": "boolean"
  },

  // åˆ†ç±»å’Œæ ‡ç­¾
  "category": "string",  // åˆ†ç±»ï¼ˆæ–°é—»ã€å­¦æœ¯ã€æ”¿ç­–ç­‰ï¼‰
  "tags": ["string"],    // æ ‡ç­¾åˆ—è¡¨

  // è´¨é‡ç®¡ç†
  "quality_score": "float",  // è´¨é‡è¯„åˆ† (0.0-1.0)
  "status": "string",        // draft, completed

  // å…³è”åŸå§‹æ•°æ®
  "raw_data_sources": [
    {
      "result_type": "search_result | instant_search_result",
      "result_id": "string | UUID",
      "included_at": "datetime"
    }
  ],
  "raw_data_count": "int",

  // å…ƒæ•°æ®
  "created_by": "string",
  "created_at": "datetime",
  "updated_at": "datetime",
  "approved_at": "datetime | null",
  "approved_by": "string | null",

  // ç»Ÿè®¡ä¿¡æ¯
  "view_count": "int",
  "usage_count": "int"  // è¢«å¤šå°‘æŠ¥å‘Šä½¿ç”¨
}
```

**ç´¢å¼•è®¾è®¡**ï¼š
```javascript
// 1. çŠ¶æ€ + åˆ†ç±»ç´¢å¼•
db.data_sources.createIndex({ "status": 1, "category": 1, "created_at": -1 })

// 2. æ ‡ç­¾ç´¢å¼•ï¼ˆæ”¯æŒæ ‡ç­¾ç­›é€‰ï¼‰
db.data_sources.createIndex({ "tags": 1 })

// 3. è´¨é‡è¯„åˆ†ç´¢å¼•
db.data_sources.createIndex({ "quality_score": -1 })

// 4. åˆ›å»ºè€…ç´¢å¼•
db.data_sources.createIndex({ "created_by": 1, "created_at": -1 })
```

### 3.3 æ•°æ®å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   search_results     â”‚
â”‚   (å®šæ—¶ä»»åŠ¡ç»“æœ)      â”‚
â”‚                      â”‚
â”‚ â€¢ status: pending    â”‚
â”‚ â€¢ published_date     â”‚
â”‚ â€¢ created_at         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ 1:N (ä¸€ä¸ªç»“æœå¯å±äºå¤šä¸ªæ•°æ®æº)
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   data_sources       â”‚
â”‚   (æ•´ç¼–åæ•°æ®æº)      â”‚
â”‚                      â”‚
â”‚ â€¢ raw_data_sources[] â”‚
â”‚ â€¢ status: draft/     â”‚
â”‚   completed          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†‘
           â”‚ 1:N
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚instant_search_resultsâ”‚
â”‚  (å³æ—¶æœç´¢ç»“æœ)       â”‚
â”‚                      â”‚
â”‚ â€¢ status: pending    â”‚
â”‚ â€¢ published_date     â”‚
â”‚ â€¢ first_found_at     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. å®ä½“å±‚è®¾è®¡

### 4.1 ä¿®æ”¹ ResultStatus æšä¸¾

**æ–‡ä»¶**: `src/core/domain/entities/search_result.py`

```python
from enum import Enum

class ResultStatus(Enum):
    """ç»“æœçŠ¶æ€æšä¸¾ - v2.0"""
    PENDING = "pending"         # å¾…å¤„ç†ï¼ˆåˆå§‹çŠ¶æ€ï¼‰
    ARCHIVED = "archived"       # å·²ç•™å­˜
    PROCESSING = "processing"   # å¤„ç†ä¸­ï¼ˆæ­£åœ¨æ•´ç¼–ï¼‰
    COMPLETED = "completed"     # å·²å®Œæˆï¼ˆæ•´ç¼–å®Œæˆå¹¶å®¡æ ¸é€šè¿‡ï¼‰
    DELETED = "deleted"         # å·²åˆ é™¤ï¼ˆè½¯åˆ é™¤ï¼‰
```

### 4.2 ä¿®æ”¹ SearchResult å®ä½“

**ä¿®æ”¹å†…å®¹**ï¼š
1. æ›´æ–°`status`å­—æ®µçš„æšä¸¾ç±»å‹
2. æ·»åŠ çŠ¶æ€è½¬æ¢æ–¹æ³•

```python
@dataclass
class SearchResult:
    """æœç´¢ç»“æœå®ä½“ - v2.0"""
    id: UUID = field(default_factory=uuid4)
    task_id: UUID = field(default_factory=uuid4)

    # ... å…¶ä»–å­—æ®µä¿æŒä¸å˜ ...

    # çŠ¶æ€ç®¡ç† - v2.0 æ›´æ–°
    status: ResultStatus = ResultStatus.PENDING
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)
    processed_at: Optional[datetime] = None

    def archive(self) -> None:
        """ç•™å­˜"""
        if self.status != ResultStatus.PENDING:
            raise ValueError(f"åªèƒ½ç•™å­˜pendingçŠ¶æ€çš„æ•°æ®ï¼Œå½“å‰çŠ¶æ€: {self.status.value}")
        self.status = ResultStatus.ARCHIVED
        self.updated_at = datetime.utcnow()

    def mark_as_processing(self) -> None:
        """æ ‡è®°ä¸ºå¤„ç†ä¸­"""
        if self.status not in [ResultStatus.PENDING, ResultStatus.ARCHIVED]:
            raise ValueError(f"åªèƒ½æ ‡è®°pendingæˆ–archivedçŠ¶æ€çš„æ•°æ®ä¸ºå¤„ç†ä¸­ï¼Œå½“å‰çŠ¶æ€: {self.status.value}")
        self.status = ResultStatus.PROCESSING
        self.updated_at = datetime.utcnow()

    def mark_as_completed(self) -> None:
        """æ ‡è®°ä¸ºå·²å®Œæˆ"""
        if self.status != ResultStatus.PROCESSING:
            raise ValueError(f"åªèƒ½æ ‡è®°processingçŠ¶æ€çš„æ•°æ®ä¸ºå·²å®Œæˆï¼Œå½“å‰çŠ¶æ€: {self.status.value}")
        self.status = ResultStatus.COMPLETED
        self.processed_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()

    def soft_delete(self) -> None:
        """è½¯åˆ é™¤"""
        if self.status in [ResultStatus.PROCESSING, ResultStatus.COMPLETED]:
            raise ValueError(f"ä¸èƒ½åˆ é™¤{self.status.value}çŠ¶æ€çš„æ•°æ®")
        self.status = ResultStatus.DELETED
        self.updated_at = datetime.utcnow()

    def can_delete(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ é™¤"""
        return self.status not in [ResultStatus.PROCESSING, ResultStatus.COMPLETED]
```

### 4.3 ä¿®æ”¹ InstantSearchResult å®ä½“

**æ–‡ä»¶**: `src/core/domain/entities/instant_search_result.py`

```python
@dataclass
class InstantSearchResult:
    """å³æ—¶æœç´¢ç»“æœå®ä½“ - v2.0"""
    id: str = field(default_factory=generate_string_id)
    task_id: str = ""

    # ... å…¶ä»–å­—æ®µä¿æŒä¸å˜ ...

    # âœ¨ æ–°å¢ï¼šçŠ¶æ€ç®¡ç†
    status: str = "pending"  # pending, archived, processing, completed, deleted

    # æ—¶é—´æˆ³
    first_found_at: datetime = field(default_factory=datetime.utcnow)
    last_found_at: datetime = field(default_factory=datetime.utcnow)
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

    def archive(self) -> None:
        """ç•™å­˜"""
        if self.status != "pending":
            raise ValueError(f"åªèƒ½ç•™å­˜pendingçŠ¶æ€çš„æ•°æ®ï¼Œå½“å‰çŠ¶æ€: {self.status}")
        self.status = "archived"
        self.updated_at = datetime.utcnow()

    def mark_as_processing(self) -> None:
        """æ ‡è®°ä¸ºå¤„ç†ä¸­"""
        if self.status not in ["pending", "archived"]:
            raise ValueError(f"åªèƒ½æ ‡è®°pendingæˆ–archivedçŠ¶æ€çš„æ•°æ®ä¸ºå¤„ç†ä¸­ï¼Œå½“å‰çŠ¶æ€: {self.status}")
        self.status = "processing"
        self.updated_at = datetime.utcnow()

    def mark_as_completed(self) -> None:
        """æ ‡è®°ä¸ºå·²å®Œæˆ"""
        if self.status != "processing":
            raise ValueError(f"åªèƒ½æ ‡è®°processingçŠ¶æ€çš„æ•°æ®ä¸ºå·²å®Œæˆï¼Œå½“å‰çŠ¶æ€: {self.status}")
        self.status = "completed"
        self.updated_at = datetime.utcnow()

    def soft_delete(self) -> None:
        """è½¯åˆ é™¤"""
        if self.status in ["processing", "completed"]:
            raise ValueError(f"ä¸èƒ½åˆ é™¤{self.status}çŠ¶æ€çš„æ•°æ®")
        self.status = "deleted"
        self.updated_at = datetime.utcnow()

    def can_delete(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆ é™¤"""
        return self.status not in ["processing", "completed"]
```

### 4.4 æ–°å¢ DataSource å®ä½“

**æ–‡ä»¶**: `src/core/domain/entities/data_source.py`

```python
"""æ•°æ®æºå®ä½“æ¨¡å‹"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Optional, Dict, Any, List

from src.infrastructure.id_generator import generate_string_id


class DataSourceStatus(Enum):
    """æ•°æ®æºçŠ¶æ€æšä¸¾"""
    DRAFT = "draft"           # è‰ç¨¿
    COMPLETED = "completed"   # å·²å®Œæˆï¼ˆå®¡æ ¸é€šè¿‡ï¼‰


class RawDataType(Enum):
    """åŸå§‹æ•°æ®ç±»å‹"""
    SEARCH_RESULT = "search_result"               # å®šæ—¶ä»»åŠ¡ç»“æœ
    INSTANT_SEARCH_RESULT = "instant_search_result"  # å³æ—¶æœç´¢ç»“æœ


@dataclass
class RawDataReference:
    """åŸå§‹æ•°æ®å¼•ç”¨"""
    result_type: str  # "search_result" æˆ– "instant_search_result"
    result_id: str    # åŸå§‹æ•°æ®ID
    included_at: datetime = field(default_factory=datetime.utcnow)


@dataclass
class DataSource:
    """
    æ•°æ®æºå®ä½“

    ç»è¿‡äººå·¥æ•´ç¼–çš„é«˜è´¨é‡å†…å®¹ï¼Œç”¨äºç”Ÿæˆæ™ºèƒ½æ€»ç»“æŠ¥å‘Š
    """
    # ä¸»é”®
    source_id: str = field(default_factory=generate_string_id)

    # æ ¸å¿ƒå†…å®¹
    title: str = ""
    content: Dict[str, Any] = field(default_factory=lambda: {
        "format": "markdown",
        "text": "",
        "manual_edits": False
    })

    # åˆ†ç±»å’Œæ ‡ç­¾
    category: str = ""
    tags: List[str] = field(default_factory=list)

    # è´¨é‡ç®¡ç†
    quality_score: float = 0.0  # 0.0-1.0
    status: DataSourceStatus = DataSourceStatus.DRAFT

    # å…³è”åŸå§‹æ•°æ®
    raw_data_sources: List[RawDataReference] = field(default_factory=list)
    raw_data_count: int = 0

    # å…ƒæ•°æ®
    created_by: str = ""
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)
    approved_at: Optional[datetime] = None
    approved_by: Optional[str] = None

    # ç»Ÿè®¡ä¿¡æ¯
    view_count: int = 0
    usage_count: int = 0

    def update_content(self, content_text: str, content_format: str = "markdown") -> None:
        """æ›´æ–°å†…å®¹"""
        self.content = {
            "format": content_format,
            "text": content_text,
            "manual_edits": True
        }
        self.updated_at = datetime.utcnow()

    def add_raw_data(self, result_type: str, result_id: str) -> None:
        """æ·»åŠ åŸå§‹æ•°æ®å¼•ç”¨"""
        ref = RawDataReference(
            result_type=result_type,
            result_id=result_id
        )
        self.raw_data_sources.append(ref)
        self.raw_data_count = len(self.raw_data_sources)
        self.updated_at = datetime.utcnow()

    def approve(self, approved_by: str) -> None:
        """å®¡æ ¸é€šè¿‡"""
        if self.status != DataSourceStatus.DRAFT:
            raise ValueError(f"åªèƒ½å®¡æ ¸draftçŠ¶æ€çš„æ•°æ®æºï¼Œå½“å‰çŠ¶æ€: {self.status.value}")

        self.status = DataSourceStatus.COMPLETED
        self.approved_at = datetime.utcnow()
        self.approved_by = approved_by
        self.updated_at = datetime.utcnow()

    def increment_view_count(self) -> None:
        """å¢åŠ æŸ¥çœ‹æ¬¡æ•°"""
        self.view_count += 1

    def increment_usage_count(self) -> None:
        """å¢åŠ ä½¿ç”¨æ¬¡æ•°"""
        self.usage_count += 1
```

---

## 5. APIè®¾è®¡

### 5.1 æŸ¥è¯¢å¢å¼º - å®šæ—¶ä»»åŠ¡ç»“æœ

**ç«¯ç‚¹**: `GET /api/v1/search-tasks/{task_id}/results`

**æŸ¥è¯¢å‚æ•°**ï¼š
```python
class SearchResultsQueryParams(BaseModel):
    # çŠ¶æ€è¿‡æ»¤
    status: Optional[List[str]] = Query(
        None,
        description="çŠ¶æ€åˆ—è¡¨: pending, archived, processing, completed, deleted"
    )

    # æ—¶é—´èŒƒå›´æŸ¥è¯¢
    published_start: Optional[datetime] = Query(None, description="å‘å¸ƒæ—¶é—´èµ·å§‹ï¼ˆå¯ä¸ºç©ºåˆ™å¿½ç•¥ï¼‰")
    published_end: Optional[datetime] = Query(None, description="å‘å¸ƒæ—¶é—´ç»“æŸ")
    crawled_start: Optional[datetime] = Query(None, description="é‡‡é›†æ—¶é—´èµ·å§‹")
    crawled_end: Optional[datetime] = Query(None, description="é‡‡é›†æ—¶é—´ç»“æŸ")

    # æ¸¸æ ‡åˆ†é¡µ
    cursor: Optional[str] = Query(None, description="åˆ†é¡µæ¸¸æ ‡")
    limit: int = Query(20, ge=1, le=100)
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "items": [
    {
      "id": "uuid",
      "task_id": "uuid",
      "title": "ç¼…ç”¸æ”¿æ²»æ–°é—»",
      "url": "https://example.com",
      "status": "pending",
      "published_date": "2025-10-20T10:00:00Z",
      "created_at": "2025-10-23T08:30:00Z",
      "relevance_score": 0.85,
      "quality_score": 0.78
    }
  ],
  "meta": {
    "has_next": true,
    "next_cursor": "eyJjcmVhdGVkX2F0IjogIjIwMjUtMTAtMjNUMDg6MDA6MDBaIn0=",
    "count": 20
  }
}
```

### 5.2 æŸ¥è¯¢å¢å¼º - å³æ—¶æœç´¢ç»“æœ

**ç«¯ç‚¹**: `GET /api/v1/instant-search/tasks/{task_id}/results`

**æŸ¥è¯¢å‚æ•°**ï¼šç›¸åŒç»“æ„ï¼Œæ—¶é—´å­—æ®µä½¿ç”¨`first_found_at`ä½œä¸ºé‡‡é›†æ—¶é—´

### 5.3 æ‰¹é‡ç•™å­˜

**ç«¯ç‚¹**: `POST /api/v1/search-tasks/results/batch-archive`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "result_ids": ["uuid1", "uuid2", "uuid3"],
  "result_type": "search_result"  // æˆ– "instant_search_result"
}
```

**å“åº”**ï¼š
```json
{
  "success_count": 2,
  "failed_count": 1,
  "failures": [
    {
      "result_id": "uuid3",
      "reason": "æ•°æ®çŠ¶æ€ä¸æ˜¯pendingï¼Œå½“å‰çŠ¶æ€: processing"
    }
  ]
}
```

### 5.4 æ‰¹é‡åˆ é™¤

**ç«¯ç‚¹**: `POST /api/v1/search-tasks/results/batch-delete`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "result_ids": ["uuid1", "uuid2"],
  "result_type": "search_result"
}
```

**å“åº”**ï¼š
```json
{
  "success_count": 1,
  "failed_count": 1,
  "failures": [
    {
      "result_id": "uuid2",
      "reason": "ä¸èƒ½åˆ é™¤processingæˆ–completedçŠ¶æ€çš„æ•°æ®"
    }
  ]
}
```

### 5.5 æ•°æ®æºç®¡ç†API

#### 5.5.1 åˆ›å»ºæ•°æ®æº

**ç«¯ç‚¹**: `POST /api/v1/data-sources/`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "title": "ç¼…ç”¸æ”¿æ²»å±€åŠ¿åˆ†æ",
  "category": "æ–°é—»",
  "tags": ["æ”¿æ²»", "ç¼…ç”¸", "ä¸œå—äºš"],
  "created_by": "user_id_123"
}
```

#### 5.5.2 å…³è”åŸå§‹æ•°æ®

**ç«¯ç‚¹**: `POST /api/v1/data-sources/{source_id}/raw-data`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "raw_data_items": [
    {
      "result_type": "search_result",
      "result_id": "uuid1"
    },
    {
      "result_type": "instant_search_result",
      "result_id": "snowflake_id_123"
    }
  ]
}
```

**ä¸šåŠ¡é€»è¾‘**ï¼š
1. éªŒè¯æ‰€æœ‰åŸå§‹æ•°æ®å­˜åœ¨ä¸”çŠ¶æ€ä¸ºpendingæˆ–archived
2. å°†åŸå§‹æ•°æ®çŠ¶æ€æ›´æ–°ä¸ºprocessing
3. å°†åŸå§‹æ•°æ®å¼•ç”¨æ·»åŠ åˆ°æ•°æ®æº
4. äº‹åŠ¡ä¿è¯ä¸€è‡´æ€§

#### 5.5.3 æ›´æ–°æ•°æ®æºå†…å®¹

**ç«¯ç‚¹**: `PUT /api/v1/data-sources/{source_id}/content`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "content_text": "# ç¼…ç”¸æ”¿æ²»å±€åŠ¿\n\nç»è¿‡æ•´åˆå¤šæ¡æ–°é—»...",
  "content_format": "markdown",
  "updated_by": "user_id_123"
}
```

#### 5.5.4 å®¡æ ¸é€šè¿‡

**ç«¯ç‚¹**: `POST /api/v1/data-sources/{source_id}/approve`

**è¯·æ±‚ä½“**ï¼š
```json
{
  "approved_by": "user_id_123"
}
```

**ä¸šåŠ¡é€»è¾‘**ï¼š
1. éªŒè¯æ•°æ®æºçŠ¶æ€ä¸ºdraft
2. æ›´æ–°æ•°æ®æºçŠ¶æ€ä¸ºcompleted
3. æ›´æ–°æ‰€æœ‰å…³è”åŸå§‹æ•°æ®çš„çŠ¶æ€ä¸ºcompleted
4. è®°å½•å®¡æ ¸æ—¶é—´å’Œå®¡æ ¸äºº

---

## 6. ä¸šåŠ¡æµç¨‹

### 6.1 å®Œæ•´å·¥ä½œæµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant API as APIæœåŠ¡
    participant DB as æ•°æ®åº“

    Note over U,DB: Step 1: æŸ¥çœ‹åŸå§‹æ•°æ®
    U->>API: GET /search-tasks/{id}/results?status=pending
    API->>DB: æŸ¥è¯¢pendingçŠ¶æ€çš„ç»“æœ
    DB-->>API: è¿”å›ç»“æœåˆ—è¡¨
    API-->>U: æ˜¾ç¤ºå¾…å¤„ç†æ•°æ®

    Note over U,DB: Step 2: åˆ›å»ºæ•°æ®æº
    U->>API: POST /data-sources/ {title, category}
    API->>DB: åˆ›å»ºæ•°æ®æºï¼ˆstatus=draftï¼‰
    DB-->>API: è¿”å› source_id
    API-->>U: æ•°æ®æºåˆ›å»ºæˆåŠŸ

    Note over U,DB: Step 3: é€‰æ‹©åŸå§‹æ•°æ®å¹¶å…³è”
    U->>API: POST /data-sources/{id}/raw-data {result_ids}
    API->>DB: æŸ¥è¯¢åŸå§‹æ•°æ®çŠ¶æ€
    DB-->>API: ç¡®è®¤çŠ¶æ€ä¸ºpending/archived
    API->>DB: æ›´æ–°åŸå§‹æ•°æ®çŠ¶æ€ä¸ºprocessing
    API->>DB: æ·»åŠ åŸå§‹æ•°æ®å¼•ç”¨åˆ°æ•°æ®æº
    API-->>U: å…³è”æˆåŠŸ

    Note over U,DB: Step 4: ç¼–è¾‘æ•´ç¼–å†…å®¹
    U->>API: PUT /data-sources/{id}/content {å¯Œæ–‡æœ¬}
    API->>DB: æ›´æ–°æ•°æ®æºå†…å®¹
    API-->>U: ä¿å­˜æˆåŠŸ

    Note over U,DB: Step 5: å®¡æ ¸é€šè¿‡
    U->>API: POST /data-sources/{id}/approve
    API->>DB: æ›´æ–°æ•°æ®æºçŠ¶æ€ä¸ºcompleted
    API->>DB: æ›´æ–°æ‰€æœ‰å…³è”åŸå§‹æ•°æ®ä¸ºcompleted
    API-->>U: å®¡æ ¸å®Œæˆ
```

### 6.2 æ‰¹é‡æ“ä½œæµç¨‹

```mermaid
flowchart TD
    A[ç”¨æˆ·é€‰æ‹©å¤šæ¡æ•°æ®] --> B{æ“ä½œç±»å‹}

    B -->|æ‰¹é‡ç•™å­˜| C[æ£€æŸ¥çŠ¶æ€]
    C --> C1{æ˜¯å¦ä¸ºpending?}
    C1 -->|æ˜¯| C2[æ›´æ–°ä¸ºarchived]
    C1 -->|å¦| C3[è®°å½•å¤±è´¥åŸå› ]

    B -->|æ‰¹é‡åˆ é™¤| D[æ£€æŸ¥çŠ¶æ€]
    D --> D1{æ˜¯å¦å¯åˆ é™¤?}
    D1 -->|æ˜¯| D2[æ›´æ–°ä¸ºdeleted]
    D1 -->|å¦| D3[è®°å½•å¤±è´¥åŸå› ]
    D1 -->|processing/completed| D4[æ‹’ç»åˆ é™¤]

    C2 --> E[è¿”å›æˆåŠŸå’Œå¤±è´¥ç»Ÿè®¡]
    C3 --> E
    D2 --> E
    D3 --> E
    D4 --> E
```

---

## 7. æ•°æ®åº“è¿ç§»

### 7.1 è¿ç§»è„šæœ¬è®¾è®¡

**æ–‡ä»¶**: `migrations/add_status_to_results.py`

```python
"""
æ•°æ®åº“è¿ç§»è„šæœ¬ï¼šä¸ºæœç´¢ç»“æœæ·»åŠ statuså­—æ®µ

æ‰§è¡Œæ—¶æœºï¼šéƒ¨ç½²å‰å¿…é¡»æ‰§è¡Œ
é£é™©ç­‰çº§ï¼šä¸­ç­‰ï¼ˆä¿®æ”¹ç°æœ‰æ•°æ®ï¼‰
å›æ»šæ–¹æ¡ˆï¼šå¯å›æ»šï¼ˆåˆ é™¤statuså­—æ®µï¼‰
"""

import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from datetime import datetime

from src.infrastructure.database.connection import get_mongodb_database
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def migrate_search_results_status():
    """ä¸ºsearch_resultsè¡¨æ·»åŠ statuså­—æ®µ"""
    db = await get_mongodb_database()
    collection = db.search_results

    # æ£€æŸ¥æ˜¯å¦å·²è¿ç§»
    sample = await collection.find_one({"status": {"$exists": True}})
    if sample:
        logger.info("âœ… search_resultsè¡¨å·²å­˜åœ¨statuså­—æ®µï¼Œè·³è¿‡è¿ç§»")
        return

    logger.info("å¼€å§‹è¿ç§»search_resultsè¡¨...")

    # ä¸ºæ‰€æœ‰ç°æœ‰æ–‡æ¡£æ·»åŠ statuså­—æ®µï¼Œé»˜è®¤å€¼ä¸ºpending
    result = await collection.update_many(
        {"status": {"$exists": False}},
        {
            "$set": {
                "status": "pending",
                "updated_at": datetime.utcnow()
            }
        }
    )

    logger.info(f"âœ… è¿ç§»å®Œæˆï¼šæ›´æ–°äº† {result.modified_count} æ¡è®°å½•")

    # åˆ›å»ºç´¢å¼•
    await collection.create_index(
        [("status", 1), ("task_id", 1), ("created_at", -1)],
        name="idx_status_task_created"
    )
    logger.info("âœ… åˆ›å»ºç´¢å¼•ï¼šidx_status_task_created")


async def migrate_instant_search_results_status():
    """ä¸ºinstant_search_resultsè¡¨æ·»åŠ statuså­—æ®µ"""
    db = await get_mongodb_database()
    collection = db.instant_search_results

    # æ£€æŸ¥æ˜¯å¦å·²è¿ç§»
    sample = await collection.find_one({"status": {"$exists": True}})
    if sample:
        logger.info("âœ… instant_search_resultsè¡¨å·²å­˜åœ¨statuså­—æ®µï¼Œè·³è¿‡è¿ç§»")
        return

    logger.info("å¼€å§‹è¿ç§»instant_search_resultsè¡¨...")

    # ä¸ºæ‰€æœ‰ç°æœ‰æ–‡æ¡£æ·»åŠ statuså­—æ®µ
    result = await collection.update_many(
        {"status": {"$exists": False}},
        {
            "$set": {
                "status": "pending",
                "updated_at": datetime.utcnow()
            }
        }
    )

    logger.info(f"âœ… è¿ç§»å®Œæˆï¼šæ›´æ–°äº† {result.modified_count} æ¡è®°å½•")

    # åˆ›å»ºç´¢å¼•
    await collection.create_index(
        [("status", 1), ("task_id", 1), ("first_found_at", -1)],
        name="idx_status_task_first_found"
    )
    logger.info("âœ… åˆ›å»ºç´¢å¼•ï¼šidx_status_task_first_found")


async def create_data_sources_collection():
    """åˆ›å»ºdata_sourcesé›†åˆå’Œç´¢å¼•"""
    db = await get_mongodb_database()

    # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨
    collections = await db.list_collection_names()
    if "data_sources" in collections:
        logger.info("âœ… data_sourcesé›†åˆå·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
        return

    logger.info("åˆ›å»ºdata_sourcesé›†åˆ...")
    collection = db.data_sources

    # åˆ›å»ºç´¢å¼•
    await collection.create_index(
        [("status", 1), ("category", 1), ("created_at", -1)],
        name="idx_status_category_created"
    )
    await collection.create_index([("tags", 1)], name="idx_tags")
    await collection.create_index([("quality_score", -1)], name="idx_quality_score")
    await collection.create_index(
        [("created_by", 1), ("created_at", -1)],
        name="idx_created_by_created"
    )

    logger.info("âœ… data_sourcesé›†åˆå’Œç´¢å¼•åˆ›å»ºå®Œæˆ")


async def verify_migration():
    """éªŒè¯è¿ç§»ç»“æœ"""
    db = await get_mongodb_database()

    # éªŒè¯search_results
    sr_count = await db.search_results.count_documents({"status": {"$exists": True}})
    sr_total = await db.search_results.count_documents({})
    logger.info(f"search_results: {sr_count}/{sr_total} æ¡è®°å½•æœ‰statuså­—æ®µ")

    # éªŒè¯instant_search_results
    isr_count = await db.instant_search_results.count_documents({"status": {"$exists": True}})
    isr_total = await db.instant_search_results.count_documents({})
    logger.info(f"instant_search_results: {isr_count}/{isr_total} æ¡è®°å½•æœ‰statuså­—æ®µ")

    # éªŒè¯data_sources
    collections = await db.list_collection_names()
    if "data_sources" in collections:
        logger.info("âœ… data_sourcesé›†åˆå­˜åœ¨")
    else:
        logger.warning("âš ï¸ data_sourcesé›†åˆä¸å­˜åœ¨")


async def rollback_migration():
    """å›æ»šè¿ç§»ï¼ˆä»…ç”¨äºç´§æ€¥æƒ…å†µï¼‰"""
    db = await get_mongodb_database()

    logger.warning("âš ï¸ å¼€å§‹å›æ»šè¿ç§»...")

    # åˆ é™¤statuså­—æ®µ
    await db.search_results.update_many(
        {},
        {"$unset": {"status": ""}}
    )
    await db.instant_search_results.update_many(
        {},
        {"$unset": {"status": ""}}
    )

    # åˆ é™¤ç´¢å¼•
    await db.search_results.drop_index("idx_status_task_created")
    await db.instant_search_results.drop_index("idx_status_task_first_found")

    logger.info("âœ… å›æ»šå®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("æ•°æ®æºçŠ¶æ€ç®¡ç† - æ•°æ®åº“è¿ç§»è„šæœ¬")
    logger.info("=" * 60)

    try:
        # æ‰§è¡Œè¿ç§»
        await migrate_search_results_status()
        await migrate_instant_search_results_status()
        await create_data_sources_collection()

        # éªŒè¯è¿ç§»
        await verify_migration()

        logger.info("=" * 60)
        logger.info("âœ… è¿ç§»å®Œæˆï¼")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ è¿ç§»å¤±è´¥: {str(e)}")
        logger.error("è¯·æ£€æŸ¥é”™è¯¯å¹¶è€ƒè™‘å›æ»š")
        raise


if __name__ == "__main__":
    asyncio.run(main())
```

### 7.2 è¿ç§»æ‰§è¡Œè®¡åˆ’

1. **å¤‡ä»½æ•°æ®åº“**ï¼ˆå¿…é¡»ï¼‰
   ```bash
   # å¤‡ä»½MongoDBæ•°æ®åº“
   mongodump --uri="mongodb://..." --out=./backups/before_status_migration
   ```

2. **æ‰§è¡Œè¿ç§»**
   ```bash
   # è¿è¡Œè¿ç§»è„šæœ¬
   python migrations/add_status_to_results.py
   ```

3. **éªŒè¯ç»“æœ**
   ```bash
   # æ£€æŸ¥è¿ç§»ç»“æœ
   python scripts/verify_status_migration.py
   ```

4. **å¦‚éœ€å›æ»š**
   ```bash
   # ç´§æ€¥å›æ»š
   python migrations/add_status_to_results.py --rollback

   # æˆ–æ¢å¤å¤‡ä»½
   mongorestore --uri="mongodb://..." ./backups/before_status_migration
   ```

---

## 8. å®æ–½è®¡åˆ’

### 8.1 å¼€å‘é˜¶æ®µ

**Phase 1: æ•°æ®åº“è¿ç§»ï¼ˆ1å¤©ï¼‰** - æœ€é«˜ä¼˜å…ˆçº§
- [ ] ç¼–å†™è¿ç§»è„šæœ¬
- [ ] æœ¬åœ°æµ‹è¯•è¿ç§»
- [ ] ç”Ÿäº§ç¯å¢ƒå¤‡ä»½
- [ ] æ‰§è¡Œè¿ç§»
- [ ] éªŒè¯ç»“æœ

**Phase 2: å®ä½“å±‚ä¿®æ”¹ï¼ˆ1å¤©ï¼‰**
- [ ] ä¿®æ”¹`ResultStatus`æšä¸¾
- [ ] æ›´æ–°`SearchResult`å®ä½“
- [ ] æ›´æ–°`InstantSearchResult`å®ä½“
- [ ] åˆ›å»º`DataSource`å®ä½“
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•

**Phase 3: ä»“å‚¨å±‚å®ç°ï¼ˆ1å¤©ï¼‰**
- [ ] ä¿®æ”¹`SearchResultRepository`
- [ ] ä¿®æ”¹`InstantSearchResultRepository`
- [ ] åˆ›å»º`DataSourceRepository`
- [ ] å®ç°æ‰¹é‡æ“ä½œæ–¹æ³•
- [ ] å®ç°çŠ¶æ€æŸ¥è¯¢æ–¹æ³•

**Phase 4: æœåŠ¡å±‚å®ç°ï¼ˆ2å¤©ï¼‰**
- [ ] å®ç°çŠ¶æ€è½¬æ¢æœåŠ¡
- [ ] å®ç°æ‰¹é‡æ“ä½œæœåŠ¡
- [ ] å®ç°æ•°æ®æºç®¡ç†æœåŠ¡
- [ ] å®ç°æŸ¥è¯¢å¢å¼ºæœåŠ¡
- [ ] ç¼–å†™æœåŠ¡å±‚æµ‹è¯•

**Phase 5: APIå±‚å®ç°ï¼ˆ2å¤©ï¼‰**
- [ ] å¢å¼ºæŸ¥è¯¢ç«¯ç‚¹
- [ ] å®ç°æ‰¹é‡æ“ä½œç«¯ç‚¹
- [ ] å®ç°æ•°æ®æºç®¡ç†ç«¯ç‚¹
- [ ] ç¼–å†™APIæµ‹è¯•
- [ ] æ›´æ–°APIæ–‡æ¡£

**Phase 6: é›†æˆæµ‹è¯•ï¼ˆ1å¤©ï¼‰**
- [ ] å®Œæ•´æµç¨‹æµ‹è¯•
- [ ] è¾¹ç•Œæ¡ä»¶æµ‹è¯•
- [ ] æ€§èƒ½æµ‹è¯•
- [ ] å¹¶å‘æµ‹è¯•

### 8.2 æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | å·¥ä½œé‡ | å…³é”®è·¯å¾„ |
|------|--------|---------|
| Phase 1 | 1å¤© | âœ… æ˜¯ |
| Phase 2 | 1å¤© | âœ… æ˜¯ |
| Phase 3 | 1å¤© | âœ… æ˜¯ |
| Phase 4 | 2å¤© | âœ… æ˜¯ |
| Phase 5 | 2å¤© | âœ… æ˜¯ |
| Phase 6 | 1å¤© | âœ… æ˜¯ |
| **æ€»è®¡** | **8å¤©** | |

### 8.3 é£é™©æ§åˆ¶

| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| æ•°æ®è¿ç§»å¤±è´¥ | é«˜ | ä½ | å®Œæ•´å¤‡ä»½ + å›æ»šè„šæœ¬ |
| å‰ç«¯æŸ¥è¯¢æŠ¥é”™ | é«˜ | ä¸­ | æ¸è¿›å¼éƒ¨ç½² + ç°åº¦æµ‹è¯• |
| æ€§èƒ½ä¸‹é™ | ä¸­ | ä¸­ | ç´¢å¼•ä¼˜åŒ– + æŸ¥è¯¢ä¼˜åŒ– |
| çŠ¶æ€ä¸ä¸€è‡´ | ä¸­ | ä½ | äº‹åŠ¡ä¿è¯ + éªŒè¯è„šæœ¬ |

---

## 9. æµ‹è¯•ç­–ç•¥

### 9.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/unit/test_result_status_management.py`

```python
import pytest
from datetime import datetime
from src.core.domain.entities.search_result import SearchResult, ResultStatus
from src.core.domain.entities.data_source import DataSource


class TestResultStatusTransitions:
    """æµ‹è¯•çŠ¶æ€è½¬æ¢é€»è¾‘"""

    def test_archive_from_pending(self):
        """æµ‹è¯•ä»pendingç•™å­˜ä¸ºarchived"""
        result = SearchResult(status=ResultStatus.PENDING)
        result.archive()
        assert result.status == ResultStatus.ARCHIVED

    def test_cannot_archive_from_processing(self):
        """æµ‹è¯•ä¸èƒ½ç•™å­˜processingçŠ¶æ€çš„æ•°æ®"""
        result = SearchResult(status=ResultStatus.PROCESSING)
        with pytest.raises(ValueError):
            result.archive()

    def test_mark_as_processing_from_pending(self):
        """æµ‹è¯•ä»pendingæ ‡è®°ä¸ºprocessing"""
        result = SearchResult(status=ResultStatus.PENDING)
        result.mark_as_processing()
        assert result.status == ResultStatus.PROCESSING

    def test_mark_as_completed_from_processing(self):
        """æµ‹è¯•ä»processingæ ‡è®°ä¸ºcompleted"""
        result = SearchResult(status=ResultStatus.PROCESSING)
        result.mark_as_completed()
        assert result.status == ResultStatus.COMPLETED
        assert result.processed_at is not None

    def test_can_delete_pending(self):
        """æµ‹è¯•å¯ä»¥åˆ é™¤pendingçŠ¶æ€"""
        result = SearchResult(status=ResultStatus.PENDING)
        assert result.can_delete() is True
        result.soft_delete()
        assert result.status == ResultStatus.DELETED

    def test_cannot_delete_processing(self):
        """æµ‹è¯•ä¸èƒ½åˆ é™¤processingçŠ¶æ€"""
        result = SearchResult(status=ResultStatus.PROCESSING)
        assert result.can_delete() is False
        with pytest.raises(ValueError):
            result.soft_delete()

    def test_cannot_delete_completed(self):
        """æµ‹è¯•ä¸èƒ½åˆ é™¤completedçŠ¶æ€"""
        result = SearchResult(status=ResultStatus.COMPLETED)
        assert result.can_delete() is False


class TestDataSourceManagement:
    """æµ‹è¯•æ•°æ®æºç®¡ç†"""

    def test_create_data_source(self):
        """æµ‹è¯•åˆ›å»ºæ•°æ®æº"""
        source = DataSource(
            title="æµ‹è¯•æ•°æ®æº",
            category="æ–°é—»",
            created_by="user_123"
        )
        assert source.status == DataSourceStatus.DRAFT
        assert source.raw_data_count == 0

    def test_add_raw_data_reference(self):
        """æµ‹è¯•æ·»åŠ åŸå§‹æ•°æ®å¼•ç”¨"""
        source = DataSource()
        source.add_raw_data("search_result", "uuid-123")
        assert len(source.raw_data_sources) == 1
        assert source.raw_data_count == 1

    def test_approve_data_source(self):
        """æµ‹è¯•å®¡æ ¸é€šè¿‡"""
        source = DataSource(status=DataSourceStatus.DRAFT)
        source.approve("admin_123")
        assert source.status == DataSourceStatus.COMPLETED
        assert source.approved_at is not None
        assert source.approved_by == "admin_123"
```

### 9.2 é›†æˆæµ‹è¯•

**æµ‹è¯•æ–‡ä»¶**: `tests/integration/test_data_source_workflow.py`

```python
import pytest
from httpx import AsyncClient

from src.main import app


@pytest.mark.asyncio
class TestDataSourceWorkflow:
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®æºæ•´ç¼–æµç¨‹"""

    async def test_complete_workflow(self, async_client: AsyncClient):
        """æµ‹è¯•å®Œæ•´æµç¨‹"""

        # Step 1: æŸ¥è¯¢pendingçŠ¶æ€çš„ç»“æœ
        response = await async_client.get(
            "/api/v1/search-tasks/test-task-id/results",
            params={"status": ["pending"]}
        )
        assert response.status_code == 200
        results = response.json()["items"]
        assert len(results) > 0
        result_id = results[0]["id"]

        # Step 2: åˆ›å»ºæ•°æ®æº
        response = await async_client.post(
            "/api/v1/data-sources/",
            json={
                "title": "æµ‹è¯•æ•°æ®æº",
                "category": "æ–°é—»",
                "created_by": "test_user"
            }
        )
        assert response.status_code == 201
        source_id = response.json()["source_id"]

        # Step 3: å…³è”åŸå§‹æ•°æ®
        response = await async_client.post(
            f"/api/v1/data-sources/{source_id}/raw-data",
            json={
                "raw_data_items": [
                    {
                        "result_type": "search_result",
                        "result_id": result_id
                    }
                ]
            }
        )
        assert response.status_code == 200

        # Step 4: éªŒè¯åŸå§‹æ•°æ®çŠ¶æ€å˜ä¸ºprocessing
        response = await async_client.get(
            f"/api/v1/search-results/{result_id}"
        )
        assert response.json()["status"] == "processing"

        # Step 5: æ›´æ–°æ•°æ®æºå†…å®¹
        response = await async_client.put(
            f"/api/v1/data-sources/{source_id}/content",
            json={
                "content_text": "# æµ‹è¯•å†…å®¹\n\nè¿™æ˜¯æ•´ç¼–åçš„å†…å®¹",
                "content_format": "markdown",
                "updated_by": "test_user"
            }
        )
        assert response.status_code == 200

        # Step 6: å®¡æ ¸é€šè¿‡
        response = await async_client.post(
            f"/api/v1/data-sources/{source_id}/approve",
            json={"approved_by": "admin"}
        )
        assert response.status_code == 200

        # Step 7: éªŒè¯æ•°æ®æºå’ŒåŸå§‹æ•°æ®éƒ½å˜ä¸ºcompleted
        response = await async_client.get(f"/api/v1/data-sources/{source_id}")
        assert response.json()["status"] == "completed"

        response = await async_client.get(f"/api/v1/search-results/{result_id}")
        assert response.json()["status"] == "completed"
```

### 9.3 æ€§èƒ½æµ‹è¯•

**æµ‹è¯•åœºæ™¯**ï¼š
1. æ‰¹é‡æŸ¥è¯¢10,000æ¡ç»“æœï¼ˆå¸¦çŠ¶æ€è¿‡æ»¤ï¼‰
2. æ‰¹é‡ç•™å­˜1,000æ¡ç»“æœ
3. æ‰¹é‡åˆ é™¤1,000æ¡ç»“æœ
4. å¹¶å‘åˆ›å»º100ä¸ªæ•°æ®æº

**æ€§èƒ½ç›®æ ‡**ï¼š
- æŸ¥è¯¢å“åº”æ—¶é—´ï¼š<500ms
- æ‰¹é‡æ“ä½œï¼š<2s
- å¹¶å‘åˆ›å»ºï¼š<5s

---

## 10. é™„å½•

### 10.1 UMLç±»å›¾

```mermaid
classDiagram
    class ResultStatus {
        <<enumeration>>
        PENDING
        ARCHIVED
        PROCESSING
        COMPLETED
        DELETED
    }

    class SearchResult {
        +UUID id
        +UUID task_id
        +string title
        +string url
        +string content
        +ResultStatus status
        +datetime published_date
        +datetime created_at
        +datetime updated_at
        +archive()
        +mark_as_processing()
        +mark_as_completed()
        +soft_delete()
        +can_delete() bool
    }

    class InstantSearchResult {
        +string id
        +string task_id
        +string title
        +string url
        +string content
        +string status
        +datetime published_date
        +datetime first_found_at
        +datetime updated_at
        +archive()
        +mark_as_processing()
        +mark_as_completed()
        +soft_delete()
        +can_delete() bool
    }

    class DataSourceStatus {
        <<enumeration>>
        DRAFT
        COMPLETED
    }

    class RawDataReference {
        +string result_type
        +string result_id
        +datetime included_at
    }

    class DataSource {
        +string source_id
        +string title
        +Dict content
        +string category
        +List~string~ tags
        +float quality_score
        +DataSourceStatus status
        +List~RawDataReference~ raw_data_sources
        +int raw_data_count
        +string created_by
        +datetime created_at
        +datetime approved_at
        +string approved_by
        +update_content()
        +add_raw_data()
        +approve()
        +increment_view_count()
    }

    SearchResult --> ResultStatus
    InstantSearchResult ..> ResultStatus : uses enum values
    DataSource --> DataSourceStatus
    DataSource --> RawDataReference
    DataSource ..> SearchResult : references
    DataSource ..> InstantSearchResult : references
```

### 10.2 çŠ¶æ€æœºå›¾

```mermaid
stateDiagram-v2
    [*] --> pending: æ•°æ®é‡‡é›†

    pending --> archived: æ‰¹é‡ç•™å­˜
    pending --> processing: åˆ›å»ºæ•°æ®æº
    pending --> deleted: æ‰¹é‡åˆ é™¤

    archived --> processing: åç»­æ•´ç¼–
    archived --> deleted: åˆ é™¤ç•™å­˜

    processing --> completed: å®¡æ ¸é€šè¿‡

    completed --> [*]
    deleted --> [*]

    note right of processing
        ä¸èƒ½åˆ é™¤
        æ­£åœ¨ç¼–è¾‘ä¸­
    end note

    note right of completed
        ä¸èƒ½åˆ é™¤
        å·²å®¡æ ¸é€šè¿‡
    end note
```

### 10.3 å‚è€ƒæ–‡æ¡£

- [Summary Report V2.0 Implementation](./SUMMARY_REPORT_V2_IMPLEMENTATION.md)
- [Summary Report V2.0 Cleanup Completed](../claudedocs/SUMMARY_REPORT_V2_CLEANUP_COMPLETED.md)
- [Firecrawl API Documentation](https://docs.firecrawl.dev)
- [MongoDB Update Operators](https://docs.mongodb.com/manual/reference/operator/update/)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-23
**ä½œè€…**: Claude Code
**å®¡æ ¸çŠ¶æ€**: å¾…å®¡æ ¸
