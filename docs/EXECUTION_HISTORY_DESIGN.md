# æœç´¢ä»»åŠ¡æ‰§è¡Œå†å²ç³»ç»Ÿè®¾è®¡

**ç‰ˆæœ¬**: 1.0
**æ—¥æœŸ**: 2025-10-24
**ç›®çš„**: ä¸ºå®šæ—¶æœç´¢ä»»åŠ¡æ·»åŠ è¯¦ç»†çš„æ‰§è¡Œå†å²è¿½è¸ª

---

## ğŸ“Š ç°çŠ¶åˆ†æ

### âœ… å·²å®ç°çš„çŠ¶æ€è¿½è¸ª

#### 1. InstantSearchTask (å³æ—¶æœç´¢)
- **çŠ¶æ€æšä¸¾**: `InstantSearchStatus` (PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)
- **çŠ¶æ€æ–¹æ³•**: `start_execution()`, `mark_as_completed()`, `mark_as_failed()`
- **æ—¶é—´æˆ³**: started_at, completed_at, updated_at
- **æ‰§è¡ŒæŒ‡æ ‡**: total_results, new_results, shared_results, credits_used, execution_time_ms
- **APIæ”¯æŒ**:
  - âœ… çŠ¶æ€å­—æ®µåœ¨å“åº”ä¸­è¿”å›
  - âœ… æ”¯æŒçŠ¶æ€è¿‡æ»¤æŸ¥è¯¢

#### 2. SearchTask (å®šæ—¶ä»»åŠ¡)
- **çŠ¶æ€æšä¸¾**: `TaskStatus` (ACTIVE, PAUSED, FAILED, COMPLETED, DISABLED)
- **çŠ¶æ€æ–¹æ³•**: `update_status()`, `record_execution()`
- **æ—¶é—´æˆ³**: last_executed_at, next_run_time, updated_at
- **ç»Ÿè®¡æŒ‡æ ‡**: execution_count, success_count, failure_count, total_results, total_credits_used
- **APIæ”¯æŒ**:
  - âœ… çŠ¶æ€å­—æ®µåœ¨å“åº”ä¸­è¿”å›
  - âœ… GET `/search-tasks/{task_id}/status`
  - âœ… PATCH `/search-tasks/{task_id}/status`
  - âœ… æ”¯æŒçŠ¶æ€è¿‡æ»¤æŸ¥è¯¢

### âŒ ç¼ºå¤±çš„åŠŸèƒ½

#### å®šæ—¶ä»»åŠ¡ç¼ºå°‘è¯¦ç»†æ‰§è¡Œå†å²
å½“å‰SearchTaskåªæœ‰èšåˆç»Ÿè®¡æ•°æ®ï¼Œç¼ºå°‘ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **å•æ¬¡æ‰§è¡Œè®°å½•**: æ— æ³•æŸ¥è¯¢æŸæ¬¡å…·ä½“æ‰§è¡Œçš„è¯¦æƒ…
2. **æ‰§è¡ŒçŠ¶æ€è¿½è¸ª**: ä¸çŸ¥é“æ¯æ¬¡æ‰§è¡ŒæˆåŠŸè¿˜æ˜¯å¤±è´¥
3. **é”™è¯¯å†å²**: ä¸çŸ¥é“ä»€ä¹ˆæ—¶å€™å¤±è´¥ã€å¤±è´¥åŸå› 
4. **æ€§èƒ½åˆ†æ**: æ— æ³•åˆ†ææ¯æ¬¡æ‰§è¡Œè€—æ—¶ã€ç§¯åˆ†æ¶ˆè€—
5. **å®¡è®¡è¿½è¸ª**: æ— æ³•è¿½æº¯å†å²æ‰§è¡Œæƒ…å†µ

---

## ğŸ¯ è®¾è®¡ç›®æ ‡

### æ ¸å¿ƒéœ€æ±‚
ä¸ºå®šæ—¶æœç´¢ä»»åŠ¡(SearchTask)æ·»åŠ è¯¦ç»†çš„æ‰§è¡Œå†å²è¿½è¸ªç³»ç»Ÿï¼Œå®ç°ï¼š

1. âœ… è®°å½•æ¯æ¬¡å®šæ—¶ä»»åŠ¡çš„æ‰§è¡Œè¯¦æƒ…
2. âœ… è¿½è¸ªæ‰§è¡ŒçŠ¶æ€ï¼ˆæˆåŠŸ/å¤±è´¥/è¿è¡Œä¸­ï¼‰
3. âœ… ä¿å­˜æ‰§è¡Œç»“æœç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡
4. âœ… æä¾›æ‰§è¡Œå†å²æŸ¥è¯¢API
5. âœ… æ”¯æŒé”™è¯¯è¯Šæ–­å’Œæ€§èƒ½åˆ†æ

---

## ğŸ“ æ•°æ®æ¨¡å‹è®¾è®¡

### 1. SearchTaskExecution å®ä½“

```python
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Optional, Dict, Any
from src.infrastructure.id_generator import generate_string_id


class ExecutionStatus(Enum):
    """æ‰§è¡ŒçŠ¶æ€æšä¸¾"""
    PENDING = "pending"       # å¾…æ‰§è¡Œ
    RUNNING = "running"       # æ‰§è¡Œä¸­
    COMPLETED = "completed"   # æ‰§è¡ŒæˆåŠŸ
    FAILED = "failed"         # æ‰§è¡Œå¤±è´¥
    SKIPPED = "skipped"       # å·²è·³è¿‡ï¼ˆä»»åŠ¡è¢«ç¦ç”¨ï¼‰


@dataclass
class SearchTaskExecution:
    """
    å®šæ—¶ä»»åŠ¡æ‰§è¡Œå†å²å®ä½“

    è®°å½•æ¯æ¬¡è°ƒåº¦å™¨æ‰§è¡Œå®šæ—¶ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯
    """
    # ä¸»é”®ï¼ˆé›ªèŠ±ç®—æ³•IDï¼‰
    id: str = field(default_factory=generate_string_id)

    # å…³è”ä»»åŠ¡
    task_id: str = ""  # å…³è”çš„SearchTask ID
    task_name: str = ""  # ä»»åŠ¡åç§°ï¼ˆå†—ä½™å­—æ®µï¼Œä¾¿äºæŸ¥è¯¢ï¼‰

    # æ‰§è¡Œä¿¡æ¯
    execution_number: int = 0  # æ‰§è¡Œåºå·ï¼ˆè¯¥ä»»åŠ¡çš„ç¬¬Næ¬¡æ‰§è¡Œï¼‰
    scheduled_time: datetime = field(default_factory=datetime.utcnow)  # è®¡åˆ’æ‰§è¡Œæ—¶é—´
    started_at: Optional[datetime] = None  # å®é™…å¼€å§‹æ—¶é—´
    completed_at: Optional[datetime] = None  # å®Œæˆæ—¶é—´
    execution_time_ms: int = 0  # æ‰§è¡Œè€—æ—¶ï¼ˆæ¯«ç§’ï¼‰

    # æ‰§è¡ŒçŠ¶æ€
    status: ExecutionStatus = ExecutionStatus.PENDING

    # æ‰§è¡Œç»“æœ
    total_results: int = 0  # æœ¬æ¬¡æœç´¢ç»“æœæ•°
    new_results: int = 0  # æ–°ç»“æœæ•°
    credits_used: int = 0  # æ¶ˆè€—ç§¯åˆ†

    # é”™è¯¯ä¿¡æ¯
    error_message: Optional[str] = None
    error_type: Optional[str] = None  # é”™è¯¯ç±»å‹ï¼ˆç½‘ç»œé”™è¯¯ã€APIé”™è¯¯ã€è¶…æ—¶ç­‰ï¼‰
    retry_count: int = 0  # é‡è¯•æ¬¡æ•°

    # å…ƒæ•°æ®
    search_config: Dict[str, Any] = field(default_factory=dict)  # æœ¬æ¬¡æ‰§è¡Œä½¿ç”¨çš„é…ç½®
    firecrawl_request_id: Optional[str] = None  # Firecrawlè¯·æ±‚IDï¼ˆç”¨äºè¿½è¸ªï¼‰

    # æ—¶é—´æˆ³
    created_at: datetime = field(default_factory=datetime.utcnow)
    updated_at: datetime = field(default_factory=datetime.utcnow)

    def start_execution(self) -> None:
        """å¼€å§‹æ‰§è¡Œ"""
        self.status = ExecutionStatus.RUNNING
        self.started_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()

    def mark_as_completed(
        self,
        total: int,
        new: int,
        credits: int,
        execution_time: int
    ) -> None:
        """æ ‡è®°ä¸ºæˆåŠŸå®Œæˆ"""
        self.status = ExecutionStatus.COMPLETED
        self.completed_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()

        self.total_results = total
        self.new_results = new
        self.credits_used = credits
        self.execution_time_ms = execution_time

    def mark_as_failed(
        self,
        error_message: str,
        error_type: str = "unknown"
    ) -> None:
        """æ ‡è®°ä¸ºå¤±è´¥"""
        self.status = ExecutionStatus.FAILED
        self.completed_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()

        self.error_message = error_message
        self.error_type = error_type

    def mark_as_skipped(self, reason: str) -> None:
        """æ ‡è®°ä¸ºè·³è¿‡"""
        self.status = ExecutionStatus.SKIPPED
        self.completed_at = datetime.utcnow()
        self.updated_at = datetime.utcnow()
        self.error_message = reason

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "id": self.id,
            "task_id": self.task_id,
            "task_name": self.task_name,
            "execution_number": self.execution_number,
            "scheduled_time": self.scheduled_time.isoformat() if self.scheduled_time else None,
            "started_at": self.started_at.isoformat() if self.started_at else None,
            "completed_at": self.completed_at.isoformat() if self.completed_at else None,
            "execution_time_ms": self.execution_time_ms,
            "status": self.status.value,
            "total_results": self.total_results,
            "new_results": self.new_results,
            "credits_used": self.credits_used,
            "error_message": self.error_message,
            "error_type": self.error_type,
            "retry_count": self.retry_count,
            "search_config": self.search_config,
            "firecrawl_request_id": self.firecrawl_request_id,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None
        }
```

### 2. MongoDB é›†åˆè®¾è®¡

**é›†åˆåç§°**: `search_task_executions`

**ç´¢å¼•ç­–ç•¥**:
```python
# 1. ä»»åŠ¡IDç´¢å¼•ï¼ˆæŸ¥è¯¢æŸä»»åŠ¡çš„æ‰€æœ‰æ‰§è¡Œå†å²ï¼‰
{"task_id": 1, "scheduled_time": -1}

# 2. çŠ¶æ€ç´¢å¼•ï¼ˆæŸ¥è¯¢å¤±è´¥çš„æ‰§è¡Œï¼‰
{"status": 1, "scheduled_time": -1}

# 3. æ—¶é—´ç´¢å¼•ï¼ˆæŸ¥è¯¢æœ€è¿‘æ‰§è¡Œï¼‰
{"scheduled_time": -1}

# 4. ç»„åˆç´¢å¼•ï¼ˆä»»åŠ¡+çŠ¶æ€æŸ¥è¯¢ï¼‰
{"task_id": 1, "status": 1, "scheduled_time": -1}
```

**æ•°æ®ç¤ºä¾‹**:
```json
{
  "_id": "1849365782347890690",
  "task_id": "1849365782347890688",
  "task_name": "ç¼…ç”¸æ–°é—»ç›‘æ§",
  "execution_number": 15,
  "scheduled_time": "2025-10-24T09:00:00Z",
  "started_at": "2025-10-24T09:00:01Z",
  "completed_at": "2025-10-24T09:00:03.5Z",
  "execution_time_ms": 2500,
  "status": "completed",
  "total_results": 12,
  "new_results": 3,
  "credits_used": 1,
  "error_message": null,
  "error_type": null,
  "retry_count": 0,
  "search_config": {
    "limit": 20,
    "include_domains": ["www.gnlm.com.mm"]
  },
  "firecrawl_request_id": "req_abc123",
  "created_at": "2025-10-24T09:00:00Z",
  "updated_at": "2025-10-24T09:00:03.5Z"
}
```

---

## ğŸ”§ ä»“å‚¨å±‚è®¾è®¡

### SearchTaskExecutionRepository

```python
from typing import List, Tuple, Optional
from motor.motor_asyncio import AsyncIOMotorDatabase
from src.core.domain.entities.search_task_execution import SearchTaskExecution, ExecutionStatus


class SearchTaskExecutionRepository:
    """æœç´¢ä»»åŠ¡æ‰§è¡Œå†å²ä»“å‚¨"""

    def __init__(self, db: AsyncIOMotorDatabase):
        self.collection = db.search_task_executions

    async def create(self, execution: SearchTaskExecution) -> SearchTaskExecution:
        """åˆ›å»ºæ‰§è¡Œè®°å½•"""
        execution_dict = execution.to_dict()
        await self.collection.insert_one({
            "_id": execution.id,
            **execution_dict
        })
        return execution

    async def update(self, execution: SearchTaskExecution) -> bool:
        """æ›´æ–°æ‰§è¡Œè®°å½•"""
        execution_dict = execution.to_dict()
        result = await self.collection.update_one(
            {"_id": execution.id},
            {"$set": execution_dict}
        )
        return result.modified_count > 0

    async def get_by_id(self, execution_id: str) -> Optional[SearchTaskExecution]:
        """æ ¹æ®IDè·å–æ‰§è¡Œè®°å½•"""
        doc = await self.collection.find_one({"_id": execution_id})
        if doc:
            return self._doc_to_entity(doc)
        return None

    async def list_by_task(
        self,
        task_id: str,
        page: int = 1,
        page_size: int = 20,
        status: Optional[str] = None
    ) -> Tuple[List[SearchTaskExecution], int]:
        """è·å–ä»»åŠ¡çš„æ‰§è¡Œå†å²åˆ—è¡¨"""
        query = {"task_id": task_id}

        if status:
            query["status"] = status

        # æ€»æ•°
        total = await self.collection.count_documents(query)

        # åˆ†é¡µæŸ¥è¯¢ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        skip = (page - 1) * page_size
        cursor = self.collection.find(query).sort("scheduled_time", -1).skip(skip).limit(page_size)

        executions = []
        async for doc in cursor:
            executions.append(self._doc_to_entity(doc))

        return executions, total

    async def get_latest_by_task(self, task_id: str) -> Optional[SearchTaskExecution]:
        """è·å–ä»»åŠ¡çš„æœ€æ–°æ‰§è¡Œè®°å½•"""
        doc = await self.collection.find_one(
            {"task_id": task_id},
            sort=[("scheduled_time", -1)]
        )
        if doc:
            return self._doc_to_entity(doc)
        return None

    async def get_statistics(self, task_id: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡çš„æ‰§è¡Œç»Ÿè®¡"""
        pipeline = [
            {"$match": {"task_id": task_id}},
            {"$group": {
                "_id": "$status",
                "count": {"$sum": 1},
                "avg_execution_time": {"$avg": "$execution_time_ms"},
                "total_results": {"$sum": "$total_results"},
                "total_credits": {"$sum": "$credits_used"}
            }}
        ]

        stats = {}
        async for doc in self.collection.aggregate(pipeline):
            stats[doc["_id"]] = {
                "count": doc["count"],
                "avg_execution_time_ms": doc["avg_execution_time"],
                "total_results": doc["total_results"],
                "total_credits": doc["total_credits"]
            }

        return stats

    def _doc_to_entity(self, doc: dict) -> SearchTaskExecution:
        """å°†MongoDBæ–‡æ¡£è½¬æ¢ä¸ºå®ä½“"""
        # å¤„ç†MongoDBçš„_idå­—æ®µ
        doc["id"] = doc.pop("_id", None)

        # è½¬æ¢statuså­—æ®µ
        if "status" in doc:
            doc["status"] = ExecutionStatus(doc["status"])

        return SearchTaskExecution(**doc)
```

---

## ğŸš€ è°ƒåº¦å™¨é›†æˆ

### ä¿®æ”¹ TaskScheduler

åœ¨ `src/services/task_scheduler.py` ä¸­é›†æˆæ‰§è¡Œå†å²è®°å½•ï¼š

```python
class TaskScheduler:
    def __init__(self, ...):
        # æ·»åŠ æ‰§è¡Œå†å²ä»“å‚¨
        self.execution_repository = SearchTaskExecutionRepository(db)

    async def execute_task(self, task: SearchTask):
        """æ‰§è¡Œä»»åŠ¡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        # 1. åˆ›å»ºæ‰§è¡Œè®°å½•
        execution = SearchTaskExecution(
            task_id=task.get_id_string(),
            task_name=task.name,
            execution_number=task.execution_count + 1,
            scheduled_time=datetime.utcnow(),
            search_config=task.search_config
        )
        await self.execution_repository.create(execution)

        # 2. æ ‡è®°ä¸ºè¿è¡Œä¸­
        execution.start_execution()
        await self.execution_repository.update(execution)

        try:
            # 3. æ‰§è¡Œæœç´¢
            start_time = datetime.utcnow()

            results = await self.search_service.execute_search(
                query=task.query,
                config=task.search_config
            )

            end_time = datetime.utcnow()
            execution_time_ms = int((end_time - start_time).total_seconds() * 1000)

            # 4. æ ‡è®°ä¸ºæˆåŠŸ
            execution.mark_as_completed(
                total=len(results),
                new=results.new_count,
                credits=results.credits_used,
                execution_time=execution_time_ms
            )
            await self.execution_repository.update(execution)

            # 5. æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
            task.record_execution(
                success=True,
                results_count=len(results),
                credits_used=results.credits_used
            )
            await self.task_repository.update(task)

        except Exception as e:
            # 6. æ ‡è®°ä¸ºå¤±è´¥
            execution.mark_as_failed(
                error_message=str(e),
                error_type=type(e).__name__
            )
            await self.execution_repository.update(execution)

            # 7. æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
            task.record_execution(success=False)
            await self.task_repository.update(task)

            logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.name}, é”™è¯¯: {e}")
```

---

## ğŸŒ API ç«¯ç‚¹è®¾è®¡

### 1. è·å–ä»»åŠ¡æ‰§è¡Œå†å²åˆ—è¡¨

```
GET /search-tasks/{task_id}/executions

Query Parameters:
- page: é¡µç ï¼ˆé»˜è®¤1ï¼‰
- page_size: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤20ï¼Œæœ€å¤§100ï¼‰
- status: çŠ¶æ€è¿‡æ»¤ï¼ˆpending, running, completed, failed, skippedï¼‰

Response:
{
  "executions": [
    {
      "id": "1849365782347890690",
      "task_id": "1849365782347890688",
      "task_name": "ç¼…ç”¸æ–°é—»ç›‘æ§",
      "execution_number": 15,
      "scheduled_time": "2025-10-24T09:00:00Z",
      "started_at": "2025-10-24T09:00:01Z",
      "completed_at": "2025-10-24T09:00:03.5Z",
      "execution_time_ms": 2500,
      "status": "completed",
      "total_results": 12,
      "new_results": 3,
      "credits_used": 1
    }
  ],
  "total": 150,
  "page": 1,
  "page_size": 20,
  "total_pages": 8
}
```

### 2. è·å–å•æ¬¡æ‰§è¡Œè¯¦æƒ…

```
GET /search-tasks/{task_id}/executions/{execution_id}

Response:
{
  "id": "1849365782347890690",
  "task_id": "1849365782347890688",
  "task_name": "ç¼…ç”¸æ–°é—»ç›‘æ§",
  "execution_number": 15,
  "scheduled_time": "2025-10-24T09:00:00Z",
  "started_at": "2025-10-24T09:00:01Z",
  "completed_at": "2025-10-24T09:00:03.5Z",
  "execution_time_ms": 2500,
  "status": "completed",
  "total_results": 12,
  "new_results": 3,
  "credits_used": 1,
  "error_message": null,
  "error_type": null,
  "search_config": {
    "limit": 20,
    "include_domains": ["www.gnlm.com.mm"]
  }
}
```

### 3. è·å–ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡

```
GET /search-tasks/{task_id}/executions/statistics

Response:
{
  "total_executions": 150,
  "successful_executions": 142,
  "failed_executions": 8,
  "success_rate": 94.67,
  "avg_execution_time_ms": 2340,
  "total_results": 1850,
  "total_credits_used": 150,
  "last_execution": {
    "id": "1849365782347890690",
    "status": "completed",
    "scheduled_time": "2025-10-24T09:00:00Z",
    "execution_time_ms": 2500
  },
  "status_distribution": {
    "completed": 142,
    "failed": 8,
    "running": 0,
    "pending": 0
  }
}
```

---

## ğŸ“ˆ ä½¿ç”¨åœºæ™¯

### 1. ç›‘æ§ä»»åŠ¡å¥åº·åº¦
```python
# æŸ¥çœ‹æœ€è¿‘10æ¬¡æ‰§è¡Œ
GET /search-tasks/{task_id}/executions?page_size=10

# æŸ¥çœ‹å¤±è´¥çš„æ‰§è¡Œ
GET /search-tasks/{task_id}/executions?status=failed

# è·å–ç»Ÿè®¡ä¿¡æ¯
GET /search-tasks/{task_id}/executions/statistics
```

### 2. é”™è¯¯è¯Šæ–­
```python
# æŸ¥æ‰¾é”™è¯¯æ‰§è¡Œ
executions = await repo.list_by_task(task_id, status="failed")

for execution in executions:
    print(f"æ‰§è¡Œ#{execution.execution_number}å¤±è´¥")
    print(f"  æ—¶é—´: {execution.scheduled_time}")
    print(f"  é”™è¯¯: {execution.error_message}")
    print(f"  ç±»å‹: {execution.error_type}")
```

### 3. æ€§èƒ½åˆ†æ
```python
# è·å–ç»Ÿè®¡æ•°æ®
stats = await repo.get_statistics(task_id)

print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['completed']['avg_execution_time_ms']}ms")
print(f"æ€»ç»“æœæ•°: {stats['completed']['total_results']}")
print(f"æ€»ç§¯åˆ†æ¶ˆè€—: {stats['completed']['total_credits']}")
```

---

## ğŸ“‹ å®æ–½è®¡åˆ’

### Phase 1: æ ¸å¿ƒå®ä½“å’Œä»“å‚¨ï¼ˆ1-2å°æ—¶ï¼‰
- [x] åˆ†æç°çŠ¶
- [ ] åˆ›å»º SearchTaskExecution å®ä½“
- [ ] å®ç° SearchTaskExecutionRepository
- [ ] æ·»åŠ MongoDBç´¢å¼•

### Phase 2: è°ƒåº¦å™¨é›†æˆï¼ˆ1å°æ—¶ï¼‰
- [ ] ä¿®æ”¹ TaskScheduler é›†æˆæ‰§è¡Œå†å²è®°å½•
- [ ] æ·»åŠ é”™è¯¯å¤„ç†å’ŒçŠ¶æ€æ›´æ–°

### Phase 3: APIç«¯ç‚¹ï¼ˆ1å°æ—¶ï¼‰
- [ ] æ·»åŠ æ‰§è¡Œå†å²æŸ¥è¯¢ç«¯ç‚¹
- [ ] æ·»åŠ æ‰§è¡Œè¯¦æƒ…ç«¯ç‚¹
- [ ] æ·»åŠ ç»Ÿè®¡ç«¯ç‚¹

### Phase 4: æµ‹è¯•å’Œæ–‡æ¡£ï¼ˆ1å°æ—¶ï¼‰
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•
- [ ] ç¼–å†™é›†æˆæµ‹è¯•
- [ ] æ›´æ–°APIæ–‡æ¡£

---

## ğŸ¯ é¢„æœŸæ”¶ç›Š

1. **å¯è§‚æµ‹æ€§æå‡**: å®Œæ•´çš„æ‰§è¡Œå†å²è¿½è¸ª
2. **æ•…éšœè¯Šæ–­**: å¿«é€Ÿå®šä½æ‰§è¡Œå¤±è´¥åŸå› 
3. **æ€§èƒ½ä¼˜åŒ–**: åŸºäºå†å²æ•°æ®ä¼˜åŒ–é…ç½®
4. **å®¡è®¡è¿½è¸ª**: å®Œæ•´çš„æ“ä½œè®°å½•
5. **æ•°æ®åˆ†æ**: æ”¯æŒBIå’Œæ•°æ®å¯è§†åŒ–

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å­˜å‚¨ç©ºé—´**: å†å²è®°å½•ä¼šæŒç»­å¢é•¿ï¼Œéœ€è¦è€ƒè™‘æ•°æ®å½’æ¡£ç­–ç•¥
2. **æŸ¥è¯¢æ€§èƒ½**: éœ€è¦åˆç†è®¾è®¡ç´¢å¼•ï¼Œé¿å…å¤§æ•°æ®é‡æŸ¥è¯¢æ€§èƒ½é—®é¢˜
3. **å¹¶å‘å®‰å…¨**: è°ƒåº¦å™¨å’ŒAPIå¹¶å‘è®¿é—®éœ€è¦ä¿è¯æ•°æ®ä¸€è‡´æ€§
4. **æ•°æ®ä¿ç•™**: å»ºè®®ä¿ç•™æœ€è¿‘3-6ä¸ªæœˆçš„æ‰§è¡Œå†å²ï¼Œæ—§æ•°æ®å¯å½’æ¡£
