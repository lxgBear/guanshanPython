#!/usr/bin/env python
"""
ä¿®å¤å­¤ç«‹çš„æœç´¢ç»“æœ

ä¸º search_results é›†åˆä¸­æ²¡æœ‰å¯¹åº”ä»»åŠ¡çš„ç»“æœåˆ›å»ºä»»åŠ¡è®°å½•ã€‚
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.database.repositories import SearchTaskRepository
from src.core.domain.entities.search_task import SearchTask, ScheduleInterval, TaskStatus
from src.core.domain.entities.search_config import UserSearchConfig
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def fix_orphaned_results():
    """ä¿®å¤å­¤ç«‹çš„æœç´¢ç»“æœ"""

    logger.info("=" * 70)
    logger.info("ğŸ”§ å¼€å§‹ä¿®å¤: ä¸ºå­¤ç«‹çš„æœç´¢ç»“æœåˆ›å»ºä»»åŠ¡è®°å½•")
    logger.info("=" * 70)

    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        logger.info("\nğŸ“Š æ­¥éª¤1: åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        db = await get_mongodb_database()
        logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {db.name}")

        # 2. åˆå§‹åŒ–ä»»åŠ¡ä»“å‚¨
        logger.info("\nğŸ“Š æ­¥éª¤2: åˆå§‹åŒ–ä»»åŠ¡ä»“å‚¨")
        task_repo = SearchTaskRepository()
        logger.info("âœ… ä»»åŠ¡ä»“å‚¨åˆå§‹åŒ–æˆåŠŸ")

        # 3. æŸ¥æ‰¾æ‰€æœ‰å­¤ç«‹çš„ task_id
        logger.info("\nğŸ“Š æ­¥éª¤3: æŸ¥æ‰¾å­¤ç«‹çš„æœç´¢ç»“æœ")
        task_ids = await db.search_results.distinct('task_id')
        logger.info(f"ğŸ“ˆ å‘ç° {len(task_ids)} ä¸ªä¸åŒçš„ task_id")

        orphaned_task_ids = []
        for task_id in task_ids:
            task = await db.search_tasks.find_one({'_id': task_id})
            if not task:
                count = await db.search_results.count_documents({'task_id': task_id})
                orphaned_task_ids.append((task_id, count))
                logger.warning(f"âš ï¸  task_id {task_id}: æœ‰ {count} æ¡ç»“æœï¼Œä½†æ— ä»»åŠ¡è®°å½•")

        if not orphaned_task_ids:
            logger.info("\nâœ… æ²¡æœ‰å‘ç°å­¤ç«‹çš„æœç´¢ç»“æœ")
            return True

        logger.info(f"\nå‘ç° {len(orphaned_task_ids)} ä¸ªå­¤ç«‹çš„ task_idï¼Œå…± {sum(c for _, c in orphaned_task_ids)} æ¡ç»“æœ")

        # 4. ä¸ºæ¯ä¸ªå­¤ç«‹çš„ task_id åˆ›å»ºä»»åŠ¡
        logger.info("\nğŸ“Š æ­¥éª¤4: åˆ›å»ºä»»åŠ¡è®°å½•")
        logger.info("-" * 70)

        created_count = 0
        for task_id, result_count in orphaned_task_ids:
            # ä»ç»“æœä¸­è·å–ä¸€æ¡ç¤ºä¾‹ï¼Œæå–æŸ¥è¯¢ä¿¡æ¯
            sample_result = await db.search_results.find_one({'task_id': task_id})

            if not sample_result:
                logger.error(f"âŒ æ— æ³•æ‰¾åˆ° task_id {task_id} çš„ç¤ºä¾‹ç»“æœ")
                continue

            # å°è¯•ä»ç»“æœä¸­æ¨æ–­æŸ¥è¯¢å†…å®¹
            query = sample_result.get('metadata', {}).get('query', f"ä»»åŠ¡_{task_id}")
            title = sample_result.get('title', '')
            title = title[:30] if title else f"æ¢å¤çš„ä»»åŠ¡_{task_id}"

            logger.info(f"\nğŸ”§ ä¸º task_id {task_id} åˆ›å»ºä»»åŠ¡:")
            logger.info(f"   ç»“æœæ•°: {result_count}")
            logger.info(f"   æ¨æ–­æŸ¥è¯¢: {query}")

            # åˆ›å»ºä»»åŠ¡æ–‡æ¡£ï¼ˆç›´æ¥ä½¿ç”¨å­—å…¸ï¼Œç»•è¿‡ Repository çš„åºåˆ—åŒ–ï¼‰
            task_doc = {
                '_id': task_id,  # ä½¿ç”¨åŸæœ‰çš„ task_id
                'name': f"æ¢å¤ä»»åŠ¡-{task_id[-8:]}",  # ä½¿ç”¨ task_id çš„å8ä½ä½œä¸ºåç§°
                'description': f"è‡ªåŠ¨æ¢å¤çš„ä»»åŠ¡ï¼ˆåŸæœ‰ {result_count} æ¡æœç´¢ç»“æœï¼‰",
                'query': query,
                'search_config': {'template': 'default', 'overrides': {}},
                'schedule_interval': 'DAILY',  # é»˜è®¤æ¯å¤©æ‰§è¡Œ
                'is_active': False,  # é»˜è®¤ä¸æ¿€æ´»ï¼Œç”±ç”¨æˆ·æ‰‹åŠ¨æ¿€æ´»
                'status': 'paused',
                'created_by': 'system_auto_recovery',
                'created_at': datetime.utcnow(),
                'updated_at': datetime.utcnow(),
                'last_executed_at': None,
                'next_run_time': datetime.utcnow() + timedelta(days=1),
                'execution_count': 0,
                'success_count': 0,
                'failure_count': 0,
                'total_results': result_count,  # ä½¿ç”¨ç°æœ‰ç»“æœæ•°
                'total_credits_used': 0
            }

            try:
                # ç›´æ¥æ’å…¥åˆ° MongoDB
                await db.search_tasks.insert_one(task_doc)
                created_count += 1
                logger.info(f"   âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
                logger.info(f"      ä»»åŠ¡ID: {task_doc['_id']}")
                logger.info(f"      ä»»åŠ¡åç§°: {task_doc['name']}")
                logger.info(f"      çŠ¶æ€: æœªæ¿€æ´»ï¼ˆéœ€æ‰‹åŠ¨æ¿€æ´»ï¼‰")
                logger.info(f"      è°ƒåº¦é—´éš”: {task_doc['schedule_interval']}")
            except Exception as e:
                logger.error(f"   âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")

        logger.info("\n" + "-" * 70)
        logger.info(f"ğŸ“Š åˆ›å»ºç»“æœç»Ÿè®¡:")
        logger.info(f"   å¾…åˆ›å»º: {len(orphaned_task_ids)} ä¸ª")
        logger.info(f"   æˆåŠŸ: {created_count} ä¸ª")
        logger.info(f"   å¤±è´¥: {len(orphaned_task_ids) - created_count} ä¸ª")

        # 5. éªŒè¯ä¿®å¤ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤5: éªŒè¯ä¿®å¤ç»“æœ")
        logger.info("-" * 70)

        for task_id, _ in orphaned_task_ids:
            task = await db.search_tasks.find_one({'_id': task_id})
            if task:
                logger.info(f"âœ… task_id {task_id}: ä»»åŠ¡å·²å­˜åœ¨")
            else:
                logger.error(f"âŒ task_id {task_id}: ä»»åŠ¡ä»ç„¶ç¼ºå¤±")

        # 6. è¾“å‡ºæ€»ç»“
        logger.info("\n" + "=" * 70)
        logger.info("ğŸ“‹ ä¿®å¤æ€»ç»“:")
        logger.info("=" * 70)
        logger.info(f"âœ… æˆåŠŸä¸º {created_count} ä¸ªå­¤ç«‹çš„ç»“æœåˆ›å»ºäº†ä»»åŠ¡è®°å½•")
        logger.info("\nğŸ’¡ åç»­æ“ä½œ:")
        logger.info("   1. æ£€æŸ¥åˆ›å»ºçš„ä»»åŠ¡æ˜¯å¦æ­£ç¡®")
        logger.info("   2. æ ¹æ®éœ€è¦ä¿®æ”¹ä»»åŠ¡çš„åç§°ã€æŸ¥è¯¢å’Œè°ƒåº¦é—´éš”")
        logger.info("   3. å°†éœ€è¦çš„ä»»åŠ¡è®¾ç½®ä¸º is_active=true ä»¥å¯ç”¨è°ƒåº¦")
        logger.info("   4. é‡å¯åº”ç”¨ä»¥åŠ è½½æ–°ä»»åŠ¡åˆ°è°ƒåº¦å™¨")
        logger.info("\nğŸ“ ä½¿ç”¨ API æ¿€æ´»ä»»åŠ¡:")
        logger.info("   PATCH /api/v1/search-tasks/{task_id}")
        logger.info("   Body: {\"is_active\": true}")
        logger.info("=" * 70)

        return created_count > 0

    except Exception as e:
        logger.error(f"âŒ ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•°"""
    try:
        success = await fix_orphaned_results()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  ä¿®å¤è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ ä¿®å¤è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
