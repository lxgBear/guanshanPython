#!/usr/bin/env python
"""
æ•°æ®åº“æŒä¹…åŒ–éªŒè¯æµ‹è¯•

éªŒè¯è°ƒåº¦å™¨æ‰§è¡Œä»»åŠ¡åï¼Œæœç´¢ç»“æœæ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°MongoDBæ•°æ®åº“ã€‚
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.database.repositories import SearchResultRepository
from src.services.task_scheduler import get_scheduler
from src.core.domain.entities.search_task import SearchTask
from src.core.domain.entities.search_config import UserSearchConfig
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def verify_database_persistence():
    """éªŒè¯æ•°æ®åº“æŒä¹…åŒ–åŠŸèƒ½"""

    logger.info("=" * 70)
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•: æ•°æ®åº“æŒä¹…åŒ–éªŒè¯")
    logger.info("=" * 70)

    try:
        # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        logger.info("\nğŸ“Š æ­¥éª¤1: åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        db = await get_mongodb_database()
        logger.info(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {db.name}")

        # 2. åˆå§‹åŒ–ç»“æœä»“å‚¨
        logger.info("\nğŸ“Š æ­¥éª¤2: åˆå§‹åŒ–ç»“æœä»“å‚¨")
        result_repo = SearchResultRepository()
        logger.info("âœ… ç»“æœä»“å‚¨åˆå§‹åŒ–æˆåŠŸ")

        # 3. è·å–è°ƒåº¦å™¨å®ä¾‹
        logger.info("\nğŸ“Š æ­¥éª¤3: è·å–è°ƒåº¦å™¨å®ä¾‹")
        scheduler = await get_scheduler()
        await scheduler.start()
        logger.info("âœ… è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")

        # 4. è·å–ç°æœ‰ä»»åŠ¡ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
        logger.info("\nğŸ“Š æ­¥éª¤4: è·å–ç°æœ‰ä»»åŠ¡")
        task_repo = await scheduler._get_task_repository()

        # æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡ï¼Œè·å–ç¬¬ä¸€ä¸ª
        tasks, total = await task_repo.list_tasks(page=1, page_size=1, is_active=True)

        if not tasks or total == 0:
            logger.error("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰ä»»åŠ¡ï¼Œè¯·å…ˆåˆ›å»ºä»»åŠ¡")
            logger.error("   æç¤º: è¿è¡Œ python tests/scheduler/test_real_firecrawl_api.py åˆ›å»ºæµ‹è¯•ä»»åŠ¡")
            return False

        test_task = tasks[0]
        test_task_id = str(test_task.id)

        logger.info(f"âœ… ä½¿ç”¨ç°æœ‰ä»»åŠ¡")
        logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
        logger.info(f"   - ä»»åŠ¡åç§°: {test_task.name}")
        logger.info(f"   - æŸ¥è¯¢: {test_task.query}")
        logger.info(f"   - åˆ›å»ºè€…: {test_task.created_by}")

        # 5. æ£€æŸ¥æ•°æ®åº“ä¸­ä»»åŠ¡å‰çš„ç»“æœæ•°é‡
        logger.info("\nğŸ“Š æ­¥éª¤5: æ£€æŸ¥æ‰§è¡Œå‰çš„æ•°æ®åº“çŠ¶æ€")
        collection = db["search_results"]
        before_count = await collection.count_documents({"task_id": test_task_id})
        logger.info(f"ğŸ“ˆ æ‰§è¡Œå‰æ•°æ®åº“ä¸­çš„ç»“æœæ•°: {before_count}")

        # 6. ç«‹å³æ‰§è¡Œä»»åŠ¡
        logger.info("\nğŸ“Š æ­¥éª¤6: æ‰§è¡Œæµ‹è¯•ä»»åŠ¡")
        execution_result = await scheduler.execute_task_now(test_task_id)
        logger.info(f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        logger.info(f"   - æ‰§è¡Œæ—¶é—´: {execution_result['executed_at']}")
        logger.info(f"   - æ‰§è¡ŒçŠ¶æ€: {execution_result['status']}")

        # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ•°æ®å·²ä¿å­˜
        await asyncio.sleep(1)

        # 7. éªŒè¯æ•°æ®åº“ä¸­çš„ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤7: éªŒè¯æ•°æ®åº“ä¸­çš„ç»“æœ")
        after_count = await collection.count_documents({"task_id": test_task_id})
        new_results_count = after_count - before_count

        logger.info(f"ğŸ“ˆ æ‰§è¡Œåæ•°æ®åº“ä¸­çš„ç»“æœæ•°: {after_count}")
        logger.info(f"ğŸ“ˆ æ–°å¢ç»“æœæ•°: {new_results_count}")

        # 8. ä½¿ç”¨ä»“å‚¨æŸ¥è¯¢ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤8: ä½¿ç”¨ä»“å‚¨æŸ¥è¯¢ç»“æœ")
        results, total = await result_repo.get_results_by_task(test_task_id, page=1, page_size=20)

        logger.info(f"ğŸ“Š ä»“å‚¨æŸ¥è¯¢ç»“æœ:")
        logger.info(f"   - æ€»æ•°: {total}")
        logger.info(f"   - è¿”å›æ•°: {len(results)}")

        if results:
            logger.info(f"\nğŸ“„ ç»“æœç¤ºä¾‹ (å‰3æ¡):")
            for i, result in enumerate(results[:3], 1):
                logger.info(f"   {i}. æ ‡é¢˜: {result.title}")
                logger.info(f"      URL: {result.url}")
                logger.info(f"      æ¥æº: {result.source}")
                logger.info(f"      ç›¸å…³æ€§: {result.relevance_score:.2f}")
                logger.info(f"      åˆ›å»ºæ—¶é—´: {result.created_at}")

        # 8.5. æ‰“å° Firecrawl åŸå§‹æ•°æ®ï¼ˆç”¨äºæ•°æ®ç­›é€‰ï¼‰
        logger.info("\nğŸ“Š æ­¥éª¤8.5: æ‰“å° Firecrawl API åŸå§‹æ•°æ®")
        logger.info("=" * 70)
        logger.info("ä»¥ä¸‹æ˜¯ Firecrawl API è¿”å›çš„åŸå§‹æ•°æ®ï¼Œå¸®åŠ©ç­›é€‰éœ€è¦å…¥åº“çš„å­—æ®µï¼š")
        logger.info("=" * 70)

        if results:
            import json
            # åªæ‰“å°ç¬¬ä¸€æ¡ç»“æœçš„å®Œæ•´åŸå§‹æ•°æ®ä½œä¸ºç¤ºä¾‹
            first_result = results[0]
            if hasattr(first_result, 'raw_data') and first_result.raw_data:
                logger.info("\nã€ç¬¬1æ¡ç»“æœçš„ Firecrawl åŸå§‹æ•°æ®ã€‘")
                logger.info(json.dumps(first_result.raw_data, indent=2, ensure_ascii=False))

                # åˆ†æå¯ç”¨å­—æ®µ
                logger.info("\n" + "=" * 70)
                logger.info("ğŸ“‹ Firecrawl åŸå§‹æ•°æ®å­—æ®µåˆ†æï¼š")
                logger.info("=" * 70)
                logger.info(f"å¯ç”¨å­—æ®µåˆ—è¡¨: {list(first_result.raw_data.keys())}")
                logger.info("\nå„å­—æ®µè¯´æ˜ï¼š")
                for key, value in first_result.raw_data.items():
                    value_type = type(value).__name__
                    value_len = len(value) if isinstance(value, (str, list, dict)) else "N/A"
                    logger.info(f"  - {key:20} ç±»å‹: {value_type:10} é•¿åº¦: {value_len}")

                # æ‰“å°å½“å‰å·²å…¥åº“çš„å­—æ®µ
                logger.info("\n" + "=" * 70)
                logger.info("ğŸ’¾ å½“å‰å·²å…¥åº“çš„å­—æ®µæ˜ å°„ï¼š")
                logger.info("=" * 70)
                logger.info(f"  SearchResult.title          â† raw_data['title']")
                logger.info(f"  SearchResult.url            â† raw_data['url']")
                logger.info(f"  SearchResult.content        â† raw_data['markdown'] or raw_data['html']")
                logger.info(f"  SearchResult.snippet        â† raw_data['description']")
                logger.info(f"  SearchResult.source         â† raw_data['source']")
                logger.info(f"  SearchResult.published_date â† raw_data['publishedDate']")
                logger.info(f"  SearchResult.author         â† raw_data['author']")
                logger.info(f"  SearchResult.language       â† raw_data['language']")
                logger.info(f"  SearchResult.relevance_scoreâ† raw_data['score']")
                logger.info(f"  SearchResult.metadata       â† raw_data['metadata'] + html + links")
                logger.info(f"  SearchResult.markdown_contentâ† raw_data['markdown']")
                logger.info(f"  SearchResult.raw_data       â† å®Œæ•´åŸå§‹æ•°æ®")

                logger.info("\nğŸ’¡ å»ºè®®ï¼šè¯·æ ¹æ®ä»¥ä¸ŠåŸå§‹æ•°æ®ç»“æ„ï¼Œå†³å®šæ˜¯å¦éœ€è¦æ·»åŠ æ–°å­—æ®µåˆ°æ•°æ®åº“æ¨¡å‹")
            else:
                logger.warning("âš ï¸  ç¬¬ä¸€æ¡ç»“æœæ²¡æœ‰ raw_data å­—æ®µ")
        else:
            logger.warning("âš ï¸  æ²¡æœ‰ç»“æœå¯ä»¥æ˜¾ç¤ºåŸå§‹æ•°æ®")

        logger.info("=" * 70)

        # 9. éªŒè¯æµ‹è¯•ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤9: éªŒè¯æµ‹è¯•ç»“æœ")

        success = True
        errors = []

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç»“æœ
        if new_results_count == 0:
            success = False
            errors.append("æ•°æ®åº“ä¸­æ²¡æœ‰æ–°å¢ç»“æœ")
        else:
            logger.info(f"âœ… è·å–åˆ° {new_results_count} æ¡æ–°ç»“æœ")

        # æ£€æŸ¥ä»“å‚¨æŸ¥è¯¢æ˜¯å¦æ­£å¸¸
        if total != after_count:
            logger.warning(f"âš ï¸  ä»“å‚¨æŸ¥è¯¢æ€»æ•°({total})ä¸æ•°æ®åº“è®¡æ•°({after_count})ä¸ä¸€è‡´")

        # 10. è¾“å‡ºæµ‹è¯•ç»“è®º
        logger.info("\n" + "=" * 70)

        if success:
            logger.info("âœ… æµ‹è¯•é€šè¿‡: æ•°æ®åº“æŒä¹…åŒ–åŠŸèƒ½æ­£å¸¸")
            logger.info("\nâœ¨ éªŒè¯ç»“æœ:")
            logger.info(f"   âœ… è°ƒåº¦å™¨æˆåŠŸè§¦å‘ä»»åŠ¡æ‰§è¡Œ")
            logger.info(f"   âœ… Firecrawl API è·å–äº† {new_results_count} æ¡æœç´¢ç»“æœ")
            logger.info(f"   âœ… ç»“æœæˆåŠŸä¿å­˜åˆ°MongoDBæ•°æ®åº“")
            logger.info(f"   âœ… ä»“å‚¨å¯ä»¥æ­£å¸¸æŸ¥è¯¢å’Œè¯»å–ç»“æœ")
            logger.info(f"   âœ… æ•°æ®æŒä¹…åŒ–åˆ° search_results é›†åˆ")

            logger.info("\nğŸ“‹ æ•°æ®åº“ä¿¡æ¯:")
            logger.info(f"   - æ•°æ®åº“: {db.name}")
            logger.info(f"   - é›†åˆ: search_results")
            logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
            logger.info(f"   - ä»»åŠ¡åç§°: {test_task.name}")
            logger.info(f"   - æ€»ç»“æœæ•°: {after_count}")
        else:
            logger.error("âŒ æµ‹è¯•å¤±è´¥: æ•°æ®åº“æŒä¹…åŒ–åŠŸèƒ½å¼‚å¸¸")
            logger.error("\nâŒ é”™è¯¯ä¿¡æ¯:")
            for error in errors:
                logger.error(f"   - {error}")

        logger.info("=" * 70)

        # 11. ä¿ç•™æµ‹è¯•æ•°æ®ï¼ˆä¸æ¸…ç†ï¼‰
        logger.info("\nğŸ“Š æ­¥éª¤10: æµ‹è¯•æ•°æ®ä¿ç•™")
        logger.info("âš ï¸  æµ‹è¯•æ•°æ®å°†è¢«ä¿ç•™åœ¨æ•°æ®åº“ä¸­ä»¥ä¾›æŸ¥çœ‹")
        logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
        logger.info(f"   - æ•°æ®åº“: {db.name}")
        logger.info(f"   - é›†åˆ: search_results")
        logger.info(f"   - ç»“æœæ•°: {after_count}æ¡")
        logger.info("\nğŸ’¡ å¦‚éœ€æ¸…ç†ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤:")
        logger.info(f"   mongosh {db.name} --eval 'db.search_tasks.deleteOne({{_id: \"{test_task_id}\"}})'")
        logger.info(f"   mongosh {db.name} --eval 'db.search_results.deleteMany({{task_id: \"{test_task_id}\"}})'")

        # åœæ­¢è°ƒåº¦å™¨
        await scheduler.stop()
        logger.info("\nâœ… è°ƒåº¦å™¨å·²åœæ­¢")

        return success

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•°"""
    try:
        success = await verify_database_persistence()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
