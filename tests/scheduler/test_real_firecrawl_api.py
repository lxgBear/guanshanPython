#!/usr/bin/env python
"""
çœŸå® Firecrawl API æµ‹è¯•

æµ‹è¯•çœŸå®çš„ Firecrawl API è°ƒç”¨ï¼ŒéªŒè¯ï¼š
1. API è¿æ¥æ˜¯å¦æ­£å¸¸
2. æœç´¢ç»“æœæ˜¯å¦æ­£ç¡®è¿”å›
3. æ•°æ®æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“
4. çœŸå®æ•°æ®çš„å®Œæ•´æ€§
"""

import sys
import asyncio
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.database.repositories import SearchResultRepository
from src.infrastructure.search.firecrawl_search_adapter import FirecrawlSearchAdapter
from src.core.domain.entities.search_config import UserSearchConfig
from src.services.task_scheduler import get_scheduler
from src.core.domain.entities.search_task import SearchTask
from src.config import settings
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def test_real_firecrawl_api():
    """æµ‹è¯•çœŸå®çš„ Firecrawl API"""

    logger.info("=" * 70)
    logger.info("ğŸŒ å¼€å§‹æµ‹è¯•: çœŸå® Firecrawl API è°ƒç”¨")
    logger.info("=" * 70)

    try:
        # 1. æ£€æŸ¥é…ç½®
        logger.info("\nğŸ“Š æ­¥éª¤1: æ£€æŸ¥ Firecrawl é…ç½®")
        logger.info(f"   - API Base URL: {settings.FIRECRAWL_BASE_URL}")
        logger.info(f"   - API Key: {settings.FIRECRAWL_API_KEY[:20]}...")
        logger.info(f"   - TEST_MODE: {settings.TEST_MODE}")
        logger.info(f"   - Timeout: {settings.FIRECRAWL_TIMEOUT}s")
        logger.info(f"   - Max Retries: {settings.FIRECRAWL_MAX_RETRIES}")

        if settings.TEST_MODE:
            logger.warning("âš ï¸  TEST_MODE ä»ç„¶å¼€å¯ï¼å°†ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è€ŒéçœŸå®æ•°æ®")
            logger.warning("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® TEST_MODE=false")
            return False
        else:
            logger.info("âœ… TEST_MODE å·²å…³é—­ï¼Œå°†è°ƒç”¨çœŸå® Firecrawl API")

        # 2. åˆå§‹åŒ–æ•°æ®åº“
        logger.info("\nğŸ“Š æ­¥éª¤2: åˆå§‹åŒ–æ•°æ®åº“è¿æ¥")
        db = await get_mongodb_database()
        result_repo = SearchResultRepository()
        logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")

        # 3. åˆå§‹åŒ–è°ƒåº¦å™¨
        logger.info("\nğŸ“Š æ­¥éª¤3: åˆå§‹åŒ–è°ƒåº¦å™¨")
        scheduler = await get_scheduler()
        await scheduler.start()
        logger.info("âœ… è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")

        # 4. åˆ›å»ºæµ‹è¯•ä»»åŠ¡ï¼ˆä½¿ç”¨è¾ƒå°çš„limitä»¥èŠ‚çœAPIé¢åº¦ï¼‰
        logger.info("\nğŸ“Š æ­¥éª¤4: åˆ›å»ºçœŸå® API æµ‹è¯•ä»»åŠ¡")
        search_config = UserSearchConfig(
            template_name="default",
            overrides={
                "limit": 5,  # é™åˆ¶ä¸º5æ¡ä»¥èŠ‚çœé¢åº¦
                "sources": ["web"],
                "enable_ai_summary": False,
                "extract_metadata": True,
                "follow_links": False
            }
        )

        test_task = SearchTask.create_with_secure_id(
            name="çœŸå®Firecrawl APIæµ‹è¯•",
            description="æµ‹è¯•çœŸå®çš„Firecrawl APIè°ƒç”¨å’Œæ•°æ®ä¿å­˜",
            query="Python programming best practices 2024",  # ä½¿ç”¨è‹±æ–‡æŸ¥è¯¢ä»¥è·å¾—æ›´å¥½çš„ç»“æœ
            search_config={
                "template": search_config.template_name,
                **search_config.overrides
            },
            schedule_interval="HOURLY_1",
            is_active=True,
            created_by="real_api_test"
        )

        # ä¿å­˜ä»»åŠ¡
        task_repo = await scheduler._get_task_repository()
        await task_repo.create(test_task)
        test_task_id = str(test_task.id)

        logger.info(f"âœ… æµ‹è¯•ä»»åŠ¡å·²åˆ›å»º")
        logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
        logger.info(f"   - ä»»åŠ¡åç§°: {test_task.name}")
        logger.info(f"   - æŸ¥è¯¢: {test_task.query}")
        logger.info(f"   - ç»“æœé™åˆ¶: 5æ¡")

        # 5. æ£€æŸ¥æ‰§è¡Œå‰çš„æ•°æ®åº“çŠ¶æ€
        logger.info("\nğŸ“Š æ­¥éª¤5: æ£€æŸ¥æ‰§è¡Œå‰çš„æ•°æ®åº“çŠ¶æ€")
        collection = db["search_results"]
        before_count = await collection.count_documents({"task_id": test_task_id})
        logger.info(f"ğŸ“ˆ æ‰§è¡Œå‰æ•°æ®åº“ä¸­çš„ç»“æœæ•°: {before_count}")

        # 6. æ‰§è¡Œä»»åŠ¡ï¼ˆè°ƒç”¨çœŸå® Firecrawl APIï¼‰
        logger.info("\nğŸ“Š æ­¥éª¤6: æ‰§è¡ŒçœŸå® Firecrawl API è°ƒç”¨")
        logger.info("â³ æ­£åœ¨è°ƒç”¨ Firecrawl APIï¼Œè¯·ç¨å€™...")
        logger.info("   (çœŸå® API è°ƒç”¨å¯èƒ½éœ€è¦ 5-30 ç§’)")

        execution_result = await scheduler.execute_task_now(test_task_id)

        logger.info(f"âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        logger.info(f"   - æ‰§è¡Œæ—¶é—´: {execution_result['executed_at']}")
        logger.info(f"   - æ‰§è¡ŒçŠ¶æ€: {execution_result['status']}")

        # ç­‰å¾…æ•°æ®ä¿å­˜å®Œæˆ
        await asyncio.sleep(2)

        # 7. éªŒè¯æ•°æ®åº“ä¸­çš„ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤7: éªŒè¯æ•°æ®åº“ä¸­çš„çœŸå®ç»“æœ")
        after_count = await collection.count_documents({"task_id": test_task_id})
        new_results_count = after_count - before_count

        logger.info(f"ğŸ“ˆ æ‰§è¡Œåæ•°æ®åº“ä¸­çš„ç»“æœæ•°: {after_count}")
        logger.info(f"ğŸ“ˆ æ–°å¢ç»“æœæ•°: {new_results_count}")

        # 8. æŸ¥è¯¢å¹¶æ˜¾ç¤ºçœŸå®ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤8: æŸ¥è¯¢å¹¶æ˜¾ç¤ºçœŸå®æœç´¢ç»“æœ")
        results, total = await result_repo.get_results_by_task(test_task_id, page=1, page_size=20)

        logger.info(f"ğŸ“Š ä»“å‚¨æŸ¥è¯¢ç»“æœ:")
        logger.info(f"   - æ€»æ•°: {total}")
        logger.info(f"   - è¿”å›æ•°: {len(results)}")

        if results:
            logger.info(f"\nğŸ“„ çœŸå®æœç´¢ç»“æœè¯¦æƒ…:")
            logger.info("=" * 70)
            for i, result in enumerate(results, 1):
                logger.info(f"\n{i}. ã€{result.title}ã€‘")
                logger.info(f"   ğŸ”— URL: {result.url}")
                logger.info(f"   ğŸ“ æ‘˜è¦: {result.snippet[:100] if result.snippet else 'æ— '}...")
                logger.info(f"   ğŸ“Š ç›¸å…³æ€§è¯„åˆ†: {result.relevance_score:.2f}")
                logger.info(f"   ğŸ“Š è´¨é‡è¯„åˆ†: {result.quality_score:.2f}")
                logger.info(f"   ğŸŒ æ¥æº: {result.source}")
                logger.info(f"   ğŸ—£ï¸ è¯­è¨€: {result.language or 'æœªçŸ¥'}")
                logger.info(f"   ğŸ“… å‘å¸ƒæ—¶é—´: {result.published_date or 'æœªçŸ¥'}")
                logger.info(f"   ğŸ‘¤ ä½œè€…: {result.author or 'æœªçŸ¥'}")
                logger.info(f"   â° åˆ›å»ºæ—¶é—´: {result.created_at}")
                logger.info(f"   ğŸ§ª æµ‹è¯•æ•°æ®: {'æ˜¯' if result.is_test_data else 'å¦'}")
                logger.info("-" * 70)

            # æ˜¾ç¤ºå†…å®¹æ ·æœ¬
            if results[0].content:
                logger.info(f"\nğŸ“„ å†…å®¹æ ·æœ¬ (ç¬¬1æ¡ç»“æœ):")
                logger.info("-" * 70)
                content_preview = results[0].content[:500]
                logger.info(content_preview)
                if len(results[0].content) > 500:
                    logger.info(f"... (è¿˜æœ‰ {len(results[0].content) - 500} ä¸ªå­—ç¬¦)")
                logger.info("-" * 70)
        else:
            logger.warning("âš ï¸  æ²¡æœ‰è·å–åˆ°ç»“æœ")

        # 9. éªŒè¯æµ‹è¯•ç»“æœ
        logger.info("\nğŸ“Š æ­¥éª¤9: éªŒè¯æµ‹è¯•ç»“æœ")

        success = True
        errors = []

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç»“æœ
        if new_results_count == 0:
            success = False
            errors.append("æ•°æ®åº“ä¸­æ²¡æœ‰æ–°å¢ç»“æœ")

        # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®æ•°æ®ï¼ˆä¸æ˜¯æµ‹è¯•æ•°æ®ï¼‰
        if results:
            real_data_count = sum(1 for r in results if not r.is_test_data)
            if real_data_count == 0:
                success = False
                errors.append("æ‰€æœ‰ç»“æœéƒ½æ ‡è®°ä¸ºæµ‹è¯•æ•°æ®ï¼Œå¯èƒ½ä»åœ¨ä½¿ç”¨TEST_MODE")
            else:
                logger.info(f"âœ… çœŸå®æ•°æ®æ•°é‡: {real_data_count}/{len(results)}")

            # æ£€æŸ¥æ•°æ®è´¨é‡
            has_content = sum(1 for r in results if r.content and len(r.content) > 100)
            if has_content > 0:
                logger.info(f"âœ… æœ‰å®é™…å†…å®¹çš„ç»“æœ: {has_content}/{len(results)}")
            else:
                logger.warning(f"âš ï¸  æ²¡æœ‰ç»“æœåŒ…å«å®é™…å†…å®¹")

        # 10. è¾“å‡ºæµ‹è¯•ç»“è®º
        logger.info("\n" + "=" * 70)

        if success:
            logger.info("âœ… æµ‹è¯•é€šè¿‡: çœŸå® Firecrawl API è°ƒç”¨æˆåŠŸ")
            logger.info("\nâœ¨ éªŒè¯ç»“æœ:")
            logger.info(f"   âœ… æˆåŠŸè°ƒç”¨çœŸå® Firecrawl API")
            logger.info(f"   âœ… è·å–äº† {new_results_count} æ¡çœŸå®æœç´¢ç»“æœ")
            logger.info(f"   âœ… ç»“æœæˆåŠŸä¿å­˜åˆ° MongoDB æ•°æ®åº“")
            logger.info(f"   âœ… æ•°æ®åŒ…å«å®é™…å†…å®¹å’Œå…ƒæ•°æ®")
            logger.info(f"   âœ… ä»“å‚¨å¯ä»¥æ­£å¸¸æŸ¥è¯¢çœŸå®æ•°æ®")

            logger.info("\nğŸ“‹ æ•°æ®åº“ä¿¡æ¯:")
            logger.info(f"   - æ•°æ®åº“: {db.name}")
            logger.info(f"   - é›†åˆ: search_results")
            logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
            logger.info(f"   - ç»“æœæ•°: {after_count}")
            logger.info(f"   - çœŸå®æ•°æ®: æ˜¯")

            logger.info("\nğŸ’¡ æç¤º:")
            logger.info("   - çœŸå®æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“")
            logger.info("   - å¯ä»¥é€šè¿‡ API æŸ¥è¯¢: GET /api/v1/search-tasks/{task_id}/results")
            logger.info("   - æ•°æ®å°†æŒä¹…åŒ–ä¿å­˜ï¼Œé‡å¯åä»ç„¶å¯ç”¨")
        else:
            logger.error("âŒ æµ‹è¯•å¤±è´¥: çœŸå® Firecrawl API è°ƒç”¨å¼‚å¸¸")
            logger.error("\nâŒ é”™è¯¯ä¿¡æ¯:")
            for error in errors:
                logger.error(f"   - {error}")

        logger.info("=" * 70)

        # 11. è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ•°æ®
        logger.info("\nğŸ“Š æ­¥éª¤10: æµ‹è¯•æ•°æ®æ¸…ç†")
        logger.info("âš ï¸  æµ‹è¯•æ•°æ®å°†è¢«ä¿ç•™ä»¥ä¾›æŸ¥çœ‹")
        logger.info(f"   - ä»»åŠ¡ID: {test_task_id}")
        logger.info("   - å¦‚éœ€æ¸…ç†ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤:")
        logger.info(f"     mongosh intelligent_system --eval 'db.search_tasks.deleteOne({{_id: \"{test_task_id}\"}})'")
        logger.info(f"     mongosh intelligent_system --eval 'db.search_results.deleteMany({{task_id: \"{test_task_id}\"}})'")

        # åœæ­¢è°ƒåº¦å™¨
        await scheduler.stop()
        logger.info("\nâœ… è°ƒåº¦å™¨å·²åœæ­¢")

        return success

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ä¸»å‡½æ•°"""
    try:
        success = await test_real_firecrawl_api()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
