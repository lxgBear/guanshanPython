# NL Search åŠŸèƒ½å®ç°æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-17
**ç›®æ ‡**: å®Œå–„ NL Search æ ¸å¿ƒåŠŸèƒ½ï¼Œå®ç°å®Œæ•´é—­ç¯
**ä¼°ç®—å·¥ä½œé‡**: 3-5 å¤©

---

## ğŸ“‹ ç›®å½•

1. [åŠŸèƒ½æ¦‚è¿°](#åŠŸèƒ½æ¦‚è¿°)
2. [æŠ€æœ¯æ¶æ„åˆ†æ](#æŠ€æœ¯æ¶æ„åˆ†æ)
3. [å®ç°æ–¹æ¡ˆ 1: GET /{log_id}/results](#å®ç°æ–¹æ¡ˆ-1-get-log_idresults)
4. [å®ç°æ–¹æ¡ˆ 2: POST /{log_id}/select](#å®ç°æ–¹æ¡ˆ-2-post-log_idselect)
5. [æ•°æ®åº“è®¾è®¡](#æ•°æ®åº“è®¾è®¡)
6. [æµ‹è¯•æ–¹æ¡ˆ](#æµ‹è¯•æ–¹æ¡ˆ)
7. [éƒ¨ç½²æ¸…å•](#éƒ¨ç½²æ¸…å•)

---

## åŠŸèƒ½æ¦‚è¿°

### å½“å‰ NL Search æ¶æ„çŠ¶æ€

**å·²å®ç°åŠŸèƒ½** (70%):
- âœ… æœç´¢è®°å½•åˆ›å»º (`POST /nl-search`)
- âœ… æœç´¢è®°å½•æŸ¥è¯¢ (`GET /nl-search/{log_id}`)
- âœ… æœç´¢å†å²åˆ—è¡¨ (`GET /nl-search`)
- âœ… MongoDB è¿ç§»å®Œæˆ
- âœ… æ¡£æ¡ˆç®¡ç†åŠŸèƒ½

**æœªå®ç°åŠŸèƒ½** (30%):
- âŒ æœç´¢ç»“æœæŸ¥è¯¢ (`GET /nl-search/{log_id}/results`)
- âŒ ç”¨æˆ·é€‰æ‹©è®°å½• (`POST /nl-search/{log_id}/select`)

### æ ¸å¿ƒé—®é¢˜åˆ†æ

**é—®é¢˜ 1: æœç´¢ç»“æœå­˜å‚¨åœ¨å“ªé‡Œï¼Ÿ**

å½“å‰ `NLSearchService.create_search()` æ–¹æ³•æ‰§è¡Œæµç¨‹:
```python
# src/services/nl_search/nl_search_service.py:50-137
async def create_search(self, query_text, user_id):
    # 1. åˆ›å»ºæœç´¢è®°å½• (ä¿å­˜åˆ° nl_search_logs)
    log_id = await self.repository.create(query_text, llm_analysis=None)

    # 2. LLM è§£ææŸ¥è¯¢
    analysis = await self.llm_processor.parse_query(query_text)

    # 3. æ›´æ–°åˆ†æç»“æœ
    await self.repository.update_llm_analysis(log_id, analysis)

    # 4. ç²¾ç‚¼æŸ¥è¯¢
    refined_query = await self.llm_processor.refine_query(query_text)

    # 5. æ‰§è¡Œæœç´¢ (GPT5SearchAdapter)
    search_results = await self.gpt5_adapter.search(refined_query, max_results)

    # 6. è¿”å›ç»“æœ (ä»…åœ¨å“åº”ä¸­è¿”å›ï¼ŒæœªæŒä¹…åŒ–)
    return {
        "log_id": log_id,
        "results": [r.to_dict() for r in search_results],  # âš ï¸ ä»…å†…å­˜ä¸­
        ...
    }
```

**å…³é”®å‘ç°**:
- âœ… æœç´¢è®°å½•ä¿å­˜åˆ° `nl_search_logs` é›†åˆ
- âŒ æœç´¢ç»“æœ **æœªä¿å­˜** åˆ°æ•°æ®åº“
- âš ï¸ æœç´¢ç»“æœä»…é€šè¿‡ API å“åº”è¿”å›ç»™å‰ç«¯ï¼ŒæœªæŒä¹…åŒ–

**é—®é¢˜ 2: æœç´¢ç»“æœæ•°æ®ç»“æ„**

`SearchResult` ç±»å®šä¹‰:
```python
# src/services/nl_search/gpt5_search_adapter.py:39-67
class SearchResult:
    def __init__(self, title, url, snippet, position, score, source):
        self.title = title
        self.url = url
        self.snippet = snippet
        self.position = position
        self.score = score
        self.source = source  # "serpapi", "test" ç­‰

    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "url": self.url,
            "snippet": self.snippet,
            "position": self.position,
            "score": self.score,
            "source": self.source
        }
```

**æ•°æ®ç‰¹å¾**:
- è½»é‡çº§ç»“æ„ (URL + æ ‡é¢˜ + æ‘˜è¦)
- æ— å®Œæ•´ç½‘é¡µå†…å®¹ (éœ€åç»­çˆ¬å–)
- ä¸ `news_results` é›†åˆ **ä¸åŒ**

---

## æŠ€æœ¯æ¶æ„åˆ†æ

### æ¶æ„å†³ç­–: æœç´¢ç»“æœå­˜å‚¨æ–¹æ¡ˆ

#### æ–¹æ¡ˆ A: å†…åµŒå­˜å‚¨ (æ¨è)

**è®¾è®¡**: å°†æœç´¢ç»“æœç›´æ¥å­˜å‚¨åœ¨ `nl_search_logs` æ–‡æ¡£ä¸­

**ä¼˜ç‚¹**:
- âœ… ç®€å•ç›´æ¥ï¼Œæ— éœ€æ–°å»ºé›†åˆ
- âœ… æŸ¥è¯¢æ•ˆç‡é«˜ (å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰æ•°æ®)
- âœ… æ•°æ®ä¸€è‡´æ€§å¼º (åŸå­æ“ä½œ)
- âœ… é€‚åˆè½»é‡çº§æœç´¢ç»“æœ

**ç¼ºç‚¹**:
- âš ï¸ æ–‡æ¡£å¤§å°å¯èƒ½å¢å¤§ (MongoDB æ–‡æ¡£é™åˆ¶ 16MB)
- âš ï¸ ä¸é€‚åˆå¤§é‡æœç´¢ç»“æœ (>100æ¡)

**æ–‡æ¡£ç»“æ„**:
```javascript
// nl_search_logs é›†åˆ
{
    "_id": "248728141926559744",
    "query_text": "æœ€è¿‘AIæŠ€æœ¯çªç ´",
    "llm_analysis": { ... },
    "search_results": [  // æ–°å¢å­—æ®µ
        {
            "title": "GPT-5 é‡ç£…å‘å¸ƒ",
            "url": "https://example.com/gpt5",
            "snippet": "OpenAI å‘å¸ƒæœ€æ–°...",
            "position": 1,
            "score": 0.95,
            "source": "serpapi"
        },
        // ... æ›´å¤šç»“æœ
    ],
    "results_count": 10,
    "status": "completed",
    "created_at": ISODate(...),
    "updated_at": ISODate(...)
}
```

#### æ–¹æ¡ˆ B: ç‹¬ç«‹é›†åˆå­˜å‚¨

**è®¾è®¡**: åˆ›å»º `nl_search_results` é›†åˆï¼Œé€šè¿‡ `log_id` å…³è”

**ä¼˜ç‚¹**:
- âœ… é€‚åˆå¤§é‡æœç´¢ç»“æœ
- âœ… æ”¯æŒç»“æœå•ç‹¬æŸ¥è¯¢å’Œè¿‡æ»¤
- âœ… æ–‡æ¡£å¤§å°ä¸å—é™åˆ¶

**ç¼ºç‚¹**:
- âš ï¸ éœ€è¦é¢å¤–çš„é›†åˆå’Œç´¢å¼•
- âš ï¸ æŸ¥è¯¢éœ€è¦ JOIN æ“ä½œ (MongoDB $lookup)
- âš ï¸ å¢åŠ ç³»ç»Ÿå¤æ‚åº¦

**æ–‡æ¡£ç»“æ„**:
```javascript
// nl_search_results é›†åˆ
{
    "_id": "result_001",
    "log_id": "248728141926559744",  // å…³è”æœç´¢è®°å½•
    "title": "GPT-5 é‡ç£…å‘å¸ƒ",
    "url": "https://example.com/gpt5",
    "snippet": "OpenAI å‘å¸ƒæœ€æ–°...",
    "position": 1,
    "score": 0.95,
    "source": "serpapi",
    "created_at": ISODate(...)
}
```

### æ¨èæ–¹æ¡ˆ: æ–¹æ¡ˆ A (å†…åµŒå­˜å‚¨)

**ç†ç”±**:
1. NL Search æœç´¢ç»“æœæ•°é‡å¯æ§ (é»˜è®¤ 10-20 æ¡)
2. ç»“æœæ•°æ®è½»é‡ (æ— å®Œæ•´å†…å®¹)
3. ç®€åŒ–æŸ¥è¯¢é€»è¾‘ï¼Œæå‡æ€§èƒ½
4. ç¬¦åˆ MongoDB æœ€ä½³å®è·µ (å†…åµŒæ–‡æ¡£)

---

## å®ç°æ–¹æ¡ˆ 1: GET /{log_id}/results

### 1.1 æ•°æ®æ¨¡å‹å®šä¹‰

```python
# src/api/v1/endpoints/nl_search.py

class SearchResultItem(BaseModel):
    """æœç´¢ç»“æœæ¡ç›®"""
    title: str = Field(..., description="ç»“æœæ ‡é¢˜")
    url: str = Field(..., description="ç»“æœURL")
    snippet: str = Field("", description="ç»“æœæ‘˜è¦")
    position: int = Field(..., description="ç»“æœä½ç½®")
    score: float = Field(0.0, description="ç›¸å…³æ€§è¯„åˆ†")
    source: str = Field("search", description="æœç´¢æ¥æº")

    class Config:
        json_schema_extra = {
            "example": {
                "title": "GPT-5 é‡ç£…å‘å¸ƒ",
                "url": "https://example.com/gpt5",
                "snippet": "OpenAI å‘å¸ƒæœ€æ–°å¤§è¯­è¨€æ¨¡å‹ GPT-5...",
                "position": 1,
                "score": 0.95,
                "source": "serpapi"
            }
        }


class SearchResultsResponse(BaseModel):
    """æœç´¢ç»“æœå“åº”"""
    log_id: str = Field(..., description="æœç´¢è®°å½•ID")
    query_text: str = Field(..., description="ç”¨æˆ·æŸ¥è¯¢")
    total_count: int = Field(..., description="ç»“æœæ€»æ•°")
    results: List[SearchResultItem] = Field(..., description="æœç´¢ç»“æœåˆ—è¡¨")
    llm_analysis: Optional[Dict[str, Any]] = Field(None, description="LLMåˆ†æç»“æœ")
    status: str = Field(..., description="æœç´¢çŠ¶æ€")
    created_at: str = Field(..., description="åˆ›å»ºæ—¶é—´")

    class Config:
        json_schema_extra = {
            "example": {
                "log_id": "248728141926559744",
                "query_text": "æœ€è¿‘AIæŠ€æœ¯çªç ´",
                "total_count": 10,
                "results": [
                    {
                        "title": "GPT-5 å‘å¸ƒ",
                        "url": "https://example.com/gpt5",
                        "snippet": "...",
                        "position": 1,
                        "score": 0.95,
                        "source": "serpapi"
                    }
                ],
                "llm_analysis": {
                    "intent": "technology_news",
                    "keywords": ["AI", "æŠ€æœ¯çªç ´"]
                },
                "status": "completed",
                "created_at": "2025-11-17T10:00:00Z"
            }
        }
```

### 1.2 Repository å±‚æ‰©å±•

```python
# src/infrastructure/database/mongo_nl_search_repository.py

class MongoNLSearchLogRepository:
    # ... ç°æœ‰æ–¹æ³• ...

    async def update_search_results(
        self,
        log_id: str,
        search_results: List[Dict[str, Any]],
        results_count: int
    ) -> bool:
        """
        æ›´æ–°æœç´¢ç»“æœ

        Args:
            log_id: æ—¥å¿—ID
            search_results: æœç´¢ç»“æœåˆ—è¡¨ (å­—å…¸æ ¼å¼)
            results_count: ç»“æœæ•°é‡

        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ

        Example:
            >>> await repo.update_search_results(
            ...     log_id="248728141926559744",
            ...     search_results=[
            ...         {
            ...             "title": "GPT-5",
            ...             "url": "https://...",
            ...             "snippet": "...",
            ...             "position": 1,
            ...             "score": 0.95,
            ...             "source": "serpapi"
            ...         }
            ...     ],
            ...     results_count=10
            ... )
        """
        collection = await self._get_collection()

        # æ›´æ–°æ–‡æ¡£
        result = await collection.update_one(
            {"_id": log_id},
            {
                "$set": {
                    "search_results": search_results,
                    "results_count": results_count,
                    "status": "completed",
                    "updated_at": datetime.utcnow()
                }
            }
        )

        success = result.modified_count > 0
        if success:
            logger.info(f"æ›´æ–°æœç´¢ç»“æœæˆåŠŸ: log_id={log_id}, count={results_count}")
        else:
            logger.warning(f"æ›´æ–°æœç´¢ç»“æœå¤±è´¥: log_id={log_id}")

        return success

    async def get_search_results(
        self,
        log_id: str
    ) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–æœç´¢ç»“æœ

        Args:
            log_id: æ—¥å¿—ID

        Returns:
            Optional[List[Dict]]: æœç´¢ç»“æœåˆ—è¡¨ï¼Œä¸å­˜åœ¨æ—¶è¿”å› None

        Example:
            >>> results = await repo.get_search_results("248728141926559744")
            >>> if results:
            ...     for r in results:
            ...         print(r["title"], r["url"])
        """
        collection = await self._get_collection()

        # æŸ¥è¯¢æ–‡æ¡£ï¼Œä»…è¿”å›æœç´¢ç»“æœå­—æ®µ
        document = await collection.find_one(
            {"_id": log_id},
            {"search_results": 1, "_id": 0}
        )

        if not document:
            logger.debug(f"æœç´¢è®°å½•ä¸å­˜åœ¨: log_id={log_id}")
            return None

        # è¿”å›æœç´¢ç»“æœæ•°ç»„
        return document.get("search_results", [])
```

### 1.3 Service å±‚å®ç°

```python
# src/services/nl_search/nl_search_service.py

class NLSearchService:
    # ... ç°æœ‰æ–¹æ³• ...

    async def create_search(
        self,
        query_text: str,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºè‡ªç„¶è¯­è¨€æœç´¢ (ä¿®æ”¹ç‰ˆæœ¬ - æŒä¹…åŒ–æœç´¢ç»“æœ)
        """
        # éªŒè¯è¾“å…¥
        if not query_text or not query_text.strip():
            raise ValueError("æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        query_text = query_text.strip()
        logger.info(f"å¼€å§‹å¤„ç†è‡ªç„¶è¯­è¨€æœç´¢: {query_text[:50]}...")

        try:
            # 1. åˆ›å»ºæœç´¢è®°å½•
            log_id = await self.repository.create(
                query_text=query_text,
                llm_analysis=None
            )

            # 2-4. LLM è§£æå’Œåˆ†æ (ä¿æŒä¸å˜)
            analysis = await self.llm_processor.parse_query(query_text)
            await self.repository.update_llm_analysis(log_id, analysis)
            refined_query = await self.llm_processor.refine_query(query_text)

            # 5. æ‰§è¡Œæœç´¢
            search_results = await self.gpt5_adapter.search(
                query=refined_query,
                max_results=nl_search_config.max_results_per_query
            )
            logger.info(f"æœç´¢å®Œæˆ: è·å¾—{len(search_results)}ä¸ªç»“æœ")

            # ğŸ†• 6. ä¿å­˜æœç´¢ç»“æœåˆ°æ•°æ®åº“
            results_dict = [r.to_dict() for r in search_results]
            await self.repository.update_search_results(
                log_id=log_id,
                search_results=results_dict,
                results_count=len(search_results)
            )
            logger.info(f"æœç´¢ç»“æœå·²ä¿å­˜: log_id={log_id}")

            # 7. æ„å»ºè¿”å›ç»“æœ
            result = {
                "log_id": log_id,
                "query_text": query_text,
                "analysis": analysis,
                "refined_query": refined_query,
                "results": results_dict,
                "created_at": datetime.now().isoformat()
            }

            return result

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}", exc_info=True)
            raise

    async def get_search_results(
        self,
        log_id: str,
        limit: Optional[int] = None,
        offset: int = 0
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–æœç´¢ç»“æœ

        Args:
            log_id: æœç´¢è®°å½•ID
            limit: è¿”å›æ•°é‡é™åˆ¶ (å¯é€‰)
            offset: åˆ†é¡µåç§»é‡ (é»˜è®¤ 0)

        Returns:
            Optional[Dict]: æœç´¢ç»“æœæ•°æ®ï¼Œä¸å­˜åœ¨æ—¶è¿”å› None

        Example:
            >>> result = await service.get_search_results("248728141926559744")
            >>> print(f"å…± {result['total_count']} æ¡ç»“æœ")
            >>> for item in result['results']:
            ...     print(item['title'])
        """
        logger.info(f"è·å–æœç´¢ç»“æœ: log_id={log_id}")

        try:
            # 1. è·å–æœç´¢è®°å½• (åŒ…å«åŸºæœ¬ä¿¡æ¯)
            log = await self.repository.get_by_id(log_id)
            if not log:
                logger.warning(f"æœç´¢è®°å½•ä¸å­˜åœ¨: log_id={log_id}")
                return None

            # 2. è·å–æœç´¢ç»“æœ
            search_results = await self.repository.get_search_results(log_id)
            if search_results is None:
                logger.warning(f"æœç´¢ç»“æœä¸å­˜åœ¨: log_id={log_id}")
                return None

            # 3. åˆ†é¡µå¤„ç†
            total_count = len(search_results)
            if limit is not None:
                search_results = search_results[offset:offset + limit]

            # 4. æ„å»ºå“åº”
            return {
                "log_id": log_id,
                "query_text": log["query_text"],
                "total_count": total_count,
                "results": search_results,
                "llm_analysis": log.get("llm_analysis"),
                "status": log.get("status", "completed"),
                "created_at": log["created_at"].isoformat() if log.get("created_at") else None
            }

        except Exception as e:
            logger.error(f"è·å–æœç´¢ç»“æœå¤±è´¥: {e}", exc_info=True)
            raise
```

### 1.4 API ç«¯ç‚¹å®ç°

```python
# src/api/v1/endpoints/nl_search.py

@router.get(
    "/{log_id}/results",
    response_model=SearchResultsResponse,
    summary="è·å–æœç´¢ç»“æœ",
    description="è·å–è‡ªç„¶è¯­è¨€æœç´¢çš„æ‰€æœ‰ç»“æœ"
)
async def get_search_results(
    log_id: str,
    limit: Optional[int] = Query(None, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åˆ†é¡µåç§»é‡")
):
    """
    è·å–æœç´¢ç»“æœ

    **åŠŸèƒ½**: âœ… å®Œæ•´å®ç°

    **åŠŸèƒ½**:
    - è·å–æŸæ¬¡æœç´¢çš„æ‰€æœ‰ç»“æœ
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - åŒ…å« LLM åˆ†æç»“æœ

    Args:
        log_id (str): æœç´¢è®°å½•IDï¼ˆé›ªèŠ±ç®—æ³•IDå­—ç¬¦ä¸²ï¼‰
        limit (Optional[int]): è¿”å›æ•°é‡é™åˆ¶ (1-100)
        offset (int): åˆ†é¡µåç§»é‡

    Returns:
        SearchResultsResponse: æœç´¢ç»“æœè¯¦æƒ…

    Raises:
        HTTPException:
            - 503: åŠŸèƒ½æœªå¯ç”¨
            - 404: æœç´¢è®°å½•ä¸å­˜åœ¨
            - 500: å†…éƒ¨é”™è¯¯

    Example:
        ```bash
        curl -X GET "http://localhost:8000/api/v1/nl-search/248728141926559744/results?limit=10"
        ```
    """
    # æ£€æŸ¥åŠŸèƒ½å¼€å…³
    if not nl_search_config.enabled:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "åŠŸèƒ½æœªå¯ç”¨",
                "message": "è‡ªç„¶è¯­è¨€æœç´¢åŠŸèƒ½å·²å…³é—­ã€‚è®¾ç½®ç¯å¢ƒå˜é‡ NL_SEARCH_ENABLED=true å¯ç”¨æ­¤åŠŸèƒ½ã€‚",
                "status": "disabled"
            }
        )

    try:
        logger.info(f"è·å–æœç´¢ç»“æœ: log_id={log_id}, limit={limit}, offset={offset}")

        # è°ƒç”¨æœåŠ¡å±‚
        result = await nl_search_service.get_search_results(
            log_id=log_id,
            limit=limit,
            offset=offset
        )

        if not result:
            logger.warning(f"æœç´¢è®°å½•æˆ–ç»“æœä¸å­˜åœ¨: log_id={log_id}")
            raise HTTPException(
                status_code=404,
                detail={
                    "error": "è®°å½•ä¸å­˜åœ¨",
                    "message": f"æœªæ‰¾åˆ°æœç´¢è®°å½•æˆ–ç»“æœ: log_id={log_id}",
                    "log_id": log_id
                }
            )

        # æ„å»ºå“åº”
        return SearchResultsResponse(
            log_id=result["log_id"],
            query_text=result["query_text"],
            total_count=result["total_count"],
            results=[SearchResultItem(**r) for r in result["results"]],
            llm_analysis=result.get("llm_analysis"),
            status=result["status"],
            created_at=result["created_at"]
        )

    except HTTPException:
        raise

    except Exception as e:
        logger.error(f"è·å–æœç´¢ç»“æœå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "æœåŠ¡é”™è¯¯",
                "message": "è·å–æœç´¢ç»“æœå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
                "log_id": log_id
            }
        )
```

---

## å®ç°æ–¹æ¡ˆ 2: POST /{log_id}/select

### 2.1 æ•°æ®æ¨¡å‹å®šä¹‰

```python
# src/api/v1/endpoints/nl_search.py

class UserSelectionRequest(BaseModel):
    """ç”¨æˆ·é€‰æ‹©è¯·æ±‚"""
    result_url: str = Field(..., description="é€‰ä¸­çš„ç»“æœURL")
    action_type: str = Field(
        "click",
        description="æ“ä½œç±»å‹: click, bookmark, archive",
        regex="^(click|bookmark|archive)$"
    )
    user_id: Optional[str] = Field(None, description="ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰")

    class Config:
        json_schema_extra = {
            "example": {
                "result_url": "https://example.com/gpt5",
                "action_type": "click",
                "user_id": "user_123"
            }
        }


class UserSelectionResponse(BaseModel):
    """ç”¨æˆ·é€‰æ‹©å“åº”"""
    event_id: str = Field(..., description="äº‹ä»¶ID")
    log_id: str = Field(..., description="æœç´¢è®°å½•ID")
    result_url: str = Field(..., description="é€‰ä¸­çš„ç»“æœURL")
    action_type: str = Field(..., description="æ“ä½œç±»å‹")
    recorded_at: str = Field(..., description="è®°å½•æ—¶é—´")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")

    class Config:
        json_schema_extra = {
            "example": {
                "event_id": "event_123456789",
                "log_id": "248728141926559744",
                "result_url": "https://example.com/gpt5",
                "action_type": "click",
                "recorded_at": "2025-11-17T10:00:00Z",
                "message": "ç”¨æˆ·é€‰æ‹©å·²è®°å½•"
            }
        }
```

### 2.2 MongoDB é›†åˆè®¾è®¡

```javascript
// user_selection_events é›†åˆ
{
    "_id": "event_123456789",
    "log_id": "248728141926559744",  // å…³è”æœç´¢è®°å½•
    "result_url": "https://example.com/gpt5",  // é€‰ä¸­çš„ç»“æœURL
    "action_type": "click",  // æ“ä½œç±»å‹
    "user_id": "user_123",  // ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
    "selected_at": ISODate("2025-11-17T10:00:00Z"),  // é€‰æ‹©æ—¶é—´
    "user_agent": "Mozilla/5.0...",  // ç”¨æˆ·ä»£ç†ï¼ˆå¯é€‰ï¼‰
    "ip_address": "192.168.1.1"  // IPåœ°å€ï¼ˆå¯é€‰ï¼‰
}

// ç´¢å¼•
db.user_selection_events.createIndex({ "log_id": 1, "selected_at": -1 })
db.user_selection_events.createIndex({ "user_id": 1, "selected_at": -1 })
db.user_selection_events.createIndex({ "selected_at": -1 })
```

### 2.3 Repository å±‚å®ç°

```python
# src/infrastructure/database/user_selection_repository.py (æ–°å»ºæ–‡ä»¶)

"""
ç”¨æˆ·é€‰æ‹©äº‹ä»¶ä»“å‚¨
è®°å½•ç”¨æˆ·å¯¹æœç´¢ç»“æœçš„é€‰æ‹©è¡Œä¸º
"""
import logging
from typing import Optional, List, Dict, Any
from datetime import datetime

from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.id_generator import generate_string_id

logger = logging.getLogger(__name__)


class UserSelectionEventRepository:
    """ç”¨æˆ·é€‰æ‹©äº‹ä»¶ä»“å‚¨"""

    def __init__(self):
        self.db = None
        self.collection_name = "user_selection_events"

    async def _get_collection(self):
        """è·å– MongoDB é›†åˆ"""
        if self.db is None:
            self.db = await get_mongodb_database()
        return self.db[self.collection_name]

    async def create(
        self,
        log_id: str,
        result_url: str,
        action_type: str,
        user_id: Optional[str] = None,
        user_agent: Optional[str] = None,
        ip_address: Optional[str] = None
    ) -> str:
        """
        åˆ›å»ºç”¨æˆ·é€‰æ‹©äº‹ä»¶

        Args:
            log_id: æœç´¢è®°å½•ID
            result_url: é€‰ä¸­çš„ç»“æœURL
            action_type: æ“ä½œç±»å‹ (click, bookmark, archive)
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
            user_agent: ç”¨æˆ·ä»£ç†ï¼ˆå¯é€‰ï¼‰
            ip_address: IPåœ°å€ï¼ˆå¯é€‰ï¼‰

        Returns:
            str: äº‹ä»¶ID

        Example:
            >>> event_id = await repo.create(
            ...     log_id="248728141926559744",
            ...     result_url="https://example.com/gpt5",
            ...     action_type="click",
            ...     user_id="user_123"
            ... )
        """
        collection = await self._get_collection()

        # ç”Ÿæˆäº‹ä»¶ID
        event_id = generate_string_id()

        # å‡†å¤‡æ–‡æ¡£
        document = {
            "_id": event_id,
            "log_id": log_id,
            "result_url": result_url,
            "action_type": action_type,
            "user_id": user_id,
            "selected_at": datetime.utcnow(),
            "user_agent": user_agent,
            "ip_address": ip_address
        }

        # æ’å…¥æ–‡æ¡£
        await collection.insert_one(document)

        logger.info(
            f"åˆ›å»ºç”¨æˆ·é€‰æ‹©äº‹ä»¶: event_id={event_id}, "
            f"log_id={log_id}, action={action_type}"
        )

        return event_id

    async def get_by_log_id(
        self,
        log_id: str,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŸæ¬¡æœç´¢çš„æ‰€æœ‰ç”¨æˆ·é€‰æ‹©äº‹ä»¶

        Args:
            log_id: æœç´¢è®°å½•ID
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            List[Dict]: äº‹ä»¶åˆ—è¡¨

        Example:
            >>> events = await repo.get_by_log_id("248728141926559744")
            >>> for event in events:
            ...     print(event["result_url"], event["action_type"])
        """
        collection = await self._get_collection()

        # æŸ¥è¯¢äº‹ä»¶ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        cursor = collection.find(
            {"log_id": log_id}
        ).sort("selected_at", -1).limit(limit)

        events = await cursor.to_list(length=limit)
        return events

    async def get_by_user_id(
        self,
        user_id: str,
        limit: int = 100,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """
        è·å–æŸç”¨æˆ·çš„æ‰€æœ‰é€‰æ‹©äº‹ä»¶

        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: åˆ†é¡µåç§»é‡

        Returns:
            List[Dict]: äº‹ä»¶åˆ—è¡¨
        """
        collection = await self._get_collection()

        # æŸ¥è¯¢äº‹ä»¶
        cursor = collection.find(
            {"user_id": user_id}
        ).sort("selected_at", -1).skip(offset).limit(limit)

        events = await cursor.to_list(length=limit)
        return events

    async def count_by_log_id(self, log_id: str) -> int:
        """ç»Ÿè®¡æŸæ¬¡æœç´¢çš„é€‰æ‹©æ¬¡æ•°"""
        collection = await self._get_collection()
        return await collection.count_documents({"log_id": log_id})

    async def create_indexes(self):
        """åˆ›å»ºç´¢å¼•"""
        collection = await self._get_collection()

        # 1. log_id + æ—¶é—´ç´¢å¼•
        await collection.create_index(
            [("log_id", 1), ("selected_at", -1)],
            name="log_time_idx"
        )

        # 2. user_id + æ—¶é—´ç´¢å¼•
        await collection.create_index(
            [("user_id", 1), ("selected_at", -1)],
            name="user_time_idx"
        )

        # 3. æ—¶é—´ç´¢å¼•
        await collection.create_index(
            [("selected_at", -1)],
            name="time_idx"
        )

        logger.info("ç”¨æˆ·é€‰æ‹©äº‹ä»¶ç´¢å¼•åˆ›å»ºå®Œæˆ")


# å…¨å±€å®ä¾‹
user_selection_repository = UserSelectionEventRepository()
```

### 2.4 Service å±‚å®ç°

```python
# src/services/nl_search/nl_search_service.py

# å¯¼å…¥æ–°çš„ä»“å‚¨
from src.infrastructure.database.user_selection_repository import user_selection_repository

class NLSearchService:
    def __init__(self):
        # ... ç°æœ‰åˆå§‹åŒ–ä»£ç  ...
        self.selection_repository = user_selection_repository

    async def record_user_selection(
        self,
        log_id: str,
        result_url: str,
        action_type: str,
        user_id: Optional[str] = None,
        user_agent: Optional[str] = None,
        ip_address: Optional[str] = None
    ) -> str:
        """
        è®°å½•ç”¨æˆ·é€‰æ‹©äº‹ä»¶

        Args:
            log_id: æœç´¢è®°å½•ID
            result_url: é€‰ä¸­çš„ç»“æœURL
            action_type: æ“ä½œç±»å‹
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
            user_agent: ç”¨æˆ·ä»£ç†ï¼ˆå¯é€‰ï¼‰
            ip_address: IPåœ°å€ï¼ˆå¯é€‰ï¼‰

        Returns:
            str: äº‹ä»¶ID

        Raises:
            ValueError: æœç´¢è®°å½•ä¸å­˜åœ¨

        Example:
            >>> event_id = await service.record_user_selection(
            ...     log_id="248728141926559744",
            ...     result_url="https://example.com/gpt5",
            ...     action_type="click"
            ... )
        """
        logger.info(
            f"è®°å½•ç”¨æˆ·é€‰æ‹©: log_id={log_id}, "
            f"url={result_url}, action={action_type}"
        )

        try:
            # 1. éªŒè¯æœç´¢è®°å½•å­˜åœ¨
            log = await self.repository.get_by_id(log_id)
            if not log:
                raise ValueError(f"æœç´¢è®°å½•ä¸å­˜åœ¨: log_id={log_id}")

            # 2. åˆ›å»ºé€‰æ‹©äº‹ä»¶
            event_id = await self.selection_repository.create(
                log_id=log_id,
                result_url=result_url,
                action_type=action_type,
                user_id=user_id,
                user_agent=user_agent,
                ip_address=ip_address
            )

            logger.info(f"ç”¨æˆ·é€‰æ‹©å·²è®°å½•: event_id={event_id}")
            return event_id

        except Exception as e:
            logger.error(f"è®°å½•ç”¨æˆ·é€‰æ‹©å¤±è´¥: {e}", exc_info=True)
            raise

    async def get_selection_statistics(
        self,
        log_id: str
    ) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·é€‰æ‹©ç»Ÿè®¡

        Args:
            log_id: æœç´¢è®°å½•ID

        Returns:
            Dict: ç»Ÿè®¡æ•°æ®

        Example:
            >>> stats = await service.get_selection_statistics("248728141926559744")
            >>> print(f"æ€»ç‚¹å‡»æ•°: {stats['total_clicks']}")
        """
        logger.info(f"è·å–é€‰æ‹©ç»Ÿè®¡: log_id={log_id}")

        try:
            # è·å–æ‰€æœ‰é€‰æ‹©äº‹ä»¶
            events = await self.selection_repository.get_by_log_id(log_id)

            # ç»Ÿè®¡æ•°æ®
            total_count = len(events)
            click_count = sum(1 for e in events if e["action_type"] == "click")
            bookmark_count = sum(1 for e in events if e["action_type"] == "bookmark")
            archive_count = sum(1 for e in events if e["action_type"] == "archive")

            # ç»Ÿè®¡ URL ç‚¹å‡»æ¬¡æ•°
            url_clicks = {}
            for event in events:
                url = event["result_url"]
                url_clicks[url] = url_clicks.get(url, 0) + 1

            return {
                "log_id": log_id,
                "total_count": total_count,
                "click_count": click_count,
                "bookmark_count": bookmark_count,
                "archive_count": archive_count,
                "top_urls": sorted(
                    url_clicks.items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:5]  # å‰5ä¸ªæœ€çƒ­é—¨URL
            }

        except Exception as e:
            logger.error(f"è·å–é€‰æ‹©ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
            raise
```

### 2.5 API ç«¯ç‚¹å®ç°

```python
# src/api/v1/endpoints/nl_search.py

@router.post(
    "/{log_id}/select",
    response_model=UserSelectionResponse,
    summary="ç”¨æˆ·é€‰æ‹©ç»“æœ",
    description="è®°å½•ç”¨æˆ·å¯¹æœç´¢ç»“æœçš„é€‰æ‹©"
)
async def select_search_result(
    log_id: str,
    request: UserSelectionRequest,
    user_agent: Optional[str] = Header(None, alias="User-Agent"),
    x_forwarded_for: Optional[str] = Header(None, alias="X-Forwarded-For")
):
    """
    è®°å½•ç”¨æˆ·é€‰æ‹©ç»“æœ

    **åŠŸèƒ½**: âœ… å®Œæ•´å®ç°

    **ç”¨é€”**:
    - æ”¶é›†ç”¨æˆ·åé¦ˆ
    - ä¼˜åŒ–LLMç†è§£
    - ä¸ªæ€§åŒ–æ¨è

    Args:
        log_id (str): æœç´¢è®°å½•ID
        request (UserSelectionRequest): é€‰æ‹©è¯·æ±‚
        user_agent (str): ç”¨æˆ·ä»£ç† (è‡ªåŠ¨ä» Header è·å–)
        x_forwarded_for (str): å®¢æˆ·ç«¯IP (è‡ªåŠ¨ä» Header è·å–)

    Returns:
        UserSelectionResponse: é€‰æ‹©è®°å½•å“åº”

    Raises:
        HTTPException:
            - 503: åŠŸèƒ½æœªå¯ç”¨
            - 404: æœç´¢è®°å½•ä¸å­˜åœ¨
            - 400: è¾“å…¥éªŒè¯å¤±è´¥
            - 500: å†…éƒ¨é”™è¯¯

    Example:
        ```bash
        curl -X POST "http://localhost:8000/api/v1/nl-search/248728141926559744/select" \\
          -H "Content-Type: application/json" \\
          -d '{
            "result_url": "https://example.com/gpt5",
            "action_type": "click",
            "user_id": "user_123"
          }'
        ```
    """
    # æ£€æŸ¥åŠŸèƒ½å¼€å…³
    if not nl_search_config.enabled:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "åŠŸèƒ½æœªå¯ç”¨",
                "message": "è‡ªç„¶è¯­è¨€æœç´¢åŠŸèƒ½å·²å…³é—­ã€‚",
                "status": "disabled"
            }
        )

    try:
        logger.info(
            f"è®°å½•ç”¨æˆ·é€‰æ‹©: log_id={log_id}, "
            f"url={request.result_url}, action={request.action_type}"
        )

        # è·å–å®¢æˆ·ç«¯IP
        ip_address = x_forwarded_for.split(",")[0].strip() if x_forwarded_for else None

        # è°ƒç”¨æœåŠ¡å±‚
        event_id = await nl_search_service.record_user_selection(
            log_id=log_id,
            result_url=request.result_url,
            action_type=request.action_type,
            user_id=request.user_id,
            user_agent=user_agent,
            ip_address=ip_address
        )

        # æ„å»ºå“åº”
        return UserSelectionResponse(
            event_id=event_id,
            log_id=log_id,
            result_url=request.result_url,
            action_type=request.action_type,
            recorded_at=datetime.utcnow().isoformat(),
            message="ç”¨æˆ·é€‰æ‹©å·²è®°å½•"
        )

    except ValueError as e:
        # è¾“å…¥éªŒè¯é”™è¯¯ (å¦‚æœç´¢è®°å½•ä¸å­˜åœ¨)
        logger.warning(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(
            status_code=404,
            detail={
                "error": "è®°å½•ä¸å­˜åœ¨",
                "message": str(e),
                "log_id": log_id
            }
        )

    except Exception as e:
        logger.error(f"è®°å½•ç”¨æˆ·é€‰æ‹©å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "æœåŠ¡é”™è¯¯",
                "message": "è®°å½•ç”¨æˆ·é€‰æ‹©å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
                "log_id": log_id
            }
        )
```

---

## æ•°æ®åº“è®¾è®¡

### ç´¢å¼•åˆ›å»ºè„šæœ¬

```python
# scripts/create_nl_search_indexes.py (æ–°å»ºæ–‡ä»¶)

"""
NL Search ç´¢å¼•åˆ›å»ºè„šæœ¬
"""
import asyncio
import logging
from src.infrastructure.database.connection import get_mongodb_database
from src.infrastructure.database.mongo_nl_search_repository import mongo_nl_search_repository
from src.infrastructure.database.user_selection_repository import user_selection_repository

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def create_all_indexes():
    """åˆ›å»ºæ‰€æœ‰ç´¢å¼•"""
    logger.info("å¼€å§‹åˆ›å»º NL Search ç´¢å¼•...")

    try:
        # 1. nl_search_logs é›†åˆç´¢å¼•
        await mongo_nl_search_repository.create_indexes()
        logger.info("âœ… nl_search_logs ç´¢å¼•åˆ›å»ºå®Œæˆ")

        # 2. user_selection_events é›†åˆç´¢å¼•
        await user_selection_repository.create_indexes()
        logger.info("âœ… user_selection_events ç´¢å¼•åˆ›å»ºå®Œæˆ")

        logger.info("ğŸ‰ æ‰€æœ‰ç´¢å¼•åˆ›å»ºå®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(create_all_indexes())
```

---

## æµ‹è¯•æ–¹æ¡ˆ

### é›†æˆæµ‹è¯•è„šæœ¬

```python
# scripts/test_nl_search_complete.py (æ–°å»ºæ–‡ä»¶)

"""
NL Search å®Œæ•´åŠŸèƒ½æµ‹è¯•
æµ‹è¯•æœç´¢ç»“æœæŸ¥è¯¢å’Œç”¨æˆ·é€‰æ‹©è®°å½•åŠŸèƒ½
"""
import asyncio
import logging
from src.services.nl_search.nl_search_service import nl_search_service

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_complete_flow():
    """æµ‹è¯•å®Œæ•´æµç¨‹"""
    logger.info("=" * 60)
    logger.info("NL Search å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    logger.info("=" * 60)

    try:
        # æµ‹è¯• 1: åˆ›å»ºæœç´¢ (åŒ…å«ç»“æœä¿å­˜)
        logger.info("\næµ‹è¯• 1: åˆ›å»ºæœç´¢å¹¶ä¿å­˜ç»“æœ")
        result = await nl_search_service.create_search(
            query_text="æœ€è¿‘æœ‰å“ªäº›AIæŠ€æœ¯çªç ´",
            user_id="test_user_001"
        )
        log_id = result["log_id"]
        logger.info(f"âœ… æœç´¢åˆ›å»ºæˆåŠŸ: log_id={log_id}")
        logger.info(f"   æœç´¢ç»“æœæ•°: {len(result['results'])}")

        # æµ‹è¯• 2: è·å–æœç´¢ç»“æœ
        logger.info(f"\næµ‹è¯• 2: è·å–æœç´¢ç»“æœ (log_id={log_id})")
        search_results = await nl_search_service.get_search_results(log_id)
        if search_results:
            logger.info(f"âœ… è·å–æœç´¢ç»“æœæˆåŠŸ")
            logger.info(f"   æŸ¥è¯¢æ–‡æœ¬: {search_results['query_text']}")
            logger.info(f"   ç»“æœæ€»æ•°: {search_results['total_count']}")
            logger.info(f"   å‰3ä¸ªç»“æœ:")
            for i, r in enumerate(search_results['results'][:3], 1):
                logger.info(f"     {i}. {r['title']} - {r['url']}")
        else:
            logger.error("âŒ è·å–æœç´¢ç»“æœå¤±è´¥")
            return

        # æµ‹è¯• 3: è®°å½•ç”¨æˆ·é€‰æ‹©
        logger.info(f"\næµ‹è¯• 3: è®°å½•ç”¨æˆ·é€‰æ‹©")
        if search_results['results']:
            first_result = search_results['results'][0]
            event_id = await nl_search_service.record_user_selection(
                log_id=log_id,
                result_url=first_result['url'],
                action_type="click",
                user_id="test_user_001"
            )
            logger.info(f"âœ… ç”¨æˆ·é€‰æ‹©å·²è®°å½•: event_id={event_id}")

            # å†æ¬¡è®°å½• (ä¸åŒæ“ä½œç±»å‹)
            event_id_2 = await nl_search_service.record_user_selection(
                log_id=log_id,
                result_url=first_result['url'],
                action_type="bookmark",
                user_id="test_user_001"
            )
            logger.info(f"âœ… ä¹¦ç­¾è®°å½•å·²ä¿å­˜: event_id={event_id_2}")

        # æµ‹è¯• 4: è·å–é€‰æ‹©ç»Ÿè®¡
        logger.info(f"\næµ‹è¯• 4: è·å–é€‰æ‹©ç»Ÿè®¡")
        stats = await nl_search_service.get_selection_statistics(log_id)
        logger.info(f"âœ… ç»Ÿè®¡æ•°æ®:")
        logger.info(f"   æ€»æ“ä½œæ•°: {stats['total_count']}")
        logger.info(f"   ç‚¹å‡»æ•°: {stats['click_count']}")
        logger.info(f"   ä¹¦ç­¾æ•°: {stats['bookmark_count']}")
        if stats['top_urls']:
            logger.info(f"   çƒ­é—¨URL:")
            for url, count in stats['top_urls']:
                logger.info(f"     {url} ({count}æ¬¡)")

        logger.info("\n" + "=" * 60)
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)


if __name__ == "__main__":
    asyncio.run(test_complete_flow())
```

---

## éƒ¨ç½²æ¸…å•

### éƒ¨ç½²æ­¥éª¤

```bash
# 1. åˆ›å»ºç´¢å¼•
python scripts/create_nl_search_indexes.py

# 2. è¿è¡Œé›†æˆæµ‹è¯•
python scripts/test_nl_search_complete.py

# 3. å¯åŠ¨æœåŠ¡
# (uvicorn å·²åœ¨è¿è¡Œï¼Œæ— éœ€é¢å¤–æ“ä½œ)

# 4. API æµ‹è¯•
# æµ‹è¯•æœç´¢ç»“æœè·å–
curl -X GET "http://localhost:8000/api/v1/nl-search/248728141926559744/results?limit=10"

# æµ‹è¯•ç”¨æˆ·é€‰æ‹©è®°å½•
curl -X POST "http://localhost:8000/api/v1/nl-search/248728141926559744/select" \
  -H "Content-Type: application/json" \
  -d '{
    "result_url": "https://example.com/gpt5",
    "action_type": "click",
    "user_id": "user_123"
  }'
```

### æ–‡ä»¶æ¸…å•

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶**:
1. `src/api/v1/endpoints/nl_search.py` - API ç«¯ç‚¹å®ç°
2. `src/services/nl_search/nl_search_service.py` - Service å±‚é€»è¾‘
3. `src/infrastructure/database/mongo_nl_search_repository.py` - Repository æ‰©å±•

**éœ€è¦æ–°å»ºçš„æ–‡ä»¶**:
1. `src/infrastructure/database/user_selection_repository.py` - ç”¨æˆ·é€‰æ‹©ä»“å‚¨
2. `scripts/create_nl_search_indexes.py` - ç´¢å¼•åˆ›å»ºè„šæœ¬
3. `scripts/test_nl_search_complete.py` - é›†æˆæµ‹è¯•è„šæœ¬

### ç¯å¢ƒå˜é‡

```bash
# .env æ–‡ä»¶
NL_SEARCH_ENABLED=true  # å¯ç”¨ NL Search åŠŸèƒ½
```

---

## æ€»ç»“

### å®ç°å·¥ä½œé‡ä¼°ç®—

| ä»»åŠ¡ | å·¥ä½œé‡ | ä¼˜å…ˆçº§ |
|------|--------|--------|
| æœç´¢ç»“æœæŸ¥è¯¢ (`GET /{log_id}/results`) | 2-3 å¤© | ğŸ”¥ é«˜ |
| ç”¨æˆ·é€‰æ‹©è®°å½• (`POST /{log_id}/select`) | 1-2 å¤© | ğŸŸ¡ ä¸­ |
| ç´¢å¼•åˆ›å»ºå’Œæµ‹è¯• | 0.5 å¤© | ğŸŸ¡ ä¸­ |
| **æ€»è®¡** | **3.5-5.5 å¤©** | |

### å…³é”®æŠ€æœ¯å†³ç­–

1. âœ… **æœç´¢ç»“æœå†…åµŒå­˜å‚¨**: ç®€åŒ–æŸ¥è¯¢ï¼Œæå‡æ€§èƒ½
2. âœ… **ç”¨æˆ·é€‰æ‹©ç‹¬ç«‹é›†åˆ**: æ”¯æŒè¡Œä¸ºåˆ†æå’Œç»Ÿè®¡
3. âœ… **å®Œæ•´çš„ç´¢å¼•è®¾è®¡**: ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
4. âœ… **è¯¦ç»†çš„æµ‹è¯•æ–¹æ¡ˆ**: ä¿è¯åŠŸèƒ½è´¨é‡

### åç»­ä¼˜åŒ–æ–¹å‘

1. **è¡Œä¸ºåˆ†æç³»ç»Ÿ**: åŸºäºç”¨æˆ·é€‰æ‹©æ•°æ®ä¼˜åŒ– LLM ç†è§£
2. **æ¨èç³»ç»Ÿ**: åŸºäºå†å²è¡Œä¸ºæä¾›ä¸ªæ€§åŒ–æ¨è
3. **A/B æµ‹è¯•**: ä¸åŒæœç´¢ç­–ç•¥çš„æ•ˆæœå¯¹æ¯”
4. **å®æ—¶ç»Ÿè®¡**: WebSocket æ¨é€çƒ­é—¨æœç´¢ç»“æœ

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-17
**ä½œè€…**: Claude Code (Backend Architect + Backend Engineer)
