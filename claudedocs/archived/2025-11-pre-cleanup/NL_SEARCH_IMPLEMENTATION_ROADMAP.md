# NL Search å®æ–½è·¯çº¿å›¾

**æ–‡æ¡£ç±»å‹**: å®æ–½æŒ‡å—
**ç›®æ ‡è¯»è€…**: åç«¯å¼€å‘å·¥ç¨‹å¸ˆ
**å½“å‰çŠ¶æ€**: 60%å®Œæˆï¼Œéœ€è¦å®Œæˆå…³é”®ç»„ä»¶
**é¢„è®¡å®Œæˆæ—¶é—´**: 3-4å°æ—¶ï¼ˆMVPï¼‰

---

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### å½“å‰çŠ¶æ€æ¦‚è§ˆ

```
è¿›åº¦ï¼šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60%

âœ… å·²å®Œæˆï¼š
- Phase 1: åŸºç¡€æ¶æ„ï¼ˆå®ä½“ã€ä»“åº“ã€é…ç½®ï¼‰
- Phase 2: LLMå¤„ç†å™¨
- Phase 3: GPT5æœç´¢é€‚é…å™¨
- 57ä¸ªå•å…ƒæµ‹è¯•ï¼ˆè¦†ç›–ç‡85%+ï¼‰
- å®Œæ•´è®¾è®¡æ–‡æ¡£

âŒ å¾…å®Œæˆï¼š
- æ•°æ®åº“è¡¨åˆ›å»º
- nl_search_service.pyï¼ˆæ ¸å¿ƒæœåŠ¡ï¼‰
- APIç«¯ç‚¹é›†æˆ
- Gitæäº¤ä¿æŠ¤ä»£ç 
```

### ç«‹å³è¡ŒåŠ¨æ¸…å•

æŒ‰ç…§ä¼˜å…ˆçº§é¡ºåºï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡å³å¯ä½¿åŠŸèƒ½å¯ç”¨ï¼š

1. **[ ] åˆ›å»ºæ•°æ®åº“è¡¨** (5åˆ†é’Ÿ) - ğŸ”´ å…³é”®
2. **[ ] å®ç°nl_search_service.py** (2-3å°æ—¶) - ğŸ”´ å…³é”®
3. **[ ] é›†æˆAPIç«¯ç‚¹** (1å°æ—¶) - ğŸ”´ å…³é”®
4. **[ ] Gitæäº¤ä»£ç ** (10åˆ†é’Ÿ) - ğŸ”´ å…³é”®
5. **[ ] ç«¯åˆ°ç«¯æµ‹è¯•** (1å°æ—¶) - ğŸŸ¡ å»ºè®®

---

## ğŸš€ ä»»åŠ¡1: åˆ›å»ºæ•°æ®åº“è¡¨

### 1.1 æ‰§è¡Œå»ºè¡¨è„šæœ¬

**æ–¹æ³•1: ä½¿ç”¨Pythonè„šæœ¬ï¼ˆæ¨èï¼‰**

```bash
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd /Users/lanxionggao/Documents/guanshanPython

# æ‰§è¡Œå»ºè¡¨è„šæœ¬
python scripts/create_nl_search_tables.py
```

**é¢„æœŸè¾“å‡º**:
```
å¼€å§‹åˆ›å»º NL Search æ•°æ®è¡¨...
è¯»å– SQL è„šæœ¬: scripts/create_nl_search_tables.sql
âœ… [1/1] CREATE æ‰§è¡ŒæˆåŠŸ

============================================================
ğŸ‰ NL Search æ•°æ®è¡¨åˆ›å»ºå®Œæˆï¼
============================================================
âœ… æˆåŠŸæ‰§è¡Œ: 1 æ¡è¯­å¥
â­ï¸  è·³è¿‡: 2 æ¡è¯­å¥
ğŸ“Š è¡¨å: nl_search_logs
============================================================

ğŸ“‹ è¡¨ç»“æ„:
--------------------------------------------------------------------------------
å­—æ®µ                 ç±»å‹                 NULL     é”®       é»˜è®¤å€¼          é¢å¤–
--------------------------------------------------------------------------------
id                   bigint              NO       PRI                      auto_increment
query_text           text                NO
llm_analysis         json                YES
created_at           datetime            YES               CURRENT_TIMESTAMP
--------------------------------------------------------------------------------
```

**æ–¹æ³•2: ç›´æ¥æ‰§è¡ŒSQLï¼ˆå¤‡é€‰ï¼‰**

```bash
# éœ€è¦MySQL/MariaDBå®¢æˆ·ç«¯
mysql -u root -p search_platform < scripts/create_nl_search_tables.sql
```

### 1.2 éªŒè¯è¡¨åˆ›å»º

```bash
# æ–¹æ³•1: PythonéªŒè¯
python -c "
import asyncio
from src.infrastructure.database.connection import get_mariadb_session

async def verify():
    session = await get_mariadb_session()
    result = await session.execute('SHOW TABLES LIKE \"nl_search_logs\"')
    row = result.fetchone()
    if row:
        print('âœ… è¡¨åˆ›å»ºæˆåŠŸ')
        result = await session.execute('DESC nl_search_logs')
        rows = result.fetchall()
        for r in rows:
            print(f'  {r[0]}: {r[1]}')
    else:
        print('âŒ è¡¨ä¸å­˜åœ¨')
    await session.close()

asyncio.run(verify())
"

# æ–¹æ³•2: MySQLå‘½ä»¤éªŒè¯
mysql -u root -p -e "USE search_platform; DESC nl_search_logs;"
```

**æˆåŠŸæ ‡å‡†**:
- [x] nl_search_logsè¡¨å­˜åœ¨
- [x] åŒ…å«4ä¸ªå­—æ®µï¼šid, query_text, llm_analysis, created_at
- [x] idå­—æ®µä¸ºä¸»é”®ä¸”è‡ªå¢
- [x] ç´¢å¼•idx_createdå­˜åœ¨

---

## ğŸ—ï¸ ä»»åŠ¡2: å®ç°nl_search_service.py

### 2.1 åˆ›å»ºæœåŠ¡æ–‡ä»¶

**æ–‡ä»¶è·¯å¾„**: `src/services/nl_search/nl_search_service.py`

**å®Œæ•´å®ç°ä»£ç **:

```python
"""
NL Search æ ¸å¿ƒæœåŠ¡
ç”¨äºç¼–æ’æ•´ä¸ªè‡ªç„¶è¯­è¨€æœç´¢æµç¨‹
"""
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from src.services.nl_search.config import nl_search_config
from src.services.nl_search.llm_processor import LLMProcessor
from src.services.nl_search.gpt5_search_adapter import GPT5SearchAdapter
from src.infrastructure.database.nl_search_repositories import NLSearchLogRepository
from src.core.domain.entities.nl_search import NLSearchLog

logger = logging.getLogger(__name__)


class NLSearchService:
    """
    è‡ªç„¶è¯­è¨€æœç´¢æ ¸å¿ƒæœåŠ¡

    èŒè´£:
    1. ç¼–æ’æ•´ä¸ªæœç´¢æµç¨‹
    2. è°ƒç”¨LLMè§£æç”¨æˆ·æŸ¥è¯¢
    3. è°ƒç”¨æœç´¢é€‚é…å™¨æ‰§è¡Œæœç´¢
    4. ä¿å­˜æœç´¢è®°å½•åˆ°æ•°æ®åº“
    5. è¿”å›å®Œæ•´çš„æœç´¢ç»“æœ

    ä½¿ç”¨ç¤ºä¾‹:
        service = NLSearchService()
        result = await service.create_search(
            query_text="æœ€è¿‘æœ‰å“ªäº›AIæŠ€æœ¯çªç ´",
            user_id="user_123"
        )
    """

    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.llm_processor = LLMProcessor()
        self.gpt5_adapter = GPT5SearchAdapter(
            test_mode=not nl_search_config.enabled  # åŠŸèƒ½å…³é—­æ—¶ä½¿ç”¨æµ‹è¯•æ¨¡å¼
        )
        self.repository = NLSearchLogRepository()

        logger.info("NLSearchService åˆå§‹åŒ–å®Œæˆ")

    async def create_search(
        self,
        query_text: str,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºè‡ªç„¶è¯­è¨€æœç´¢

        æµç¨‹:
        1. éªŒè¯è¾“å…¥
        2. åˆ›å»ºæœç´¢è®°å½•
        3. LLMè§£ææŸ¥è¯¢
        4. æ›´æ–°åˆ†æç»“æœ
        5. ç²¾ç‚¼æŸ¥è¯¢
        6. æ‰§è¡Œæœç´¢
        7. è¿”å›ç»“æœ

        Args:
            query_text: ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰

        Returns:
            åŒ…å«æœç´¢ç»“æœçš„å­—å…¸:
            {
                "log_id": int,
                "query_text": str,
                "analysis": dict,
                "refined_query": str,
                "results": list,
                "created_at": datetime
            }

        Raises:
            ValueError: è¾“å…¥éªŒè¯å¤±è´¥
            Exception: æœç´¢è¿‡ç¨‹ä¸­çš„å…¶ä»–é”™è¯¯
        """
        # 1. éªŒè¯è¾“å…¥
        if not query_text or not query_text.strip():
            raise ValueError("æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

        query_text = query_text.strip()
        logger.info(f"å¼€å§‹å¤„ç†è‡ªç„¶è¯­è¨€æœç´¢: {query_text[:50]}...")

        try:
            # 2. åˆ›å»ºæœç´¢è®°å½•
            log_id = await self.repository.create(
                query_text=query_text,
                llm_analysis=None
            )
            logger.info(f"åˆ›å»ºæœç´¢è®°å½•: log_id={log_id}")

            # 3. LLMè§£ææŸ¥è¯¢
            logger.info("è°ƒç”¨LLMè§£ææŸ¥è¯¢...")
            analysis = await self.llm_processor.parse_query(query_text)
            logger.info(f"LLMè§£æå®Œæˆ: intent={analysis.get('intent')}, "
                       f"keywords={analysis.get('keywords')}")

            # 4. æ›´æ–°åˆ†æç»“æœ
            await self.repository.update_llm_analysis(
                log_id=log_id,
                llm_analysis=analysis
            )
            logger.info("åˆ†æç»“æœå·²ä¿å­˜")

            # 5. ç²¾ç‚¼æŸ¥è¯¢
            refined_query = await self.llm_processor.refine_query(query_text)
            logger.info(f"ç²¾ç‚¼åçš„æŸ¥è¯¢: {refined_query}")

            # 6. æ‰§è¡Œæœç´¢
            logger.info("å¼€å§‹æ‰§è¡Œæœç´¢...")
            search_results = await self.gpt5_adapter.search(
                query=refined_query,
                max_results=nl_search_config.max_results_per_query
            )
            logger.info(f"æœç´¢å®Œæˆ: è·å¾—{len(search_results)}ä¸ªç»“æœ")

            # 7. æ„å»ºè¿”å›ç»“æœ
            result = {
                "log_id": log_id,
                "query_text": query_text,
                "analysis": analysis,
                "refined_query": refined_query,
                "results": [r.to_dict() for r in search_results],
                "created_at": datetime.now().isoformat()
            }

            logger.info(f"æœç´¢æµç¨‹å®Œæˆ: log_id={log_id}")
            return result

        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}", exc_info=True)
            # ä¸é‡æ–°æŠ›å‡ºï¼Œè®©APIå±‚å¤„ç†
            raise

    async def get_search_log(self, log_id: int) -> Optional[Dict[str, Any]]:
        """
        è·å–æœç´¢è®°å½•

        Args:
            log_id: æœç´¢è®°å½•ID

        Returns:
            æœç´¢è®°å½•å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        logger.info(f"è·å–æœç´¢è®°å½•: log_id={log_id}")

        try:
            log = await self.repository.get_by_id(log_id)

            if not log:
                logger.warning(f"æœç´¢è®°å½•ä¸å­˜åœ¨: log_id={log_id}")
                return None

            return {
                "log_id": log.id,
                "query_text": log.query_text,
                "analysis": log.llm_analysis,
                "created_at": log.created_at.isoformat() if log.created_at else None
            }

        except Exception as e:
            logger.error(f"è·å–æœç´¢è®°å½•å¤±è´¥: {e}", exc_info=True)
            raise

    async def list_search_logs(
        self,
        limit: int = 10,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæœç´¢å†å²

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            offset: åˆ†é¡µåç§»é‡

        Returns:
            æœç´¢è®°å½•åˆ—è¡¨
        """
        logger.info(f"æŸ¥è¯¢æœç´¢å†å²: limit={limit}, offset={offset}")

        try:
            logs = await self.repository.get_recent(limit=limit, offset=offset)

            results = [
                {
                    "log_id": log.id,
                    "query_text": log.query_text,
                    "analysis": log.llm_analysis,
                    "created_at": log.created_at.isoformat() if log.created_at else None
                }
                for log in logs
            ]

            logger.info(f"è¿”å›{len(results)}æ¡æœç´¢è®°å½•")
            return results

        except Exception as e:
            logger.error(f"æŸ¥è¯¢æœç´¢å†å²å¤±è´¥: {e}", exc_info=True)
            raise

    async def search_by_keyword(
        self,
        keyword: str,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        æ ¹æ®å…³é”®è¯æœç´¢å†å²è®°å½•

        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            åŒ¹é…çš„æœç´¢è®°å½•åˆ—è¡¨
        """
        logger.info(f"æ ¹æ®å…³é”®è¯æœç´¢: keyword={keyword}")

        try:
            logs = await self.repository.search_by_keyword(
                keyword=keyword,
                limit=limit
            )

            results = [
                {
                    "log_id": log.id,
                    "query_text": log.query_text,
                    "analysis": log.llm_analysis,
                    "created_at": log.created_at.isoformat() if log.created_at else None
                }
                for log in logs
            ]

            logger.info(f"æ‰¾åˆ°{len(results)}æ¡åŒ¹é…è®°å½•")
            return results

        except Exception as e:
            logger.error(f"å…³é”®è¯æœç´¢å¤±è´¥: {e}", exc_info=True)
            raise

    async def get_service_status(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡çŠ¶æ€

        Returns:
            æœåŠ¡çŠ¶æ€ä¿¡æ¯
        """
        return {
            "enabled": nl_search_config.enabled,
            "llm_configured": bool(self.llm_processor.llm_client),
            "search_configured": bool(self.gpt5_adapter.api_key or self.gpt5_adapter.test_mode),
            "test_mode": self.gpt5_adapter.test_mode,
            "version": "1.0.0-beta"
        }


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
nl_search_service = NLSearchService()
```

### 2.2 æ›´æ–°æœåŠ¡æ¨¡å—å¯¼å‡º

**æ–‡ä»¶**: `src/services/nl_search/__init__.py`

```python
"""
NL Search æœåŠ¡æ¨¡å—
"""
from src.services.nl_search.config import nl_search_config, NLSearchConfig
from src.services.nl_search.llm_processor import LLMProcessor
from src.services.nl_search.gpt5_search_adapter import GPT5SearchAdapter, SearchResult
from src.services.nl_search.nl_search_service import NLSearchService, nl_search_service

__all__ = [
    # é…ç½®
    "nl_search_config",
    "NLSearchConfig",

    # å¤„ç†å™¨
    "LLMProcessor",

    # é€‚é…å™¨
    "GPT5SearchAdapter",
    "SearchResult",

    # æœåŠ¡
    "NLSearchService",
    "nl_search_service",  # å…¨å±€å•ä¾‹
]
```

### 2.3 åˆ›å»ºæœåŠ¡æµ‹è¯•

**æ–‡ä»¶**: `tests/nl_search/test_nl_search_service.py`

```python
"""
NL Search æœåŠ¡æµ‹è¯•
"""
import pytest
from unittest.mock import AsyncMock, Mock, patch
from datetime import datetime

from src.services.nl_search.nl_search_service import NLSearchService
from src.services.nl_search.gpt5_search_adapter import SearchResult


class TestNLSearchService:
    """æµ‹è¯•NLæœç´¢æœåŠ¡"""

    @pytest.fixture
    def service(self):
        """åˆ›å»ºæœåŠ¡å®ä¾‹"""
        return NLSearchService()

    @pytest.mark.asyncio
    async def test_create_search_success(self, service):
        """æµ‹è¯•æˆåŠŸåˆ›å»ºæœç´¢"""
        query_text = "æœ€è¿‘æœ‰å“ªäº›AIæŠ€æœ¯çªç ´"

        # Mockæ‰€æœ‰ä¾èµ–
        with patch.object(service.repository, 'create', new_callable=AsyncMock) as mock_create, \
             patch.object(service.repository, 'update_llm_analysis', new_callable=AsyncMock) as mock_update, \
             patch.object(service.llm_processor, 'parse_query', new_callable=AsyncMock) as mock_parse, \
             patch.object(service.llm_processor, 'refine_query', new_callable=AsyncMock) as mock_refine, \
             patch.object(service.gpt5_adapter, 'search', new_callable=AsyncMock) as mock_search:

            # è®¾ç½®mockè¿”å›å€¼
            mock_create.return_value = 12345
            mock_parse.return_value = {
                "intent": "technology_news",
                "keywords": ["AI", "æŠ€æœ¯çªç ´"],
                "confidence": 0.95
            }
            mock_refine.return_value = "AIæŠ€æœ¯çªç ´ 2024"
            mock_search.return_value = [
                SearchResult(title="AIæ–°é—»", url="https://example.com/1", position=1, score=0.95)
            ]

            # æ‰§è¡Œæµ‹è¯•
            result = await service.create_search(query_text)

            # éªŒè¯ç»“æœ
            assert result["log_id"] == 12345
            assert result["query_text"] == query_text
            assert result["analysis"]["intent"] == "technology_news"
            assert len(result["results"]) == 1

            # éªŒè¯è°ƒç”¨
            mock_create.assert_called_once()
            mock_parse.assert_called_once_with(query_text)
            mock_update.assert_called_once()
            mock_refine.assert_called_once_with(query_text)
            mock_search.assert_called_once()

    @pytest.mark.asyncio
    async def test_create_search_empty_query(self, service):
        """æµ‹è¯•ç©ºæŸ¥è¯¢å¤„ç†"""
        with pytest.raises(ValueError, match="æŸ¥è¯¢æ–‡æœ¬ä¸èƒ½ä¸ºç©º"):
            await service.create_search("")

    @pytest.mark.asyncio
    async def test_create_search_llm_error(self, service):
        """æµ‹è¯•LLMé”™è¯¯å¤„ç†"""
        query_text = "æµ‹è¯•æŸ¥è¯¢"

        with patch.object(service.repository, 'create', new_callable=AsyncMock) as mock_create, \
             patch.object(service.llm_processor, 'parse_query', new_callable=AsyncMock) as mock_parse:

            mock_create.return_value = 12345
            mock_parse.side_effect = Exception("LLM APIé”™è¯¯")

            # éªŒè¯å¼‚å¸¸è¢«ä¼ æ’­
            with pytest.raises(Exception, match="LLM APIé”™è¯¯"):
                await service.create_search(query_text)

    @pytest.mark.asyncio
    async def test_get_search_log_success(self, service):
        """æµ‹è¯•è·å–æœç´¢è®°å½•"""
        log_id = 12345

        with patch.object(service.repository, 'get_by_id', new_callable=AsyncMock) as mock_get:
            # Mock NLSearchLogå¯¹è±¡
            mock_log = Mock()
            mock_log.id = log_id
            mock_log.query_text = "æµ‹è¯•æŸ¥è¯¢"
            mock_log.llm_analysis = {"intent": "test"}
            mock_log.created_at = datetime.now()

            mock_get.return_value = mock_log

            result = await service.get_search_log(log_id)

            assert result["log_id"] == log_id
            assert result["query_text"] == "æµ‹è¯•æŸ¥è¯¢"
            assert result["analysis"]["intent"] == "test"

    @pytest.mark.asyncio
    async def test_get_search_log_not_found(self, service):
        """æµ‹è¯•è®°å½•ä¸å­˜åœ¨"""
        with patch.object(service.repository, 'get_by_id', new_callable=AsyncMock) as mock_get:
            mock_get.return_value = None

            result = await service.get_search_log(99999)

            assert result is None

    @pytest.mark.asyncio
    async def test_list_search_logs(self, service):
        """æµ‹è¯•åˆ—å‡ºæœç´¢å†å²"""
        with patch.object(service.repository, 'get_recent', new_callable=AsyncMock) as mock_get:
            # Mockæ—¥å¿—åˆ—è¡¨
            mock_logs = [
                Mock(id=1, query_text="æŸ¥è¯¢1", llm_analysis={}, created_at=datetime.now()),
                Mock(id=2, query_text="æŸ¥è¯¢2", llm_analysis={}, created_at=datetime.now())
            ]
            mock_get.return_value = mock_logs

            result = await service.list_search_logs(limit=10, offset=0)

            assert len(result) == 2
            assert result[0]["log_id"] == 1
            assert result[1]["log_id"] == 2

    @pytest.mark.asyncio
    async def test_get_service_status(self, service):
        """æµ‹è¯•æœåŠ¡çŠ¶æ€"""
        status = await service.get_service_status()

        assert "enabled" in status
        assert "llm_configured" in status
        assert "search_configured" in status
        assert "test_mode" in status
        assert "version" in status
```

### 2.4 è¿è¡Œæµ‹è¯•

```bash
# è¿è¡ŒæœåŠ¡æµ‹è¯•
pytest tests/nl_search/test_nl_search_service.py -v

# è¿è¡Œæ‰€æœ‰NL Searchæµ‹è¯•
pytest tests/nl_search/ -v

# æŸ¥çœ‹è¦†ç›–ç‡
pytest tests/nl_search/ --cov=src/services/nl_search --cov-report=html
```

**æˆåŠŸæ ‡å‡†**:
- [x] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [x] æµ‹è¯•è¦†ç›–ç‡ >85%
- [x] æ— importé”™è¯¯

---

## ğŸ”Œ ä»»åŠ¡3: é›†æˆAPIç«¯ç‚¹

### 3.1 ä¿®æ”¹APIç«¯ç‚¹æ–‡ä»¶

**æ–‡ä»¶**: `src/api/v1/endpoints/nl_search.py`

**ä¸»è¦ä¿®æ”¹**:

```python
"""
è‡ªç„¶è¯­è¨€æœç´¢API (v1.0.0-beta)

**çŠ¶æ€**: ğŸš€ åŠŸèƒ½å®Œæ•´ï¼ˆåŠŸèƒ½å¼€å…³æ§åˆ¶ï¼‰
"""
from fastapi import APIRouter, HTTPException, Query, Depends
from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime
import logging

# å¯¼å…¥æœåŠ¡å±‚
from src.services.nl_search.nl_search_service import nl_search_service
from src.services.nl_search.config import nl_search_config

logger = logging.getLogger(__name__)

router = APIRouter()

# ==================== æ•°æ®æ¨¡å‹ ====================
# (ä¿æŒåŸæœ‰æ¨¡å‹å®šä¹‰ä¸å˜)
# ...

# ==================== APIç«¯ç‚¹ ====================

@router.get(
    "/status",
    response_model=NLSearchStatus,
    summary="åŠŸèƒ½çŠ¶æ€æ£€æŸ¥"
)
async def get_nl_search_status():
    """
    æ£€æŸ¥è‡ªç„¶è¯­è¨€æœç´¢åŠŸèƒ½çŠ¶æ€

    Returns:
        åŠŸèƒ½çŠ¶æ€ä¿¡æ¯å’Œé…ç½®
    """
    # è°ƒç”¨æœåŠ¡å±‚è·å–çŠ¶æ€
    service_status = await nl_search_service.get_service_status()

    return NLSearchStatus(
        enabled=service_status["enabled"],
        version=service_status["version"],
        message="è‡ªç„¶è¯­è¨€æœç´¢åŠŸèƒ½å·²å°±ç»ª" if service_status["enabled"]
                else "åŠŸèƒ½å·²å…³é—­ï¼Œè®¾ç½®NL_SEARCH_ENABLED=trueå¯ç”¨",
        alternative_api="/api/v1/smart-search" if not service_status["enabled"] else None,
        documentation="docs/NL_SEARCH_IMPLEMENTATION_GUIDE.md"
    )


@router.post(
    "/",
    response_model=NLSearchResponse,
    summary="åˆ›å»ºè‡ªç„¶è¯­è¨€æœç´¢"
)
async def create_nl_search(request: NLSearchRequest):
    """
    åˆ›å»ºè‡ªç„¶è¯­è¨€æœç´¢è¯·æ±‚

    **åŠŸèƒ½**: å®Œæ•´å®ç°

    æµç¨‹:
    1. æ£€æŸ¥åŠŸèƒ½å¼€å…³
    2. è°ƒç”¨æœåŠ¡å±‚å¤„ç†æœç´¢
    3. è¿”å›æœç´¢ç»“æœ

    Args:
        request: æœç´¢è¯·æ±‚å‚æ•°

    Returns:
        æœç´¢å“åº”ï¼ŒåŒ…å«åˆ†æç»“æœå’Œæœç´¢ç»“æœ

    Raises:
        HTTPException:
            - 503: åŠŸèƒ½æœªå¯ç”¨
            - 400: è¾“å…¥éªŒè¯å¤±è´¥
            - 500: å†…éƒ¨é”™è¯¯
    """
    # æ£€æŸ¥åŠŸèƒ½å¼€å…³
    if not nl_search_config.enabled:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "åŠŸèƒ½æœªå¯ç”¨",
                "message": "è‡ªç„¶è¯­è¨€æœç´¢åŠŸèƒ½å·²å…³é—­ã€‚è®¾ç½®ç¯å¢ƒå˜é‡ NL_SEARCH_ENABLED=true å¯ç”¨æ­¤åŠŸèƒ½ã€‚",
                "alternative_endpoint": "/api/v1/smart-search",
                "status": "disabled"
            }
        )

    try:
        # è°ƒç”¨æœåŠ¡å±‚
        logger.info(f"æ”¶åˆ°è‡ªç„¶è¯­è¨€æœç´¢è¯·æ±‚: {request.query_text[:50]}...")

        result = await nl_search_service.create_search(
            query_text=request.query_text,
            user_id=request.user_id
        )

        logger.info(f"æœç´¢æˆåŠŸ: log_id={result['log_id']}")

        return NLSearchResponse(
            log_id=result["log_id"],
            status="completed",
            message="æœç´¢æˆåŠŸ",
            results=result["results"],
            analysis=result["analysis"],
            refined_query=result["refined_query"]
        )

    except ValueError as e:
        # è¾“å…¥éªŒè¯é”™è¯¯
        logger.warning(f"è¾“å…¥éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(
            status_code=400,
            detail={
                "error": "è¾“å…¥éªŒè¯å¤±è´¥",
                "message": str(e)
            }
        )

    except Exception as e:
        # å†…éƒ¨é”™è¯¯
        logger.error(f"æœç´¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "æœç´¢å¤±è´¥",
                "message": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•",
                "log_id": None
            }
        )


@router.get(
    "/{log_id}",
    response_model=NLSearchLog,
    summary="è·å–æœç´¢è®°å½•"
)
async def get_nl_search_log(log_id: int):
    """
    è·å–è‡ªç„¶è¯­è¨€æœç´¢è®°å½•

    Args:
        log_id: æœç´¢è®°å½•ID

    Returns:
        æœç´¢è®°å½•è¯¦æƒ…

    Raises:
        HTTPException:
            - 404: è®°å½•ä¸å­˜åœ¨
            - 500: å†…éƒ¨é”™è¯¯
    """
    # æ£€æŸ¥åŠŸèƒ½å¼€å…³
    if not nl_search_config.enabled:
        raise HTTPException(status_code=503, detail="åŠŸèƒ½æœªå¯ç”¨")

    try:
        log = await nl_search_service.get_search_log(log_id)

        if not log:
            raise HTTPException(
                status_code=404,
                detail=f"æœç´¢è®°å½•ä¸å­˜åœ¨: log_id={log_id}"
            )

        return NLSearchLog(
            id=log["log_id"],
            query_text=log["query_text"],
            created_at=log["created_at"],
            status="completed",
            analysis=log.get("analysis")
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æœç´¢è®°å½•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="æœåŠ¡é”™è¯¯")


@router.get(
    "/",
    response_model=NLSearchListResponse,
    summary="æŸ¥è¯¢æœç´¢å†å²"
)
async def list_nl_search_logs(
    limit: int = Query(10, ge=1, le=100),
    offset: int = Query(0, ge=0),
    user_id: Optional[str] = Query(None)
):
    """
    æŸ¥è¯¢è‡ªç„¶è¯­è¨€æœç´¢å†å²

    Args:
        limit: è¿”å›æ•°é‡é™åˆ¶
        offset: åˆ†é¡µåç§»é‡
        user_id: ç”¨æˆ·IDè¿‡æ»¤ï¼ˆæš‚æœªå®ç°ï¼‰

    Returns:
        æœç´¢å†å²åˆ—è¡¨
    """
    # æ£€æŸ¥åŠŸèƒ½å¼€å…³
    if not nl_search_config.enabled:
        raise HTTPException(status_code=503, detail="åŠŸèƒ½æœªå¯ç”¨")

    try:
        logs = await nl_search_service.list_search_logs(
            limit=limit,
            offset=offset
        )

        items = [
            NLSearchLog(
                id=log["log_id"],
                query_text=log["query_text"],
                created_at=log["created_at"],
                status="completed",
                analysis=log.get("analysis")
            )
            for log in logs
        ]

        return NLSearchListResponse(
            total=len(items),  # TODO: æ·»åŠ æ€»æ•°æŸ¥è¯¢
            items=items,
            page=offset // limit + 1 if limit > 0 else 1,
            page_size=limit
        )

    except Exception as e:
        logger.error(f"æŸ¥è¯¢å†å²å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="æœåŠ¡é”™è¯¯")
```

### 3.2 æ›´æ–°å“åº”æ¨¡å‹

åœ¨`nl_search.py`ä¸­æ·»åŠ æ–°çš„å“åº”å­—æ®µï¼š

```python
class NLSearchResponse(BaseModel):
    """è‡ªç„¶è¯­è¨€æœç´¢å“åº”ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    log_id: Optional[int] = Field(None, description="æœç´¢è®°å½•ID")
    status: str = Field(..., description="æœç´¢çŠ¶æ€")
    message: str = Field(..., description="å“åº”æ¶ˆæ¯")
    results: Optional[List[Dict]] = Field(None, description="æœç´¢ç»“æœåˆ—è¡¨")
    analysis: Optional[Dict] = Field(None, description="LLMåˆ†æç»“æœ")
    refined_query: Optional[str] = Field(None, description="ç²¾ç‚¼åçš„æŸ¥è¯¢")
    alternative_api: Optional[str] = Field(None, description="æ›¿ä»£æ–¹æ¡ˆAPI")

class NLSearchLog(BaseModel):
    """è‡ªç„¶è¯­è¨€æœç´¢è®°å½•ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    id: int = Field(..., description="è®°å½•ID")
    query_text: str = Field(..., description="ç”¨æˆ·æŸ¥è¯¢")
    created_at: str = Field(..., description="åˆ›å»ºæ—¶é—´")
    status: str = Field(..., description="æœç´¢çŠ¶æ€")
    analysis: Optional[Dict] = Field(None, description="LLMåˆ†æç»“æœ")
```

### 3.3 æµ‹è¯•APIç«¯ç‚¹

```bash
# 1. å¯åŠ¨æœåŠ¡
uvicorn main:app --reload

# 2. æµ‹è¯•çŠ¶æ€ç«¯ç‚¹
curl -X GET "http://localhost:8000/api/v1/nl-search/status"

# 3. å¯ç”¨åŠŸèƒ½ï¼ˆåœ¨.envä¸­è®¾ç½®ï¼‰
echo "NL_SEARCH_ENABLED=true" >> .env

# 4. é‡å¯æœåŠ¡åæµ‹è¯•æœç´¢
curl -X POST "http://localhost:8000/api/v1/nl-search" \
  -H "Content-Type: application/json" \
  -d '{
    "query_text": "æœ€è¿‘æœ‰å“ªäº›AIæŠ€æœ¯çªç ´",
    "user_id": "test_user"
  }'

# 5. æµ‹è¯•è·å–è®°å½•ï¼ˆä½¿ç”¨è¿”å›çš„log_idï¼‰
curl -X GET "http://localhost:8000/api/v1/nl-search/1"

# 6. æµ‹è¯•å†å²åˆ—è¡¨
curl -X GET "http://localhost:8000/api/v1/nl-search?limit=10&offset=0"
```

**æˆåŠŸæ ‡å‡†**:
- [x] APIç«¯ç‚¹è¿”å›200çŠ¶æ€ç 
- [x] æ•°æ®æ ¼å¼æ­£ç¡®
- [x] é”™è¯¯å¤„ç†æ­£å¸¸
- [x] åŠŸèƒ½å¼€å…³ç”Ÿæ•ˆ

---

## ğŸ“ ä»»åŠ¡4: Gitæäº¤ä»£ç 

### 4.1 æŸ¥çœ‹æ–‡ä»¶çŠ¶æ€

```bash
# æŸ¥çœ‹æœªè·Ÿè¸ªæ–‡ä»¶
git status

# åº”è¯¥çœ‹åˆ°ä»¥ä¸‹æ–‡ä»¶
# æœªè·Ÿè¸ªæ–‡ä»¶:
#   claudedocs/NL_SEARCH_*
#   scripts/create_nl_search_tables.*
#   src/api/v1/endpoints/nl_search.py
#   src/core/domain/entities/nl_search/
#   src/infrastructure/database/nl_search_repositories.py
#   src/services/nl_search/
#   tests/nl_search/
#
# å·²ä¿®æ”¹æ–‡ä»¶:
#   src/api/v1/router.py
```

### 4.2 æ·»åŠ æ‰€æœ‰æ–‡ä»¶

```bash
# æ·»åŠ æ–°åˆ›å»ºçš„æ–‡ä»¶å’Œç›®å½•
git add src/core/domain/entities/nl_search/
git add src/services/nl_search/
git add src/infrastructure/database/nl_search_repositories.py
git add src/api/v1/endpoints/nl_search.py
git add tests/nl_search/
git add scripts/create_nl_search_tables.sql
git add scripts/create_nl_search_tables.py
git add claudedocs/NL_SEARCH_*.md

# æ·»åŠ ä¿®æ”¹çš„æ–‡ä»¶
git add src/api/v1/router.py
```

### 4.3 åˆ›å»ºCommit

```bash
git commit -m "feat: implement NL Search feature (Phase 1-5 MVP)

å®ç°è‡ªç„¶è¯­è¨€æœç´¢æ ¸å¿ƒåŠŸèƒ½ï¼š

**Phase 1: åŸºç¡€æ¶æ„** (100% âœ…)
- å®ä½“æ¨¡å‹: NLSearchLog, SearchStatusæšä¸¾
- ä»“åº“å±‚: NLSearchLogRepository (MariaDB)
- é…ç½®ç®¡ç†: NLSearchConfig with Pydantic
- æ•°æ®åº“è„šæœ¬: create_nl_search_tables.sql/py
- æµ‹è¯•: 25ä¸ªæµ‹è¯•ï¼Œ100%è¦†ç›–ç‡

**Phase 2: LLMå¤„ç†æœåŠ¡** (100% âœ…)
- LLMå¤„ç†å™¨: æŸ¥è¯¢è§£æå’Œç²¾ç‚¼
- Promptå·¥ç¨‹: 3ä¸ªPromptæ¨¡æ¿
- OpenAIé›†æˆ: å¼‚æ­¥APIè°ƒç”¨ï¼Œé‡è¯•æœºåˆ¶
- æµ‹è¯•: 32ä¸ªæµ‹è¯•ï¼Œ85%è¦†ç›–ç‡

**Phase 3: GPT5æœç´¢é›†æˆ** (100% âœ…)
- æœç´¢é€‚é…å™¨: GPT5SearchAdapter
- SerpAPIé›†æˆ: æ”¯æŒå¤šä¸ªæœç´¢å¼•æ“
- æ‰¹é‡æœç´¢: å¹¶å‘æœç´¢æ”¯æŒ
- æµ‹è¯•æ¨¡å¼: æ— éœ€API Keyçš„Mockæ•°æ®
- æµ‹è¯•: å®Œæ•´å•å…ƒæµ‹è¯•

**Phase 5: æœåŠ¡ç¼–æ’** (100% âœ…)
- æ ¸å¿ƒæœåŠ¡: NLSearchService
- æµç¨‹ç¼–æ’: LLM â†’ Search â†’ Repository
- é”™è¯¯å¤„ç†: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- æµ‹è¯•: å®Œæ•´å•å…ƒæµ‹è¯•ï¼ŒMockæ‰€æœ‰ä¾èµ–

**APIé›†æˆ** (100% âœ…)
- MVPç«¯ç‚¹: status, create, get, list
- åŠŸèƒ½å¼€å…³: NL_SEARCH_ENABLEDæ§åˆ¶
- è·¯ç”±æ³¨å†Œ: /api/v1/nl-search
- Swaggeræ–‡æ¡£: å®Œæ•´APIæ–‡æ¡£

**æµ‹è¯•è¦†ç›–**:
- å•å…ƒæµ‹è¯•: 65+ä¸ªæµ‹è¯•
- è¦†ç›–ç‡: 85%+
- æ‰€æœ‰æµ‹è¯•é€šè¿‡: âœ…

**åŠŸèƒ½ç‰¹æ€§**:
- å¼‚æ­¥æ¶æ„: å…¨å¼‚æ­¥IOæ“ä½œ
- é”™è¯¯å¤„ç†: Fallbackå’Œé‡è¯•æœºåˆ¶
- å®‰å…¨æ€§: ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿä¿¡æ¯
- å¯é…ç½®: Pydanticé…ç½®ç®¡ç†
- æµ‹è¯•å‹å¥½: æµ‹è¯•æ¨¡å¼æ”¯æŒ

**ä½¿ç”¨æ–¹å¼**:
\`\`\`bash
# 1. åˆ›å»ºæ•°æ®åº“è¡¨
python scripts/create_nl_search_tables.py

# 2. é…ç½®ç¯å¢ƒå˜é‡
export NL_SEARCH_ENABLED=true
export NL_SEARCH_LLM_API_KEY=your_openai_key
export NL_SEARCH_GPT5_SEARCH_API_KEY=your_search_key

# 3. å¯åŠ¨æœåŠ¡
uvicorn main:app --reload

# 4. æµ‹è¯•API
curl -X POST http://localhost:8000/api/v1/nl-search \\
  -H \"Content-Type: application/json\" \\
  -d '{\"query_text\": \"AIæŠ€æœ¯çªç ´\", \"user_id\": \"test\"}'
\`\`\`

**æ–‡æ¡£**:
- è®¾è®¡æ–‡æ¡£: docs/NL_SEARCH_MODULAR_DESIGN.md
- å®æ–½æŒ‡å—: docs/NL_SEARCH_IMPLEMENTATION_GUIDE.md
- Phase 1æŠ¥å‘Š: claudedocs/NL_SEARCH_PHASE1_COMPLETION.md
- Phase 2æŠ¥å‘Š: claudedocs/NL_SEARCH_PHASE2_COMPLETION.md
- ç»¼åˆåˆ†æ: claudedocs/NL_SEARCH_COMPREHENSIVE_ANALYSIS.md

**åç»­è®¡åˆ’**:
- Phase 4: Content Enricher (Firecrawlé›†æˆ)
- Phase 6-8: å‰ç«¯é›†æˆã€é›†æˆæµ‹è¯•ã€éƒ¨ç½²

ğŸ¤– Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>"
```

### 4.4 æ¨é€åˆ°è¿œç¨‹

```bash
# æ¨é€åˆ°å½“å‰åˆ†æ”¯
git push origin feature/summary-report-v2-cleanup
```

**æˆåŠŸæ ‡å‡†**:
- [x] Commitåˆ›å»ºæˆåŠŸ
- [x] æ¨é€åˆ°è¿œç¨‹æˆåŠŸ
- [x] æ‰€æœ‰æ–‡ä»¶å·²è·Ÿè¸ª

---

## âœ… ä»»åŠ¡5: ç«¯åˆ°ç«¯æµ‹è¯•

### 5.1 ç¼–å†™é›†æˆæµ‹è¯•

**æ–‡ä»¶**: `tests/nl_search/test_integration.py`

```python
"""
NL Search é›†æˆæµ‹è¯•
"""
import pytest
from httpx import AsyncClient
from main import app


@pytest.mark.asyncio
@pytest.mark.integration
class TestNLSearchIntegration:
    """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""

    async def test_status_endpoint(self):
        """æµ‹è¯•çŠ¶æ€ç«¯ç‚¹"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/api/v1/nl-search/status")

            assert response.status_code == 200
            data = response.json()
            assert "enabled" in data
            assert "version" in data

    @pytest.mark.skipif(
        not os.getenv("NL_SEARCH_ENABLED"),
        reason="åŠŸèƒ½æœªå¯ç”¨"
    )
    async def test_create_search_flow(self):
        """æµ‹è¯•å®Œæ•´æœç´¢æµç¨‹"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            # 1. åˆ›å»ºæœç´¢
            response = await client.post(
                "/api/v1/nl-search",
                json={
                    "query_text": "æœ€è¿‘æœ‰å“ªäº›AIæŠ€æœ¯çªç ´",
                    "user_id": "integration_test"
                }
            )

            assert response.status_code == 200
            data = response.json()

            assert "log_id" in data
            assert data["status"] == "completed"
            assert "results" in data
            assert "analysis" in data

            log_id = data["log_id"]

            # 2. è·å–æœç´¢è®°å½•
            response = await client.get(f"/api/v1/nl-search/{log_id}")
            assert response.status_code == 200

            # 3. åˆ—å‡ºå†å²
            response = await client.get("/api/v1/nl-search?limit=10")
            assert response.status_code == 200
```

### 5.2 æ‰‹åŠ¨æµ‹è¯•æµç¨‹

```bash
# 1. ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
python scripts/create_nl_search_tables.py

# 2. å¯ç”¨åŠŸèƒ½
export NL_SEARCH_ENABLED=true

# 3. é…ç½®API Keysï¼ˆå¯é€‰ï¼Œæœ‰æµ‹è¯•æ¨¡å¼ï¼‰
export NL_SEARCH_LLM_API_KEY=your_key
export NL_SEARCH_GPT5_SEARCH_API_KEY=your_key

# 4. å¯åŠ¨æœåŠ¡
uvicorn main:app --reload

# 5. æµ‹è¯•çŠ¶æ€
curl http://localhost:8000/api/v1/nl-search/status | jq

# 6. åˆ›å»ºæœç´¢
curl -X POST http://localhost:8000/api/v1/nl-search \
  -H "Content-Type: application/json" \
  -d '{"query_text": "æœ€è¿‘AIæŠ€æœ¯çªç ´", "user_id": "test"}' | jq

# 7. æŸ¥çœ‹æ•°æ®åº“
mysql -u root -p search_platform -e "
SELECT id, query_text, created_at,
       JSON_EXTRACT(llm_analysis, '$.intent') as intent,
       JSON_EXTRACT(llm_analysis, '$.keywords') as keywords
FROM nl_search_logs
ORDER BY created_at DESC
LIMIT 5;"
```

**æˆåŠŸæ ‡å‡†**:
- [x] APIè°ƒç”¨æˆåŠŸ
- [x] æ•°æ®æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“
- [x] LLMåˆ†æç»“æœæ­£ç¡®
- [x] æœç´¢ç»“æœè¿”å›æ­£å¸¸
- [x] æ—¥å¿—è®°å½•å®Œæ•´

---

## ğŸ“Š å®Œæˆåº¦æ£€æŸ¥

### MVPå®Œæˆæ ‡å‡†

å®Œæˆä»¥ä¸‹æ£€æŸ¥åï¼ŒåŠŸèƒ½å³è¾¾åˆ°MVPå¯ç”¨çŠ¶æ€ï¼š

#### åŸºç¡€è®¾æ–½
- [ ] æ•°æ®åº“è¡¨nl_search_logså·²åˆ›å»º
- [ ] è¡¨ç»“æ„åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
- [ ] ç´¢å¼•idx_createdå·²åˆ›å»º

#### ä»£ç å®ç°
- [ ] nl_search_service.pyå·²å®ç°
- [ ] æœåŠ¡æµ‹è¯•å·²é€šè¿‡
- [ ] APIç«¯ç‚¹å·²é›†æˆæœåŠ¡å±‚
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆ65+ä¸ªæµ‹è¯•ï¼‰

#### Gitç®¡ç†
- [ ] æ‰€æœ‰æ–‡ä»¶å·²æ·»åŠ åˆ°Git
- [ ] Commitæ¶ˆæ¯æ¸…æ™°å®Œæ•´
- [ ] å·²æ¨é€åˆ°è¿œç¨‹ä»“åº“

#### åŠŸèƒ½éªŒè¯
- [ ] çŠ¶æ€ç«¯ç‚¹æ­£å¸¸å·¥ä½œ
- [ ] åˆ›å»ºæœç´¢åŠŸèƒ½æ­£å¸¸
- [ ] è·å–è®°å½•åŠŸèƒ½æ­£å¸¸
- [ ] åˆ—è¡¨æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸
- [ ] åŠŸèƒ½å¼€å…³ç”Ÿæ•ˆ

#### è´¨é‡ä¿è¯
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ â‰¥85%
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] é”™è¯¯å¤„ç†å®Œå–„
- [ ] æ—¥å¿—è®°å½•å®Œæ•´

### å®Œæˆåº¦è‡ªæ£€

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
pytest tests/nl_search/ -v --cov=src --cov-report=term-missing

# æ£€æŸ¥ä»£ç è´¨é‡
flake8 src/services/nl_search/
pylint src/services/nl_search/

# éªŒè¯APIæ–‡æ¡£
curl http://localhost:8000/api/docs

# æ£€æŸ¥æ•°æ®åº“
mysql -u root -p -e "USE search_platform; SHOW TABLES LIKE 'nl_search%';"
```

---

## ğŸ¯ åç»­ä¼˜åŒ–è®¡åˆ’

å®ŒæˆMVPåï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹ä¼˜åŒ–ï¼š

### Phase 4: å†…å®¹å¯ŒåŒ– (1-2å¤©)
- å®ç°content_enricher.py
- é›†æˆFirecrawlæŠ“å–
- å†…å®¹è§£æå’Œæ¸…ç†

### æ€§èƒ½ä¼˜åŒ– (2-3å¤©)
- æ·»åŠ Redisç¼“å­˜å±‚
- å¼‚æ­¥åå°å¤„ç†
- æ‰¹é‡æ“ä½œä¼˜åŒ–

### ç›‘æ§å’Œå‘Šè­¦ (1-2å¤©)
- æ€§èƒ½æŒ‡æ ‡é‡‡é›†
- é”™è¯¯å‘Šè­¦é…ç½®
- Dashboardå±•ç¤º

### å®‰å…¨å¢å¼º (1-2å¤©)
- APIé™æµæœºåˆ¶
- å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
- å†…å®¹å®‰å…¨æ‰«æ

---

## ğŸ“ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q1: æ•°æ®åº“è¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥æ•°æ®åº“é…ç½®
grep DATABASE .env

# æµ‹è¯•è¿æ¥
mysql -u root -p search_platform -e "SELECT 1"
```

**Q2: Importé”™è¯¯**
```bash
# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
cd /Users/lanxionggao/Documents/guanshanPython

# æ£€æŸ¥Pythonè·¯å¾„
python -c "import sys; print(sys.path)"

# é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

**Q3: æµ‹è¯•å¤±è´¥**
```bash
# æ¸…ç†pytestç¼“å­˜
pytest --cache-clear

# é‡æ–°è¿è¡Œæµ‹è¯•
pytest tests/nl_search/ -v
```

**Q4: API Keyæœªé…ç½®**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
printenv | grep NL_SEARCH

# ä½¿ç”¨æµ‹è¯•æ¨¡å¼ï¼ˆæ— éœ€API Keyï¼‰
export NL_SEARCH_ENABLED=false  # æµ‹è¯•æ¨¡å¼è‡ªåŠ¨å¯ç”¨
```

---

## ğŸ“š ç›¸å…³èµ„æº

**æ–‡æ¡£**:
- [ç»¼åˆåˆ†ææŠ¥å‘Š](NL_SEARCH_COMPREHENSIVE_ANALYSIS.md)
- [æ¨¡å—åŒ–è®¾è®¡](../docs/NL_SEARCH_MODULAR_DESIGN.md)
- [å®æ–½æŒ‡å—](../docs/NL_SEARCH_IMPLEMENTATION_GUIDE.md)

**å®ŒæˆæŠ¥å‘Š**:
- [Phase 1å®ŒæˆæŠ¥å‘Š](NL_SEARCH_PHASE1_COMPLETION.md)
- [Phase 2å®ŒæˆæŠ¥å‘Š](NL_SEARCH_PHASE2_COMPLETION.md)

**APIæ–‡æ¡£**:
- http://localhost:8000/api/docs#/è‡ªç„¶è¯­è¨€æœç´¢

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å®Œæˆ
**æœ€åæ›´æ–°**: 2025-11-16
**ç»´æŠ¤è€…**: Backend Team

---

*ç«‹å³å¼€å§‹å®æ–½ï¼Œ3-4å°æ—¶å³å¯å®ŒæˆMVPï¼*
