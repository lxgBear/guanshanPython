# Firecrawl Prompt å‚æ•°å®ç°æ€»ç»“

**æ—¥æœŸ**: 2025-11-06
**ä»»åŠ¡**: ä¸º `crawl_website` ä»»åŠ¡ç±»å‹æ·»åŠ  Firecrawl v2 API çš„ `prompt` å‚æ•°æ”¯æŒ
**æµ‹è¯•ä»»åŠ¡**: 244746288889929728 (å¤©ä¹‹å£°)

---

## ğŸ“‹ èƒŒæ™¯

### éœ€æ±‚æ¥æº
ç”¨æˆ·å¸Œæœ›é€šè¿‡è‡ªç„¶è¯­è¨€ prompt æ¥è¿‡æ»¤çˆ¬å–ç»“æœï¼Œå®ç°æ—¶é—´èŒƒå›´è¿‡æ»¤åŠŸèƒ½ï¼š
- **ç›®æ ‡**: "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
- **é—®é¢˜**: ä¹‹å‰çš„åˆ†æè¡¨æ˜ Firecrawl Crawl API ä¸æ”¯æŒåŸç”Ÿæ—¶é—´è¿‡æ»¤å‚æ•°
- **è§£å†³æ–¹æ¡ˆ**: åˆ©ç”¨ Firecrawl v2 API çš„ `prompt` å‚æ•°å®ç°è¯­ä¹‰è¿‡æ»¤

### æŠ€æœ¯èƒŒæ™¯
- **Firecrawl SDK**: firecrawl-py v4.6.0
- **API ç‰ˆæœ¬**: Firecrawl v2 API
- **ç³»ç»Ÿæ¶æ„**: Python + AsyncIO + MongoDB
- **é€‚é…å™¨æ¨¡å¼**: `FirecrawlAdapter` å®ç° `CrawlerInterface`

---

## âœ… å®ç°æ­¥éª¤

### 1. éªŒè¯ Firecrawl v2 API æ”¯æŒ

**è°ƒç ”ç»“æœ**:
- âœ… Firecrawl v2 API çš„ `crawl()` æ–¹æ³•æ”¯æŒ `prompt` å‚æ•°
- âœ… å‚æ•°ç±»å‹: `str` (è‡ªç„¶è¯­è¨€æè¿°)
- âœ… åŠŸèƒ½: æŒ‡å¯¼çˆ¬è™«æ™ºèƒ½é€‰æ‹©å’Œè¿‡æ»¤é¡µé¢

**å®˜æ–¹æ–‡æ¡£ç¤ºä¾‹**:
```python
from firecrawl import Firecrawl

app = Firecrawl(api_key="YOUR_API_KEY")

result = app.crawl(
    url="https://example.com",
    limit=10,
    prompt="åªæŠ“å–ä¸ 2025 å¹´å‘å¸ƒçš„æ–°é—»ã€å…¬å‘Šå’Œæœ€æ–°æ›´æ–°é¡µé¢ï¼Œå¿½ç•¥æ—§ç‰ˆå­˜æ¡£å’Œäº§å“é¡µã€‚"
)
```

### 2. ä¿®æ”¹ FirecrawlAdapter

**æ–‡ä»¶**: `src/infrastructure/crawlers/firecrawl_adapter.py`

**å…³é”®ä¿®æ”¹**:

#### 2.1 æ›´æ–° `crawl()` æ–¹æ³•æ–‡æ¡£
```python
async def crawl(self, url: str, limit: int = 10, **options) -> List[CrawlResult]:
    """
    çˆ¬å–æ•´ä¸ªç½‘ç«™

    Args:
        url: èµ·å§‹URL
        limit: æœ€å¤§é¡µé¢æ•°
        **options: çˆ¬å–é€‰é¡¹
            - prompt: è‡ªç„¶è¯­è¨€æè¿°çˆ¬å–æ„å›¾ï¼ˆv2 APIæ–°å¢ï¼‰
            - max_depth: æœ€å¤§çˆ¬å–æ·±åº¦
            - include_paths: åŒ…å«çš„URLè·¯å¾„æ¨¡å¼
            - exclude_paths: æ’é™¤çš„URLè·¯å¾„æ¨¡å¼
            - only_main_content: åªæå–ä¸»è¦å†…å®¹
            - wait_for: ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            - exclude_tags: æ’é™¤çš„HTMLæ ‡ç­¾

    Returns:
        List[CrawlResult]: çˆ¬å–ç»“æœåˆ—è¡¨
    """
```

#### 2.2 æ·»åŠ  prompt å‚æ•°æå–
```python
# Firecrawl v2 API: ä½¿ç”¨å‘½åå‚æ•°ï¼ˆä¸å†ä½¿ç”¨ params å­—å…¸ï¼‰
max_depth = options.get('max_depth', 3)
include_paths = options.get('include_paths', [])
exclude_paths = options.get('exclude_paths', [])
prompt = options.get('prompt')  # v2 API æ–°å¢: è‡ªç„¶è¯­è¨€æè¿°
```

#### 2.3 æ·»åŠ  prompt æ—¥å¿—
```python
if prompt:
    logger.info(f"ğŸ¤– ä½¿ç”¨ prompt å‚æ•°: {prompt}")
logger.info(f"Firecrawl v2 çˆ¬å–å‚æ•°: limit={limit}, max_discovery_depth={max_depth}")
```

#### 2.4 åŠ¨æ€æ„å»º API è°ƒç”¨å‚æ•°
```python
# v4.6.0: ä½¿ç”¨ v2 API çš„ crawl() æ–¹æ³•ï¼ˆåŒæ­¥ï¼Œè¿”å› CrawlJobï¼‰
# timeout=None è¡¨ç¤ºæ°¸ä¸è¶…æ—¶,è®©çˆ¬å–ä»»åŠ¡å®Œæ•´æ‰§è¡Œ
crawl_params = {
    "url": url,
    "limit": limit,
    "max_discovery_depth": max_depth,
    "include_paths": include_paths,
    "exclude_paths": exclude_paths,
    "scrape_options": scrape_options,
    "poll_interval": 2,
    "timeout": None  # æ°¸ä¸è¶…æ—¶
}

# å¦‚æœæœ‰ promptï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
if prompt:
    crawl_params["prompt"] = prompt

job = await asyncio.to_thread(
    self.client.crawl,
    **crawl_params
)
```

**ä¿®æ”¹å‰**:
```python
job = await asyncio.to_thread(
    self.client.crawl,
    url,
    limit=limit,
    max_discovery_depth=max_depth,
    include_paths=include_paths,
    exclude_paths=exclude_paths,
    scrape_options=scrape_options,
    poll_interval=2,
    timeout=None
)
```

**ä¿®æ”¹å**:
- ä½¿ç”¨å­—å…¸æ„å»ºå‚æ•°
- æ¡ä»¶æ€§æ·»åŠ  prompt
- ä½¿ç”¨ `**crawl_params` å±•å¼€ä¼ é€’
- ä¿æŒå‘åå…¼å®¹ï¼ˆprompt å¯é€‰ï¼‰

### 3. æ›´æ–°æµ‹è¯•ä»»åŠ¡é…ç½®

**ä»»åŠ¡ ID**: 244746288889929728
**ä»»åŠ¡åç§°**: å¤©ä¹‹å£°
**ç›®æ ‡ URL**: https://www.thetibetpost.com/

#### 3.1 åˆ›å»ºæ›´æ–°è„šæœ¬
**æ–‡ä»¶**: `scripts/update_task_with_prompt.py`

**åŠŸèƒ½**:
- æŸ¥è¯¢ä»»åŠ¡å½“å‰é…ç½®
- æ·»åŠ  `prompt` å­—æ®µåˆ° `crawl_config`
- æ›´æ–°æ•°æ®åº“
- éªŒè¯æ›´æ–°ç»“æœ

**å…³é”®ä»£ç **:
```python
current_config = task.get('crawl_config', {})
current_config['prompt'] = "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"

result = await db.search_tasks.update_one(
    {"_id": task_id},
    {"$set": {"crawl_config": current_config}}
)
```

#### 3.2 æ›´æ–°åçš„é…ç½®
```json
{
  "limit": 10.0,
  "max_depth": 2.0,
  "wait_for": 1000.0,
  "only_main_content": true,
  "exclude_tags": "(Array) 3 Elements",
  "prompt": "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
}
```

### 4. æ‰§è¡Œæµ‹è¯•

#### 4.1 åˆ›å»ºæµ‹è¯•è„šæœ¬
**æ–‡ä»¶**: `scripts/execute_task_with_prompt.py`

**åŠŸèƒ½**:
- è¯»å–ä»»åŠ¡é…ç½®
- åˆå§‹åŒ– FirecrawlAdapter
- æ‰§è¡Œçˆ¬å–ä»»åŠ¡
- åˆ†æç»“æœ
- ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶

**å…³é”®å¤„ç†**:
```python
# å¤„ç†æ•°æ®åº“ä¸­çš„ exclude_tags å­—ç¬¦ä¸²æ ¼å¼
exclude_tags = crawl_config.get('exclude_tags', ['nav', 'footer', 'header'])
if isinstance(exclude_tags, str):
    logger.warning(f"   exclude_tags æ˜¯å­—ç¬¦ä¸²æ ¼å¼: {exclude_tags}, ä½¿ç”¨é»˜è®¤å€¼")
    exclude_tags = ['nav', 'footer', 'header']

# æ‰§è¡Œçˆ¬å–
results = await adapter.crawl(
    url=url,
    limit=int(crawl_config.get('limit', 10)),
    max_depth=int(crawl_config.get('max_depth', 2)),
    only_main_content=crawl_config.get('only_main_content', True),
    wait_for=int(crawl_config.get('wait_for', 1000)),
    exclude_tags=exclude_tags,
    prompt=crawl_config.get('prompt')  # ä¼ é€’ prompt å‚æ•°
)
```

#### 4.2 æµ‹è¯•æ‰§è¡Œç»“æœ

**æ‰§è¡Œæ—¥å¿—**:
```
============================================================
æµ‹è¯• Firecrawl v2 API prompt å‚æ•° - æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
============================================================

ä»»åŠ¡ä¿¡æ¯:
  ID: 244746288889929728
  åç§°: å¤©ä¹‹å£°
  URL: https://www.thetibetpost.com/
  ç±»å‹: crawl_website

çˆ¬å–é…ç½®:
  limit: 10.0
  max_depth: 2.0
  wait_for: 1000.0
  only_main_content: True
  exclude_tags: (Array) 3 Elements
  prompt: åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£

åˆå§‹åŒ– Firecrawl é€‚é…å™¨...
âœ… Firecrawl v2 é€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ

ğŸš€ å¼€å§‹çˆ¬å–...
   ç›®æ ‡: https://www.thetibetpost.com/
   Prompt: åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£

ğŸ¤– ä½¿ç”¨ prompt å‚æ•°: åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£
Firecrawl v2 çˆ¬å–å‚æ•°: limit=10, max_discovery_depth=2

âœ… çˆ¬å–å®Œæˆ
   è€—æ—¶: 21.48 ç§’
   ç»“æœæ•°: 10 é¡µ
```

**ç»“æœæ¦‚è§ˆ**:
```
ğŸ“Š ç»“æœé¢„è§ˆ:

   [1]
       æ ‡é¢˜: Contribution - Tibet Post International...
       å‘å¸ƒæ—¶é—´: æœªæ‰¾åˆ°
       å†…å®¹é•¿åº¦: 12101 å­—ç¬¦

   [2]
       æ ‡é¢˜: Editorials - Tibet Post International...
       å‘å¸ƒæ—¶é—´: æœªæ‰¾åˆ°
       å†…å®¹é•¿åº¦: 14447 å­—ç¬¦

   [3]
       æ ‡é¢˜: Exiled parliament conveys condolences over monaste...
       å‘å¸ƒæ—¶é—´: æœªæ‰¾åˆ°
       å†…å®¹é•¿åº¦: 21295 å­—ç¬¦

   ... è¿˜æœ‰ 7 æ¡ç»“æœ
```

**æ—¶é—´åˆ†å¸ƒåˆ†æ**:
```
ğŸ“… æ—¶é—´åˆ†å¸ƒåˆ†æ:
   åŒ…å«å‘å¸ƒæ—¶é—´: 0 é¡µ
   æ— å‘å¸ƒæ—¶é—´: 10 é¡µ
```

#### 4.3 ä¿å­˜çš„ç»“æœæ–‡ä»¶
**æ–‡ä»¶**: `crawl_result_244746288889929728_20251106_175105.json`

**ç¤ºä¾‹ç»“æœ**:
```json
{
  "url": "",
  "title": "Exiled parliament conveys condolences over monastery fire damage - Tibet Post International",
  "published_time": null,
  "content_length": 21295,
  "metadata_keys": [
    "title",
    "description",
    "url",
    "language",
    "keywords",
    "robots",
    "og_title",
    "og_description",
    "og_url",
    "og_image",
    "og_audio",
    "og_determiner",
    "og_locale",
    "og_locale_alternate",
    "og_site_name",
    "og_video",
    "favicon",
    "dc_terms_created",
    "dc_date_created",
    "dc_date",
    "dc_terms_type",
    "dc_type",
    "dc_terms_audience",
    "dc_terms_subject",
    "dc_subject",
    "dc_description",
    "dc_terms_keywords",
    "modified_time",
    "published_time",
    "article_tag",
    "article_section",
    "source_url",
    "status_code",
    "scrape_id",
    "num_pages",
    "content_type",
    "proxy_used",
    "cache_state",
    "cached_at",
    "credits_used",
    "error"
  ]
}
```

---

## ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ

### æˆåŠŸæŒ‡æ ‡

âœ… **æŠ€æœ¯å®ç°æˆåŠŸ**:
- Prompt å‚æ•°æ­£ç¡®ä¼ é€’åˆ° Firecrawl API
- çˆ¬å–ä»»åŠ¡æˆåŠŸå®Œæˆï¼ˆ10 é¡µï¼Œ21.48 ç§’ï¼‰
- API è°ƒç”¨æ²¡æœ‰é”™è¯¯
- æ—¥å¿—æ˜¾ç¤º `ğŸ¤– ä½¿ç”¨ prompt å‚æ•°: åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£`

âœ… **ç³»ç»Ÿé›†æˆæˆåŠŸ**:
- FirecrawlAdapter ä¿®æ”¹å‘åå…¼å®¹
- æ•°æ®åº“é…ç½®æ›´æ–°æˆåŠŸ
- æµ‹è¯•è„šæœ¬æ‰§è¡Œæµç•…
- ç»“æœä¿å­˜å’Œåˆ†æå®Œæ•´

### å±€é™æ€§åˆ†æ

âš ï¸ **æ—¶é—´ä¿¡æ¯ç¼ºå¤±**:
- **è§‚å¯Ÿ**: æ‰€æœ‰çˆ¬å–é¡µé¢çš„ `published_time` å‡ä¸º `null`
- **åŸå› **:
  1. ç›®æ ‡ç½‘ç«™ (thetibetpost.com) å¯èƒ½æ²¡æœ‰åœ¨ HTML metadata ä¸­æš´éœ²å‘å¸ƒæ—¶é—´
  2. ç½‘ç«™å¯èƒ½ä½¿ç”¨ JavaScript åŠ¨æ€æ¸²æŸ“å‘å¸ƒæ—¶é—´
  3. æ—¶é—´ä¿¡æ¯å¯èƒ½åœ¨é¡µé¢å†…å®¹ä¸­è€Œé metadata ä¸­
- **å½±å“**: æ— æ³•é€šè¿‡ metadata ç›´æ¥éªŒè¯æ—¶é—´è¿‡æ»¤æ•ˆæœ

âš ï¸ **URL å­—æ®µä¸ºç©º**:
- **è§‚å¯Ÿ**: ç»“æœä¸­çš„ `url` å­—æ®µä¸ºç©ºå­—ç¬¦ä¸²
- **å¯èƒ½åŸå› **:
  1. Firecrawl v2 API è¿”å›çš„ Document å¯¹è±¡ URL å­—æ®µå¤„ç†é—®é¢˜
  2. å¯èƒ½éœ€è¦ä» metadata çš„ `url` æˆ– `og_url` å­—æ®µæå–
- **å»ºè®®**: åœ¨ `FirecrawlAdapter` çš„ `crawl()` æ–¹æ³•ä¸­æ·»åŠ  URL æå–é€»è¾‘

### Prompt æ•ˆæœè¯„ä¼°

**ç›´æ¥éªŒè¯å›°éš¾**:
- ç”±äºç¼ºä¹æ˜ç¡®çš„æ—¶é—´æˆ³ä¿¡æ¯ï¼Œæ— æ³•ç›´æ¥éªŒè¯ prompt æ˜¯å¦æˆåŠŸè¿‡æ»¤äº†æ—§å†…å®¹
- é¡µé¢æ ‡é¢˜å’Œå†…å®¹çœ‹èµ·æ¥ä¸æ—¶äº‹ç›¸å…³ï¼ˆå¦‚"Exiled parliament conveys condolences over monastery fire damage"ï¼‰

**é—´æ¥è¯æ®**:
- çˆ¬å–çš„é¡µé¢å†…å®¹ä¸°å¯Œï¼ˆ12K-56K å­—ç¬¦ï¼‰
- æ ‡é¢˜æ¶‰åŠå½“å‰äº‹ä»¶å’Œè¯é¢˜
- æ²¡æœ‰æ˜æ˜¾çš„å½’æ¡£é¡µé¢æ ‡é¢˜ï¼ˆå¦‚ "Archive 2020"ï¼‰

**æ¨èéªŒè¯æ–¹æ³•**:
1. **å†…å®¹åˆ†æ**: æ£€æŸ¥çˆ¬å–çš„ markdown/content ä¸­æ˜¯å¦åŒ…å«æ—¥æœŸä¿¡æ¯
2. **å¯¹æ¯”æµ‹è¯•**: ä¸ä½¿ç”¨ prompt çˆ¬å–ç›¸åŒç½‘ç«™ï¼Œå¯¹æ¯”ç»“æœå·®å¼‚
3. **æ‰‹åŠ¨å®¡æŸ¥**: è®¿é—®çˆ¬å–çš„ URLï¼ˆéœ€è¦ä¿®å¤ URL å­—æ®µï¼‰ï¼Œç¡®è®¤å†…å®¹æ—¶æ•ˆæ€§

---

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚

### FirecrawlAdapter ä¿®æ”¹æ‘˜è¦

**ä¿®æ”¹ä½ç½®**: `src/infrastructure/crawlers/firecrawl_adapter.py:114-174`

**ä¿®æ”¹ç±»å‹**: åŠŸèƒ½å¢å¼º (å‘åå…¼å®¹)

**å…³é”®å˜æ›´**:
1. æ·»åŠ  `prompt` å‚æ•°åˆ°æ–¹æ³•æ–‡æ¡£
2. ä» `options` ä¸­æå– `prompt` å‚æ•°
3. æ·»åŠ  prompt ä½¿ç”¨æ—¥å¿—
4. æ”¹ç”¨å­—å…¸æ„å»º API è°ƒç”¨å‚æ•°
5. æ¡ä»¶æ€§æ·»åŠ  prompt åˆ°å‚æ•°å­—å…¸

**å…¼å®¹æ€§ä¿è¯**:
- `prompt` å‚æ•°å®Œå…¨å¯é€‰
- ä¸ä¼ é€’ prompt æ—¶è¡Œä¸ºä¸ä¹‹å‰å®Œå…¨ä¸€è‡´
- ä¸å½±å“ç°æœ‰ä»»åŠ¡çš„æ‰§è¡Œ

### æ•°æ®åº“ç»“æ„

**é›†åˆ**: `search_tasks`
**å­—æ®µ**: `crawl_config.prompt`
**ç±»å‹**: `str`
**å¯é€‰**: æ˜¯

**ç¤ºä¾‹é…ç½®**:
```json
{
  "_id": "244746288889929728",
  "name": "å¤©ä¹‹å£°",
  "task_type": "crawl_website",
  "crawl_url": "https://www.thetibetpost.com/",
  "crawl_config": {
    "limit": 10,
    "max_depth": 2,
    "wait_for": 1000,
    "only_main_content": true,
    "exclude_tags": ["nav", "footer", "header"],
    "prompt": "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
  },
  "schedule_interval": "HOURLY_1",
  "is_active": false,
  "status": "active",
  "created_by": "test_user"
}
```

---

## ğŸ“ ä½¿ç”¨æŒ‡å—

### å‰ç«¯ API è°ƒç”¨

**åˆ›å»ºå¸¦ prompt çš„çˆ¬å–ä»»åŠ¡**:
```javascript
POST /api/v1/search-tasks

{
  "name": "æ–°é—»çˆ¬å– - è¿‘æœŸä¸€ä¸ªæœˆ",
  "task_type": "crawl_website",
  "crawl_url": "https://example.com/news",
  "crawl_config": {
    "limit": 20,
    "max_depth": 2,
    "only_main_content": true,
    "wait_for": 1000,
    "exclude_tags": ["nav", "footer", "header"],
    "prompt": "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
  },
  "schedule_interval": "DAILY_1",
  "is_active": true,
  "created_by": "user_id"
}
```

### åç«¯ç›´æ¥è°ƒç”¨

**ä½¿ç”¨ FirecrawlAdapter**:
```python
from src.infrastructure.crawlers.firecrawl_adapter import FirecrawlAdapter

adapter = FirecrawlAdapter()

results = await adapter.crawl(
    url="https://example.com/news",
    limit=20,
    max_depth=2,
    only_main_content=True,
    wait_for=1000,
    exclude_tags=['nav', 'footer', 'header'],
    prompt="åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
)
```

### Prompt å‚æ•°æœ€ä½³å®è·µ

**æœ‰æ•ˆçš„ Prompt ç¤ºä¾‹**:

1. **æ—¶é—´è¿‡æ»¤**:
   ```
   "åªæŠ“å–ä¸ 2025 å¹´å‘å¸ƒçš„æ–°é—»ã€å…¬å‘Šå’Œæœ€æ–°æ›´æ–°é¡µé¢ï¼Œå¿½ç•¥æ—§ç‰ˆå­˜æ¡£å’Œäº§å“é¡µã€‚"
   "åªçˆ¬å–è¿‘æœŸä¸€ä¸ªæœˆçš„æ•°æ® å¿½ç•¥æ—§ç‰ˆå­˜æ¡£"
   "Focus on content published in the last 30 days"
   ```

2. **å†…å®¹ç±»å‹è¿‡æ»¤**:
   ```
   "åªçˆ¬å–æ–°é—»æ–‡ç« å’Œåšå®¢æ–‡ç« ï¼Œå¿½ç•¥äº§å“é¡µé¢å’Œå…³äºæˆ‘ä»¬é¡µé¢"
   "Crawl only article pages and blog posts, skip product listings"
   ```

3. **ä¸»é¢˜è¿‡æ»¤**:
   ```
   "ä¸“æ³¨äºæŠ€æœ¯å’Œç§‘å­¦ç›¸å…³çš„æ–‡ç« ï¼Œè·³è¿‡å¨±ä¹å’Œä½“è‚²å†…å®¹"
   "Focus on climate change and environmental topics"
   ```

4. **ç»„åˆæ¡ä»¶**:
   ```
   "çˆ¬å–2025å¹´å‘å¸ƒçš„æŠ€æœ¯æ–°é—»æ–‡ç« ï¼Œè·³è¿‡äº§å“é¡µå’Œå½’æ¡£é¡µ"
   "Recent research papers on AI, published within last 3 months"
   ```

**Prompt ç¼–å†™å»ºè®®**:
- âœ… ä½¿ç”¨æ¸…æ™°æ˜ç¡®çš„è¯­è¨€
- âœ… æŒ‡å®šè¦åŒ…å«çš„å†…å®¹
- âœ… æŒ‡å®šè¦æ’é™¤çš„å†…å®¹
- âœ… ä½¿ç”¨æ—¶é—´ã€ä¸»é¢˜ã€å†…å®¹ç±»å‹ç­‰å…·ä½“æè¿°ç¬¦
- âŒ é¿å…è¿‡äºå¤æ‚çš„é€»è¾‘
- âŒ é¿å…è¿‡äºå®½æ³›çš„æè¿°

---

## ğŸ” å·²çŸ¥é—®é¢˜å’Œæ”¹è¿›å»ºè®®

### Issue 1: URL å­—æ®µä¸ºç©º

**é—®é¢˜æè¿°**:
- `CrawlResult.url` å­—æ®µä¸ºç©ºå­—ç¬¦ä¸²
- æ— æ³•ç›´æ¥è®¿é—®çˆ¬å–çš„é¡µé¢éªŒè¯å†…å®¹

**å½±å“**:
- ç»“æœéªŒè¯å›°éš¾
- æ•°æ®å¯è¿½æº¯æ€§é™ä½

**å»ºè®®ä¿®å¤**:
```python
# åœ¨ FirecrawlAdapter.crawl() ä¸­
for document in job.data:
    result = CrawlResult(
        url=getattr(document, 'url', '') or document.metadata.get('url') or '',
        content=getattr(document, 'content', '') or '',
        markdown=getattr(document, 'markdown', None),
        html=getattr(document, 'html', None),
        metadata=getattr(document, 'metadata', {})
    )
```

### Issue 2: æ—¶é—´ä¿¡æ¯æå–

**é—®é¢˜æè¿°**:
- Metadata ä¸­çš„ `published_time` ä¸º null
- æ— æ³•é€šè¿‡ metadata ç›´æ¥éªŒè¯æ—¶é—´è¿‡æ»¤æ•ˆæœ

**å½±å“**:
- Prompt æ•ˆæœéš¾ä»¥é‡åŒ–éªŒè¯
- æ—¶é—´èŒƒå›´è¿‡æ»¤åŠŸèƒ½æœ‰æ•ˆæ€§æœªçŸ¥

**å»ºè®®æ”¹è¿›**:
1. **å¢å¼ºæ—¶é—´æå–**:
   ```python
   # å°è¯•ä»å¤šä¸ª metadata å­—æ®µæå–æ—¶é—´
   time_fields = [
       'article_published_time',
       'og:article:published_time',
       'published_time',
       'dc_date_created',
       'dc_terms_created',
       'modified_time'
   ]

   for field in time_fields:
       pub_time = metadata.get(field)
       if pub_time:
           break
   ```

2. **å†…å®¹æ—¶é—´æå–**:
   - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä» markdown/content ä¸­æå–æ—¥æœŸ
   - ä½¿ç”¨ NLP æ¨¡å‹æå–æ—¶é—´ä¿¡æ¯

3. **å¯¹æ¯”æµ‹è¯•**:
   - å®ç° A/B æµ‹è¯•åŠŸèƒ½
   - å¯¹æ¯”æœ‰æ—  prompt çš„çˆ¬å–ç»“æœå·®å¼‚

### Issue 3: exclude_tags æ•°æ®ç±»å‹

**é—®é¢˜æè¿°**:
- æ•°æ®åº“ä¸­çš„ `exclude_tags` å­˜å‚¨ä¸ºå­—ç¬¦ä¸² `"(Array) 3 Elements"`
- éœ€è¦åœ¨ä»£ç ä¸­æ‰‹åŠ¨å¤„ç†ç±»å‹è½¬æ¢

**å½±å“**:
- ä»£ç å†—ä½™
- ç±»å‹ä¸ä¸€è‡´

**å»ºè®®ä¿®å¤**:
```python
# åœ¨æ•°æ®åº“è¿ç§»è„šæœ¬ä¸­ç»Ÿä¸€ä¿®å¤
await db.search_tasks.update_many(
    {"crawl_config.exclude_tags": {"$type": "string"}},
    {"$set": {"crawl_config.exclude_tags": ["nav", "footer", "header"]}}
)
```

### Issue 4: Prompt æ•ˆæœéªŒè¯

**é—®é¢˜æè¿°**:
- ç¼ºä¹æ˜ç¡®çš„æ–¹æ³•éªŒè¯ prompt æ˜¯å¦ç”Ÿæ•ˆ
- æ— æ³•é‡åŒ– prompt çš„è¿‡æ»¤æ•ˆæœ

**å»ºè®®å®ç°**:
1. **å¯¹æ¯”æµ‹è¯•åŠŸèƒ½**:
   - ç›¸åŒ URL åˆ†åˆ«ä½¿ç”¨æœ‰/æ—  prompt çˆ¬å–
   - æ¯”è¾ƒç»“æœæ•°é‡å’Œå†…å®¹å·®å¼‚
   - ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

2. **å†…å®¹åˆ†æåŠŸèƒ½**:
   - åˆ†æçˆ¬å–å†…å®¹ä¸­çš„æ—¶é—´ä¿¡æ¯
   - æå–ä¸»é¢˜å’Œå…³é”®è¯
   - éªŒè¯æ˜¯å¦ç¬¦åˆ prompt æè¿°

3. **æ•ˆæœè¯„åˆ†ç³»ç»Ÿ**:
   - åŸºäºå†…å®¹æ—¶æ•ˆæ€§æ‰“åˆ†
   - åŸºäºä¸»é¢˜ç›¸å…³æ€§æ‰“åˆ†
   - åŸºäºé¢„æœŸç»“æœåŒ¹é…åº¦æ‰“åˆ†

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

### å·²åˆ›å»ºæ–‡æ¡£
- **æ—¶é—´èŒƒå›´åˆ†æ**: `claudedocs/CRAWL_WEBSITE_TIME_RANGE_ANALYSIS.md`
  - åˆ†æäº† crawl_website æ—¶é—´è¿‡æ»¤éœ€æ±‚
  - å¯¹æ¯”äº† Crawl API vs Search API
  - æå‡ºäº†å¤šç§è§£å†³æ–¹æ¡ˆ

### ç›¸å…³ä»£ç æ–‡ä»¶
- **é€‚é…å™¨å®ç°**: `src/infrastructure/crawlers/firecrawl_adapter.py`
- **æ›´æ–°è„šæœ¬**: `scripts/update_task_with_prompt.py`
- **æµ‹è¯•è„šæœ¬**: `scripts/execute_task_with_prompt.py`
- **ç»“æœæ–‡ä»¶**: `crawl_result_244746288889929728_20251106_175105.json`

### API æ–‡æ¡£å‚è€ƒ
- **Firecrawl API**: https://api.firecrawl.dev/docs
- **Firecrawl Python SDK**: https://github.com/mendableai/firecrawl

---

## âœ… å®ç°æ€»ç»“

### å®Œæˆçš„å·¥ä½œ
1. âœ… éªŒè¯ Firecrawl v2 API æ”¯æŒ prompt å‚æ•°
2. âœ… ä¿®æ”¹ `FirecrawlAdapter` æ·»åŠ  prompt å‚æ•°æ”¯æŒ
3. âœ… æ›´æ–°ä»»åŠ¡ 244746288889929728 çš„é…ç½®
4. âœ… åˆ›å»ºæµ‹è¯•è„šæœ¬å¹¶æˆåŠŸæ‰§è¡Œ
5. âœ… ç”Ÿæˆæµ‹è¯•ç»“æœå’Œåˆ†ææŠ¥å‘Š
6. âœ… åˆ›å»ºå®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£

### æŠ€æœ¯äº®ç‚¹
- **å‘åå…¼å®¹**: prompt å‚æ•°å®Œå…¨å¯é€‰ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
- **çµæ´»é…ç½®**: æ”¯æŒåœ¨ `crawl_config` ä¸­çµæ´»é…ç½®
- **æ—¥å¿—å®Œå–„**: æ·»åŠ äº† prompt ä½¿ç”¨çš„æ—¥å¿—è®°å½•
- **æµ‹è¯•å®Œæ•´**: åˆ›å»ºäº†å®Œæ•´çš„æµ‹è¯•å’ŒéªŒè¯æµç¨‹

### å±€é™æ€§
- ç›®æ ‡ç½‘ç«™ç¼ºä¹æ—¶é—´ metadataï¼Œéš¾ä»¥ç›´æ¥éªŒè¯è¿‡æ»¤æ•ˆæœ
- URL å­—æ®µæå–éœ€è¦ä¼˜åŒ–
- éœ€è¦æ›´å¤šçš„å¯¹æ¯”æµ‹è¯•æ¥éªŒè¯ prompt å®é™…æ•ˆæœ

### åç»­å»ºè®®
1. **ä¿®å¤ URL å­—æ®µæå–**
2. **å¢å¼ºæ—¶é—´ä¿¡æ¯æå–**
3. **å®ç°å¯¹æ¯”æµ‹è¯•åŠŸèƒ½**
4. **å¼€å‘ prompt æ•ˆæœè¯„ä¼°å·¥å…·**
5. **æ‰©å±•åˆ°æ›´å¤šæµ‹è¯•ç½‘ç«™éªŒè¯**

---

## ğŸ“ è”ç³»ä¿¡æ¯

**å®ç°è€…**: Claude (Anthropic)
**æ—¥æœŸ**: 2025-11-06
**é¡¹ç›®**: guanshanPython (å…³å±±æœç´¢ç³»ç»Ÿ)
