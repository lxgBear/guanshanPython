# Firecrawl ç½‘å€çˆ¬å–ä¼˜åŒ–æ€»ç»“

## ğŸ“‹ å®æ–½æ—¥æœŸ
2025-11-04

## ğŸ¯ é—®é¢˜æè¿°

ç”¨æˆ·æŠ¥å‘Š Firecrawl API ç½‘å€çˆ¬å–è¿”å›çš„å†…å®¹ç¼ºå°‘å¾ˆå¤šï¼Œç»è¿‡åˆ†æå‘ç°ï¼š

### åŸå§‹é—®é¢˜

1. **å†…å®¹åŒ…å«å¤§é‡éä¸»è¦å†…å®¹** - Markdown å¼€å¤´å…¨æ˜¯ Sidebarã€Magazine menu ç­‰å¯¼èˆªå…ƒç´ 
2. **HTML å†…å®¹ä¸ºç©º** - API åªè¿”å› markdownï¼Œæœªè¿”å› HTML
3. **çˆ¬å–å‚æ•°æœªç”Ÿæ•ˆ** - `firecrawl_adapter.py` å®Œå…¨å¿½ç•¥äº†ä¼ é€’çš„ `options` å‚æ•°

### å…·ä½“è¡¨ç°

```markdown
## Sidebar

Ã—

- [Magazine](https://www.thetibetpost.com/)
- [Events](https://www.thetibetpost.com/events)
...
### Magazine menu
...
```

**å†…å®¹ç»Ÿè®¡**ï¼ˆä¼˜åŒ–å‰ï¼‰ï¼š
- Markdown: 113,997 å­—ç¬¦
- HTML: 0 å­—ç¬¦
- åŒ…å« Sidebar: **æ˜¯** âš ï¸
- åŒ…å« Magazine menu: **æ˜¯** âš ï¸

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### ä»£ç é—®é¢˜

**æ–‡ä»¶**: `src/infrastructure/crawlers/firecrawl_adapter.py:66-68`

```python
# âŒ åŸå§‹ä»£ç ï¼ˆæœ‰é—®é¢˜ï¼‰
params = {
    'formats': ['markdown', 'html']
}
# å®Œå…¨å¿½ç•¥äº† **options å‚æ•°ï¼
```

**æ–‡ä»¶**: `src/services/task_scheduler.py:409-413`

```python
# ä¼ é€’äº†é€‰é¡¹ï¼Œä½† firecrawl_adapter æœªä½¿ç”¨
scrape_options = {
    "wait_for": task.search_config.get("wait_for", 1000),
    "include_tags": task.search_config.get("include_tags"),
    "exclude_tags": task.search_config.get("exclude_tags", ["nav", "footer", "header"])
}
```

### Firecrawl API å‚æ•°ç¼ºå¤±

ç¼ºå°‘å…³é”®å‚æ•°ï¼š
1. **`onlyMainContent`** - æ§åˆ¶æ˜¯å¦åªæå–ä¸»è¦å†…å®¹
2. **`waitFor`** - ç­‰å¾…é¡µé¢åŠ è½½æ—¶é—´
3. **`excludeTags`** - æ’é™¤æŒ‡å®š HTML æ ‡ç­¾
4. **`timeout`** - è¶…æ—¶æ§åˆ¶

## âœ… è§£å†³æ–¹æ¡ˆ

### 1. ä¿®å¤ `firecrawl_adapter.py`

**ä½ç½®**: `src/infrastructure/crawlers/firecrawl_adapter.py:51-93`

**å…³é”®æ”¹è¿›**ï¼š

```python
async def scrape(self, url: str, **options) -> CrawlResult:
    """çˆ¬å–å•ä¸ªé¡µé¢

    Args:
        url: ç›®æ ‡URL
        **options: çˆ¬å–é€‰é¡¹
            - only_main_content: åªæå–ä¸»è¦å†…å®¹ï¼Œé»˜è®¤ True
            - wait_for: ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤ 1000
            - include_tags: è¦åŒ…å«çš„ HTML æ ‡ç­¾åˆ—è¡¨
            - exclude_tags: è¦æ’é™¤çš„ HTML æ ‡ç­¾åˆ—è¡¨
            - timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    """
    # æ„å»ºFirecrawlå‚æ•°
    params = {
        'formats': ['markdown', 'html'],
        'onlyMainContent': options.get('only_main_content', True),  # âœ… æ–°å¢
        'waitFor': options.get('wait_for', 1000),  # âœ… æ–°å¢
    }

    # æ·»åŠ æ ‡ç­¾è¿‡æ»¤é€‰é¡¹
    if 'include_tags' in options and options['include_tags']:
        params['includeTags'] = options['include_tags']

    if 'exclude_tags' in options and options['exclude_tags']:
        params['excludeTags'] = options['exclude_tags']  # âœ… æ–°å¢

    # è®¾ç½®è¶…æ—¶æ—¶é—´
    timeout = options.get('timeout', self.timeout)  # âœ… æ–°å¢

    logger.info(f"çˆ¬å–å‚æ•°: onlyMainContent={params['onlyMainContent']}, waitFor={params['waitFor']}ms, excludeTags={params.get('excludeTags', 'None')}")
```

### 2. ä¼˜åŒ– `task_scheduler.py` é…ç½®

**ä½ç½®**: `src/services/task_scheduler.py:409-415`

**æ”¹è¿›**ï¼š

```python
scrape_options = {
    "only_main_content": task.search_config.get("only_main_content", True),  # âœ… åªæå–ä¸»è¦å†…å®¹
    "wait_for": task.search_config.get("wait_for", 2000),  # âœ… å¢åŠ ç­‰å¾…æ—¶é—´
    "include_tags": task.search_config.get("include_tags"),
    "exclude_tags": task.search_config.get("exclude_tags", ["nav", "footer", "header", "aside", "sidebar"]),  # âœ… æ’é™¤æ›´å¤šéä¸»è¦å†…å®¹
    "timeout": task.search_config.get("timeout", 30)  # âœ… è®¾ç½®åˆç†è¶…æ—¶
}
```

## ğŸ“Š ä¼˜åŒ–æ•ˆæœ

### æµ‹è¯•æ‰§è¡Œ

```bash
âœ… çˆ¬å–å‚æ•°å·²æ­£ç¡®ä¼ é€’:
   onlyMainContent=True
   waitFor=2000ms
   excludeTags=['nav', 'footer', 'header', 'aside', 'sidebar']
```

### é¢„æœŸæ•ˆæœ

æ ¹æ® Firecrawl API æ–‡æ¡£ï¼Œ`onlyMainContent=True` åº”è¯¥ï¼š
1. âœ… è‡ªåŠ¨è¯†åˆ«å¹¶æå–é¡µé¢ä¸»è¦å†…å®¹
2. âœ… æ’é™¤å¯¼èˆªã€é¡µè„šã€ä¾§è¾¹æ ç­‰å…ƒç´ 
3. âœ… è¿”å›æ›´å¹²å‡€çš„ markdown å†…å®¹

### å®é™…é—®é¢˜

è™½ç„¶å‚æ•°å·²æ­£ç¡®ä¼ é€’ï¼Œä½†å†…å®¹ä»åŒ…å« Sidebar å’Œ Magazine menuï¼Œå¯èƒ½åŸå› ï¼š

1. **Firecrawl API ç¼“å­˜** - ä½¿ç”¨äº†ä¹‹å‰çš„ç¼“å­˜ç»“æœï¼ˆæ³¨æ„æ—¥å¿—ä¸­çš„ `cacheState: hit`ï¼‰
2. **ç½‘ç«™ç»“æ„ç‰¹æ®Š** - è¯¥ç½‘ç«™çš„"ä¸»è¦å†…å®¹"å®šä¹‰åŒ…å«è¿™äº›å¯¼èˆªå…ƒç´ 
3. **å‚æ•°æ ¼å¼é—®é¢˜** - å¯èƒ½éœ€è¦å…¶ä»–å‚æ•°ç»„åˆ

### Firecrawl API ç¼“å­˜è¯´æ˜

ä» metadata ä¸­çœ‹åˆ°ï¼š
```json
{
  "cacheState": "hit",
  "cachedAt": "2025-11-04T09:23:51.029Z"
}
```

**å»ºè®®**ï¼š
- ç­‰å¾…ç¼“å­˜è¿‡æœŸåé‡è¯•
- æˆ–ä½¿ç”¨ä¸åŒçš„ URL å‚æ•°å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
- æˆ–è”ç³» Firecrawl æ”¯æŒæ¸…é™¤ç‰¹å®š URL çš„ç¼“å­˜

## ğŸ”§ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### 1. å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ

```python
params = {
    'formats': ['markdown', 'html'],
    'onlyMainContent': True,
    'waitFor': 3000,  # æ›´é•¿çš„ç­‰å¾…æ—¶é—´
    'removeTags': ['nav', 'aside', 'footer', 'header'],  # å°è¯• removeTags
    'timeout': 30
}
```

### 2. ä½¿ç”¨ Firecrawl çš„ Extract API

å¯¹äºç»“æ„åŒ–å†…å®¹æå–ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ Extract APIï¼š

```python
schema = {
    "type": "object",
    "properties": {
        "articles": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "title": {"type": "string"},
                    "content": {"type": "string"},
                    "url": {"type": "string"}
                }
            }
        }
    }
}

result = await crawler.extract(url, schema)
```

### 3. è‡ªå®šä¹‰é€‰æ‹©å™¨

å¦‚æœçŸ¥é“ä¸»è¦å†…å®¹çš„ CSS é€‰æ‹©å™¨ï¼Œå¯ä»¥ä½¿ç”¨ï¼š

```python
params = {
    'formats': ['markdown'],
    'selectors': ['.main-content', 'article', '.post-content']
}
```

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶

1. âœ… `src/infrastructure/crawlers/firecrawl_adapter.py` - ä¿®å¤ scrape æ–¹æ³•å‚æ•°å¤„ç†
2. âœ… `src/services/task_scheduler.py` - ä¼˜åŒ–çˆ¬å–é…ç½®å‚æ•°

## ğŸ¯ ä½¿ç”¨è¯´æ˜

### åˆ›å»ºçˆ¬å–ä»»åŠ¡æ—¶æŒ‡å®šå‚æ•°

é€šè¿‡ `search_config` å­—æ®µè‡ªå®šä¹‰çˆ¬å–è¡Œä¸ºï¼š

```python
task = SearchTask(
    name="è‡ªå®šä¹‰çˆ¬å–ä»»åŠ¡",
    crawl_url="https://example.com",
    search_config={
        "only_main_content": True,  # åªæå–ä¸»è¦å†…å®¹
        "wait_for": 3000,  # ç­‰å¾…3ç§’
        "exclude_tags": ["nav", "footer", "aside", "header"],
        "timeout": 30
    }
)
```

### é»˜è®¤å€¼

å¦‚æœä¸æŒ‡å®šï¼Œä½¿ç”¨ä»¥ä¸‹é»˜è®¤å€¼ï¼š
- `only_main_content`: True
- `wait_for`: 2000ms
- `exclude_tags`: `["nav", "footer", "header", "aside", "sidebar"]`
- `timeout`: 30ç§’

## âš ï¸ å·²çŸ¥é—®é¢˜

1. **HTML å†…å®¹ä¸ºç©º** - Firecrawl API å¯èƒ½åœ¨æŸäº›æƒ…å†µä¸‹ä¸è¿”å› HTML
2. **ç¼“å­˜å½±å“** - API ç¼“å­˜å¯èƒ½å¯¼è‡´å‚æ•°ä¿®æ”¹ä¸ç«‹å³ç”Ÿæ•ˆ
3. **ç½‘ç«™ç‰¹å¼‚æ€§** - ä¸åŒç½‘ç«™çš„"ä¸»è¦å†…å®¹"è¯†åˆ«æ•ˆæœå¯èƒ½ä¸åŒ

## ğŸ”„ æµ‹è¯•æ¨¡å¼è¯´æ˜

å½“å‰ç³»ç»Ÿé…ç½®ï¼š
- `TEST_MODE=true` - æµ‹è¯•æ¨¡å¼å¯ç”¨
- Firecrawl API ä½¿ç”¨çœŸå® API Key
- çˆ¬å–åŠŸèƒ½ä½¿ç”¨çœŸå® Firecrawl Scrape API
- æœç´¢åŠŸèƒ½åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Firecrawl API æ–‡æ¡£](https://docs.firecrawl.dev/)
- [Firecrawl Python SDK](https://github.com/mendableai/firecrawl-py)
- é¡¹ç›®æ–‡æ¡£: `claudedocs/RAW_DATA_STORAGE_IMPLEMENTATION_SUMMARY.md`

## æ€»ç»“

âœ… **å·²å®Œæˆ**:
1. ä¿®å¤ `firecrawl_adapter.py` å¿½ç•¥ options å‚æ•°çš„é—®é¢˜
2. æ·»åŠ  `onlyMainContent`, `waitFor`, `excludeTags` ç­‰å…³é”®å‚æ•°
3. ä¼˜åŒ–é»˜è®¤é…ç½®ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´å’Œæ’é™¤æ ‡ç­¾
4. æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è¾“å‡º

â³ **å¾…è§‚å¯Ÿ**:
1. Firecrawl API ç¼“å­˜è¿‡æœŸåçš„æ•ˆæœ
2. HTML å†…å®¹æ˜¯å¦èƒ½æ­£å¸¸è¿”å›
3. ä¸åŒç½‘ç«™çš„çˆ¬å–æ•ˆæœ

ğŸ’¡ **å»ºè®®**:
1. æ ¹æ®å…·ä½“ç½‘ç«™è°ƒæ•´å‚æ•°
2. å¿…è¦æ—¶ä½¿ç”¨ Extract API è¿›è¡Œç»“æ„åŒ–æå–
3. è€ƒè™‘æ·»åŠ è‡ªå®šä¹‰ CSS é€‰æ‹©å™¨æ”¯æŒ
